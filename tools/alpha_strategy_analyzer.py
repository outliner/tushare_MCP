"""
ç›¸å¯¹å¼ºåº¦Alphaæ¨¡å‹ç­–ç•¥åˆ†æå™¨

ç­–ç•¥è¯´æ˜ï¼š
1. è®¡ç®—æ¿å—å’Œæ²ªæ·±300åœ¨2å¤©å’Œ5å¤©çš„åŒºé—´æ”¶ç›Šç‡
2. è®¡ç®—è¶…é¢æ”¶ç›ŠAlpha = æ¿å—æ”¶ç›Š - åŸºå‡†æ”¶ç›Š
3. ç»¼åˆè¯„åˆ†ï¼šScore = Î±2 Ã— 60% + Î±5 Ã— 40%
"""
import sys
import tushare as ts
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from config.token_manager import get_tushare_token
from cache.index_daily_cache_manager import index_daily_cache_manager
from cache.cache_manager import cache_manager
from cache.concept_cache_manager import concept_cache_manager

# [Fix] Override print to suppress excessive stderr logging that might cause MCP crashes
def print(*args, **kwargs):
    pass


def calculate_period_return(prices: pd.Series, days: int) -> float:
    """
    è®¡ç®—åŒºé—´æ”¶ç›Šç‡
    
    å‚æ•°:
        prices: ä»·æ ¼åºåˆ—ï¼ˆæŒ‰æ—¥æœŸæ’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
        days: æ—¶é—´çª—å£ï¼ˆå¤©æ•°ï¼‰
    
    è¿”å›:
        æ”¶ç›Šç‡ï¼ˆå°æ•°å½¢å¼ï¼Œå¦‚0.05è¡¨ç¤º5%ï¼‰
    """
    if len(prices) < days + 1:
        return None
    
    # æœ€æ–°ä»·æ ¼
    p_end = prices.iloc[0]
    # Nå¤©å‰çš„ä»·æ ¼
    p_start = prices.iloc[days]
    
    if pd.isna(p_end) or pd.isna(p_start) or p_start == 0:
        return None
    
    return (p_end - p_start) / p_start

def calculate_alpha(sector_return: float, benchmark_return: float) -> float:
    """
    è®¡ç®—è¶…é¢æ”¶ç›ŠAlpha
    
    å‚æ•°:
        sector_return: æ¿å—æ”¶ç›Šç‡
        benchmark_return: åŸºå‡†æ”¶ç›Šç‡
    
    è¿”å›:
        Alphaå€¼ï¼ˆå°æ•°å½¢å¼ï¼‰
    """
    if sector_return is None or benchmark_return is None:
        return None
    return sector_return - benchmark_return

def calculate_alpha_score(alpha_2: float, alpha_5: float) -> float:
    """
    è®¡ç®—ç»¼åˆAlphaå¾—åˆ†
    
    å‚æ•°:
        alpha_2: 2å¤©Alpha
        alpha_5: 5å¤©Alpha
    
    è¿”å›:
        ç»¼åˆå¾—åˆ†ï¼ˆå¦‚æœ5æ—¥Alphaç¼ºå¤±ï¼Œåˆ™ä»…ä½¿ç”¨2æ—¥Alphaï¼‰
    """
    if alpha_2 is None:
        return None
    if alpha_5 is None:
        # å¦‚æœ5æ—¥Alphaç¼ºå¤±ï¼Œä»…ä½¿ç”¨2æ—¥Alphaï¼ˆæƒé‡100%ï¼‰
        return alpha_2
    return alpha_2 * 0.6 + alpha_5 * 0.4

def analyze_sector_alpha(
    sector_code: str,
    benchmark_code: str = "000001.SH",
    end_date: str = None
) -> Dict:
    """
    åˆ†æå•ä¸ªæ¿å—çš„Alpha
    
    å‚æ•°:
        sector_code: æ¿å—æŒ‡æ•°ä»£ç 
        benchmark_code: åŸºå‡†æŒ‡æ•°ä»£ç ï¼ˆé»˜è®¤ä¸Šè¯æŒ‡æ•°ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
    
    è¿”å›:
        åŒ…å«Alphaåˆ†æç»“æœçš„å­—å…¸
    """
    token = get_tushare_token()
    if not token:
        return {"error": "è¯·å…ˆé…ç½®Tushare token"}
    
    if end_date is None or end_date == "":
        end_date = datetime.now().strftime('%Y%m%d')
    
    try:
        # è·å–æ¿å—æ•°æ®ï¼ˆè‡³å°‘éœ€è¦5ä¸ªäº¤æ˜“æ—¥ï¼Œé¢„ç•™30å¤©ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
        start_date = (datetime.strptime(end_date, '%Y%m%d') - timedelta(days=30)).strftime('%Y%m%d')
        
        # åˆ¤æ–­æ˜¯ç”³ä¸‡è¡Œä¸šæŒ‡æ•°ã€ä¸œè´¢æ¦‚å¿µæ¿å—è¿˜æ˜¯æ™®é€šæŒ‡æ•°
        is_sw_industry = sector_code.endswith('.SI')
        is_eastmoney_concept = sector_code.endswith('.DC')
        
        if is_sw_industry:
            # ç”³ä¸‡è¡Œä¸šæŒ‡æ•°ä½¿ç”¨sw_dailyæ¥å£
            # è‡ªåŠ¨æ£€æµ‹è¡Œä¸šçº§åˆ«ï¼šäºŒçº§è¡Œä¸šä»£ç é€šå¸¸æ˜¯6ä½æ•°å­—ï¼ˆå¦‚801011.SIï¼‰ï¼Œä¸€çº§è¡Œä¸šæ˜¯5ä½ï¼ˆå¦‚801010.SIï¼‰
            # æ›´å‡†ç¡®çš„æ–¹æ³•ï¼šå°è¯•L1ï¼Œå¦‚æœå¤±è´¥å†å°è¯•L2
            level = 'L1'  # é»˜è®¤L1
            if len(sector_code.split('.')[0]) == 6:  # äºŒçº§è¡Œä¸šä»£ç é€šå¸¸æ˜¯6ä½
                level = 'L2'
            
            cache_params = {
                'ts_code': sector_code,
                'level': level,
                'start_date': start_date,
                'end_date': end_date
            }
            sector_df = cache_manager.get_dataframe('sw_industry_daily', **cache_params)
            
            if sector_df is None or sector_df.empty:
                # ä»APIè·å–
                pro = ts.pro_api()
                sector_df = pro.sw_daily(ts_code=sector_code, level=level, start_date=start_date, end_date=end_date)
                if not sector_df.empty:
                    cache_manager.set('sw_industry_daily', sector_df, **cache_params)
                elif level == 'L1':
                    # å¦‚æœL1å¤±è´¥ï¼Œå°è¯•L2
                    level = 'L2'
                    cache_params['level'] = 'L2'
                    sector_df = pro.sw_daily(ts_code=sector_code, level='L2', start_date=start_date, end_date=end_date)
                    if not sector_df.empty:
                        cache_manager.set('sw_industry_daily', sector_df, **cache_params)
            
            # ç­›é€‰æŒ‡å®šæŒ‡æ•°çš„æ•°æ®
            if not sector_df.empty:
                # sw_dailyè¿”å›çš„å­—æ®µå¯èƒ½æ˜¯index_codeæˆ–ts_code
                if 'ts_code' in sector_df.columns:
                    sector_df = sector_df[sector_df['ts_code'] == sector_code].copy()
                elif 'index_code' in sector_df.columns:
                    sector_df = sector_df[sector_df['index_code'] == sector_code].copy()
                    # ç»Ÿä¸€å­—æ®µåï¼Œç¡®ä¿æœ‰ts_codeå­—æ®µ
                    if 'ts_code' not in sector_df.columns:
                        sector_df['ts_code'] = sector_df['index_code']
        elif is_eastmoney_concept:
            # ä¸œè´¢æ¦‚å¿µæ¿å—ä½¿ç”¨dc_dailyæ¥å£
            # ä¼˜å…ˆä»ä¸“ç”¨ç¼“å­˜ç®¡ç†å™¨è·å–æ•°æ®
            sector_df = concept_cache_manager.get_concept_daily_data(
                ts_code=sector_code,
                start_date=start_date,
                end_date=end_date
            )
            
            if sector_df is None or sector_df.empty:
                # ä»APIè·å–
                pro = ts.pro_api()
                sector_df = pro.dc_daily(ts_code=sector_code, start_date=start_date, end_date=end_date)
                if not sector_df.empty:
                    # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜ç®¡ç†å™¨
                    concept_cache_manager.save_concept_daily_data(sector_df)
            
            # ç­›é€‰æŒ‡å®šæ¿å—çš„æ•°æ®
            if not sector_df.empty and 'ts_code' in sector_df.columns:
                sector_df = sector_df[sector_df['ts_code'] == sector_code].copy()
        else:
            # æ™®é€šæŒ‡æ•°ä½¿ç”¨index_dailyæ¥å£
            sector_df = index_daily_cache_manager.get_index_daily_data(
                ts_code=sector_code,
                start_date=start_date,
                end_date=end_date
            )
            
            if sector_df is None or sector_df.empty:
                # ä»APIè·å–
                pro = ts.pro_api()
                sector_df = pro.index_daily(ts_code=sector_code, start_date=start_date, end_date=end_date)
                if not sector_df.empty:
                    index_daily_cache_manager.save_index_daily_data(sector_df)
        
        # è·å–åŸºå‡†æ•°æ®
        benchmark_df = index_daily_cache_manager.get_index_daily_data(
            ts_code=benchmark_code,
            start_date=start_date,
            end_date=end_date
        )
        
        if benchmark_df is None or benchmark_df.empty:
            # ä»APIè·å–
            pro = ts.pro_api()
            benchmark_df = pro.index_daily(ts_code=benchmark_code, start_date=start_date, end_date=end_date)
            if not benchmark_df.empty:
                index_daily_cache_manager.save_index_daily_data(benchmark_df)
        
        if sector_df.empty or benchmark_df.empty:
            return {"error": f"æ— æ³•è·å– {sector_code} æˆ– {benchmark_code} çš„æ•°æ®"}
        
        # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        sector_df = sector_df.sort_values('trade_date', ascending=False)
        benchmark_df = benchmark_df.sort_values('trade_date', ascending=False)
        
        # æå–æ”¶ç›˜ä»·åºåˆ—ï¼ˆç”³ä¸‡è¡Œä¸šå¯èƒ½ä½¿ç”¨ä¸åŒçš„å­—æ®µåï¼‰
        if 'close' in sector_df.columns:
            sector_val = 'close'
        elif 'index' in sector_df.columns:
            sector_val = 'index'  # sw_dailyå¯èƒ½ä½¿ç”¨indexå­—æ®µ
        else:
            return {"error": f"æ— æ³•æ‰¾åˆ° {sector_code} çš„æ”¶ç›˜ä»·å­—æ®µ"}
            
        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸå¯¹é½
        # å°† trade_date è®¾ä¸ºç´¢å¼•å¹¶è½¬ä¸º datetime ç±»å‹
        sector_df['trade_date'] = pd.to_datetime(sector_df['trade_date'].astype(str))
        benchmark_df['trade_date'] = pd.to_datetime(benchmark_df['trade_date'].astype(str))
        
        sector_df = sector_df.set_index('trade_date')
        benchmark_df = benchmark_df.set_index('trade_date')
        
        # å–äº¤é›†ç´¢å¼•ï¼ˆå…±åŒçš„äº¤æ˜“æ—¥ï¼‰ï¼Œå¹¶æŒ‰æ—¥æœŸé™åºæ’åˆ—
        common_dates = sector_df.index.intersection(benchmark_df.index).sort_values(ascending=False)
        
        if len(common_dates) < 6: # è‡³å°‘éœ€è¦6å¤©æ•°æ®ï¼ˆè®¡ç®—5æ—¥æ”¶ç›Šç‡éœ€è¦ç¬¬6å¤©çš„æ•°æ®ä½œä¸ºåŸºå‡†ï¼‰
             return {"error": f"æ•°æ®ä¸è¶³ï¼Œå…±åŒäº¤æ˜“æ—¥ä»… {len(common_dates)} å¤©"}
             
        # åŸºäºå…±åŒæ—¥æœŸå¯¹é½æ•°æ®
        sector_prices = sector_df.loc[common_dates][sector_val]
        benchmark_prices = benchmark_df.loc[common_dates]['close']
        
        # æ£€æŸ¥æœ€æ–°æ—¥æœŸæ˜¯å¦æ˜¯è¯·æ±‚çš„ end_date (æˆ–è€…æœ€è¿‘çš„äº¤æ˜“æ—¥)
        # åªæœ‰å½“æ˜¾å¼è¯·æ±‚äº† end_date ä¸”ä¸æ˜¯ä»Šå¤©æ—¶æ‰è¿›è¡Œæ­¤æ£€æŸ¥
        # (å¦‚æœæ˜¯ä»Šå¤©ï¼Œå¯èƒ½æ•°æ®è¿˜æ²¡æ›´æ–°ï¼Œæˆ‘ä»¬æ¥å—æœ€æ–°å¯ç”¨çš„æ•°æ®)
        latest_date = sector_prices.index[0].strftime('%Y%m%d')
        
        # è®°å½•å®é™…ä½¿ç”¨çš„æ—¥æœŸï¼Œç”¨äºè¿”å›ç»“æœ
        actual_date = latest_date
        
        # è®¡ç®—æ”¶ç›Šç‡
        r_sector_1 = calculate_period_return(sector_prices, 1)
        r_sector_2 = calculate_period_return(sector_prices, 2)
        r_sector_5 = calculate_period_return(sector_prices, 5)
        r_benchmark_1 = calculate_period_return(benchmark_prices, 1)
        r_benchmark_2 = calculate_period_return(benchmark_prices, 2)
        r_benchmark_5 = calculate_period_return(benchmark_prices, 5)
        
        # è®¡ç®—Alpha
        alpha_1 = calculate_alpha(r_sector_1, r_benchmark_1)
        alpha_2 = calculate_alpha(r_sector_2, r_benchmark_2)
        alpha_5 = calculate_alpha(r_sector_5, r_benchmark_5)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        score = calculate_alpha_score(alpha_2, alpha_5)
        
        # ç¡®ä¿scoreä¸ä¸ºNoneï¼ˆå¦‚æœalpha_2å­˜åœ¨ï¼Œscoreåº”è¯¥è¢«è®¾ç½®ï¼‰
        if score is None and alpha_2 is not None:
            score = alpha_2  # ä½¿ç”¨2æ—¥Alphaä½œä¸ºç»¼åˆå¾—åˆ†
        
        return {
            "sector_code": sector_code,
            "benchmark_code": benchmark_code,
            "end_date": end_date,
            "actual_date": actual_date,  # æ·»åŠ å®é™…ä½¿ç”¨çš„æ—¥æœŸ
            "r_sector_1": r_sector_1,
            "r_sector_2": r_sector_2,
            "r_sector_5": r_sector_5,
            "r_benchmark_1": r_benchmark_1,
            "r_benchmark_2": r_benchmark_2,
            "r_benchmark_5": r_benchmark_5,
            "alpha_1": alpha_1,
            "alpha_2": alpha_2,
            "alpha_5": alpha_5,
            "score": score
        }
    
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        return {"error": f"åˆ†æå¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"}

def rank_sectors_alpha(
    sector_codes: List[str],
    benchmark_code: str = "000001.SH",
    end_date: str = None
) -> pd.DataFrame:
    """
    å¯¹å¤šä¸ªæ¿å—è¿›è¡ŒAlphaæ’å
    
    å‚æ•°:
        sector_codes: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
        benchmark_code: åŸºå‡†æŒ‡æ•°ä»£ç 
        end_date: ç»“æŸæ—¥æœŸï¼ˆNoneæˆ–ç©ºå­—ç¬¦ä¸²æ—¶ä½¿ç”¨ä»Šå¤©ï¼‰
    
    è¿”å›:
        åŒ…å«æ’åç»“æœçš„DataFrame
    """
    # å¦‚æœend_dateä¸ºç©ºå­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºNone
    if end_date == "":
        end_date = None
    
    results = []
    errors = []
    
    for sector_code in sector_codes:
        result = analyze_sector_alpha(sector_code, benchmark_code, end_date)
        if "error" not in result:
            results.append(result)
        else:
            errors.append(f"{sector_code}: {result['error']}")
    
    if not results:
        # å¦‚æœæ‰€æœ‰éƒ½å¤±è´¥ï¼Œæ‰“å°å‰å‡ ä¸ªé”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
        if errors:
            error_summary = "\n".join(errors[:10])  # æ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
            print(f"æ‰€æœ‰æ¿å—æ•°æ®è·å–å¤±è´¥ï¼Œå‰10ä¸ªé”™è¯¯:\n{error_summary}", file=sys.stderr)
        else:
            print("æ‰€æœ‰æ¿å—æ•°æ®è·å–å¤±è´¥ï¼Œä½†æ²¡æœ‰é”™è¯¯ä¿¡æ¯", file=sys.stderr)
        return pd.DataFrame()
    
    df = pd.DataFrame(results)
    
    # ç¡®ä¿scoreåˆ—å­˜åœ¨ä¸”æ­£ç¡®å¡«å……ï¼ˆå¦‚æœscoreä¸ºNoneä½†alpha_2å­˜åœ¨ï¼Œä½¿ç”¨alpha_2ï¼‰
    if 'score' in df.columns:
        df['score'] = df['score'].fillna(df['alpha_2'])
    else:
        df['score'] = df['alpha_2']
    
    # æŒ‰å¾—åˆ†æ’åºï¼ˆé™åºï¼‰
    df = df.sort_values('score', ascending=False, na_position='last')
    
    # æ·»åŠ æ’å
    df['rank'] = range(1, len(df) + 1)
    
    return df

def format_alpha_analysis(df: pd.DataFrame) -> str:
    """
    æ ¼å¼åŒ–Alphaåˆ†æç»“æœ
    
    å‚æ•°:
        df: Alphaåˆ†æç»“æœDataFrame
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»“æœ"
    
    result = []
    result.append("ğŸ“Š ç›¸å¯¹å¼ºåº¦Alphaæ¨¡å‹åˆ†æç»“æœ")
    result.append("=" * 120)
    
    # æ·»åŠ æ—¥æœŸä¿¡æ¯æ£€æŸ¥
    if 'actual_date' in df.columns:
        actual_dates = df['actual_date'].dropna().unique()
        requested_dates = df['end_date'].dropna().unique() if 'end_date' in df.columns else []
        
        if len(actual_dates) == 1:
            actual_date_str = str(actual_dates[0])
            result.append(f"å®é™…æ•°æ®æ—¥æœŸ: {actual_date_str}")
            
            # æ£€æŸ¥ä¸è¯·æ±‚æ—¥æœŸæ˜¯å¦ä¸€è‡´
            if len(requested_dates) == 1:
                req_date = str(requested_dates[0])
                if req_date and req_date != actual_date_str:
                    result.append(f"âš ï¸ æ³¨æ„ï¼šå®é™…æ•°æ®æ—¥æœŸ ({actual_date_str}) ä¸è¯·æ±‚æ—¥æœŸ ({req_date}) ä¸ä¸€è‡´")
                    result.append("          å¯èƒ½æ˜¯å½“å¤©æ•°æ®å°šæœªæ›´æ–°ï¼Œç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨äº†æœ€è¿‘çš„äº¤æ˜“æ—¥æ•°æ®")
        elif len(actual_dates) > 1:
            dates_str = ", ".join([str(d) for d in actual_dates[:3]])
            if len(actual_dates) > 3:
                dates_str += "..."
            result.append(f"å®é™…æ•°æ®æ—¥æœŸ: {dates_str} (å­˜åœ¨å¤šä¸ªæ—¥æœŸ)")
            result.append("âš ï¸ æ³¨æ„ï¼šæ’åä¸­åŒ…å«ä¸åŒæ—¥æœŸçš„æ•°æ®ï¼Œè¯·è°¨æ…å¯¹æ¯”")
            
    result.append("")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰nameåˆ—
    has_name = 'name' in df.columns
    
    if has_name:
        result.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<12} {'æ¿å—åç§°':<12} {'å½“å¤©Alpha':<12} {'2æ—¥Alpha':<12} {'5æ—¥Alpha':<12} {'ç»¼åˆå¾—åˆ†':<12} {'å½“å¤©æ”¶ç›Š':<12} {'2æ—¥æ”¶ç›Š':<12} {'5æ—¥æ”¶ç›Š':<12}")
    else:
        result.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<12} {'å½“å¤©Alpha':<12} {'2æ—¥Alpha':<12} {'5æ—¥Alpha':<12} {'ç»¼åˆå¾—åˆ†':<12} {'å½“å¤©æ”¶ç›Š':<12} {'2æ—¥æ”¶ç›Š':<12} {'5æ—¥æ”¶ç›Š':<12}")
    result.append("-" * 140)
    
    for _, row in df.iterrows():
        rank = f"{int(row['rank'])}"
        sector_code = row['sector_code']
        
        if has_name:
            sector_name = str(row['name'])
            # æˆªæ–­è¿‡é•¿çš„åç§°
            if len(sector_name) > 6:
                sector_name = sector_name[:6]
        
        alpha_1 = f"{row['alpha_1']*100:.2f}%" if pd.notna(row['alpha_1']) else "-"
        alpha_2 = f"{row['alpha_2']*100:.2f}%" if pd.notna(row['alpha_2']) else "-"
        alpha_5 = f"{row['alpha_5']*100:.2f}%" if pd.notna(row['alpha_5']) else "-"
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆä½¿ç”¨scoreåˆ—ï¼‰
        if pd.notna(row['score']):
            score = f"{row['score']*100:.2f}%"
        elif pd.notna(row['alpha_2']):
            # å¤‡ç”¨æ–¹æ¡ˆï¼šå¦‚æœscoreç¼ºå¤±ä½†alpha_2å­˜åœ¨
            score = f"{row['alpha_2']*100:.2f}%"
        else:
            score = "-"
        
        r_1 = f"{row['r_sector_1']*100:.2f}%" if pd.notna(row['r_sector_1']) else "-"
        r_2 = f"{row['r_sector_2']*100:.2f}%" if pd.notna(row['r_sector_2']) else "-"
        r_5 = f"{row['r_sector_5']*100:.2f}%" if pd.notna(row['r_sector_5']) else "-"
        
        if has_name:
            result.append(f"{rank:<6} {sector_code:<12} {sector_name:<12} {alpha_1:<12} {alpha_2:<12} {alpha_5:<12} {score:<12} {r_1:<12} {r_2:<12} {r_5:<12}")
        else:
            result.append(f"{rank:<6} {sector_code:<12} {alpha_1:<12} {alpha_2:<12} {alpha_5:<12} {score:<12} {r_1:<12} {r_2:<12} {r_5:<12}")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - Alpha = æ¿å—æ”¶ç›Šç‡ - åŸºå‡†æ”¶ç›Šç‡ï¼ˆä¸Šè¯æŒ‡æ•°ï¼‰")
    result.append("  - ç»¼åˆå¾—åˆ† = Alpha_2 Ã— 60% + Alpha_5 Ã— 40%ï¼ˆå¦‚æœ5æ—¥æ•°æ®ä¸è¶³ï¼Œåˆ™ä»…ä½¿ç”¨2æ—¥Alphaï¼‰")
    result.append("  - å¾—åˆ†è¶Šé«˜ï¼Œè¡¨ç¤ºæ¿å—ç›¸å¯¹å¤§ç›˜è¶Šå¼ºåŠ¿")
    result.append("  - å»ºè®®å…³æ³¨å¾—åˆ†å‰5-10åçš„æ¿å—")
    result.append("")
    result.append(f"ğŸ“Š ç»Ÿè®¡ï¼šå…±åˆ†æ {len(df)} ä¸ªè¡Œä¸šï¼Œå…¶ä¸­ {len(df[df['alpha_5'].notna()])} ä¸ªè¡Œä¸šæœ‰5æ—¥æ•°æ®")
    
    return "\n".join(result)

def get_previous_trading_dates(end_date: str, days: int = 5) -> List[str]:
    """
    è·å–å‰Nä¸ªäº¤æ˜“æ—¥ï¼ˆåŒ…æ‹¬å½“å¤©ï¼‰
    
    å‚æ•°:
        end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚æœæ˜¯å‘¨æœ«ä¼šè‡ªåŠ¨ä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰
        days: éœ€è¦è·å–çš„å¤©æ•°ï¼ˆé»˜è®¤5å¤©ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼‰
    
    è¿”å›:
        äº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆä»æ–°åˆ°æ—§ï¼‰
    """
    token = get_tushare_token()
    if not token:
        print("è­¦å‘Šï¼šæ— æ³•è·å–token", file=sys.stderr)
        return []
    
    try:
        pro = ts.pro_api()
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨äº¤æ˜“æ—¥å†æ¥å£è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
        # å¦‚æœend_dateæ˜¯å‘¨æœ«ï¼Œéœ€è¦æ‰¾åˆ°æœ€è¿‘çš„äº¤æ˜“æ—¥
        end_date_obj = datetime.strptime(end_date, '%Y%m%d')
        start_date = (end_date_obj - timedelta(days=days*3)).strftime('%Y%m%d')
        
        print(f"è°ƒè¯•ï¼šè·å–äº¤æ˜“æ—¥ - end_date={end_date}, start_date={start_date}, days={days}", file=sys.stderr)
        
        # æ–¹æ³•1ï¼šä½¿ç”¨äº¤æ˜“æ—¥å†æ¥å£ï¼ˆæ›´å¯é ï¼Œå¯ä»¥å¤„ç†å‘¨æœ«ï¼‰
        try:
            # è·å–äº¤æ˜“æ—¥å†ï¼Œæ‰¾åˆ°end_dateä¹‹å‰ï¼ˆåŒ…æ‹¬end_dateï¼‰çš„æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥
            cal_df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=end_date, is_open=1)
            
            if cal_df is not None and not cal_df.empty:
                # ç­›é€‰å‡ºäº¤æ˜“æ—¥ï¼ˆis_open=1ï¼‰ï¼ŒæŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                cal_df = cal_df.sort_values('cal_date', ascending=False)
                # åªå–end_dateåŠä¹‹å‰çš„äº¤æ˜“æ—¥
                # ç¡®ä¿cal_dateåˆ—å’Œend_dateéƒ½æ˜¯æ•´æ•°ç±»å‹è¿›è¡Œæ¯”è¾ƒ
                if cal_df['cal_date'].dtype != 'int64':
                    cal_df['cal_date'] = pd.to_numeric(cal_df['cal_date'], errors='coerce')
                end_date_int = int(end_date) if isinstance(end_date, str) else end_date
                cal_df = cal_df[cal_df['cal_date'] <= end_date_int]
                # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å»é‡
                trading_dates = cal_df['cal_date'].astype(str).unique().tolist()[:days]
                
                # ç¡®ä¿æ—¥æœŸä¸é‡å¤
                trading_dates = list(dict.fromkeys(trading_dates))  # ä¿æŒé¡ºåºçš„å»é‡
                
                if len(trading_dates) >= 1:  # è‡³å°‘éœ€è¦1ä¸ªäº¤æ˜“æ—¥
                    print(f"è°ƒè¯•ï¼šä»äº¤æ˜“æ—¥å†è·å–åˆ°{len(trading_dates)}ä¸ªäº¤æ˜“æ—¥: {trading_dates}", file=sys.stderr)
                    return trading_dates
        except Exception as e:
            print(f"è°ƒè¯•ï¼šäº¤æ˜“æ—¥å†æ¥å£å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•: {str(e)}", file=sys.stderr)
        
        # æ–¹æ³•2ï¼šå¤‡ç”¨æ–¹æ³• - ä½¿ç”¨åŸºå‡†æŒ‡æ•°çš„æ•°æ®æ¥ç¡®å®šäº¤æ˜“æ—¥
        benchmark_code = "000001.SH"
        
        benchmark_df = index_daily_cache_manager.get_index_daily_data(
            ts_code=benchmark_code,
            start_date=start_date,
            end_date=end_date
        )
        
        if benchmark_df is None or benchmark_df.empty:
            print(f"è°ƒè¯•ï¼šç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œä»APIè·å–", file=sys.stderr)
            benchmark_df = pro.index_daily(ts_code=benchmark_code, start_date=start_date, end_date=end_date)
            if not benchmark_df.empty:
                index_daily_cache_manager.save_index_daily_data(benchmark_df)
                print(f"è°ƒè¯•ï¼šä»APIè·å–åˆ°{len(benchmark_df)}æ¡æ•°æ®", file=sys.stderr)
        
        if benchmark_df.empty:
            print(f"è­¦å‘Šï¼šæ— æ³•è·å–åŸºå‡†æŒ‡æ•°æ•°æ®æ¥ç¡®å®šäº¤æ˜“æ—¥", file=sys.stderr)
            return []
        
        # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰ï¼Œå»é‡å¹¶è·å–å‰Nä¸ªäº¤æ˜“æ—¥
        benchmark_df = benchmark_df.sort_values('trade_date', ascending=False)
        # åªå–end_dateåŠä¹‹å‰çš„äº¤æ˜“æ—¥
        # ç¡®ä¿trade_dateåˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä»¥ä¾¿ä¸end_dateï¼ˆå­—ç¬¦ä¸²ï¼‰æ¯”è¾ƒ
        if benchmark_df['trade_date'].dtype != 'object':
            benchmark_df['trade_date'] = benchmark_df['trade_date'].astype(str)
        benchmark_df = benchmark_df[benchmark_df['trade_date'] <= str(end_date)]
        # å»é‡å¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        trading_dates = benchmark_df['trade_date'].unique().tolist()[:days]
        trading_dates = [str(date) for date in trading_dates]
        # å†æ¬¡å»é‡ï¼ˆç¡®ä¿å­—ç¬¦ä¸²æ ¼å¼çš„æ—¥æœŸä¸é‡å¤ï¼‰
        trading_dates = list(dict.fromkeys(trading_dates))
        
        print(f"è°ƒè¯•ï¼šä»æŒ‡æ•°æ•°æ®è·å–åˆ°{len(trading_dates)}ä¸ªäº¤æ˜“æ—¥: {trading_dates}", file=sys.stderr)
        
        return trading_dates
    
    except Exception as e:
        print(f"è·å–äº¤æ˜“æ—¥å¤±è´¥: {str(e)}", file=sys.stderr)
        import traceback
        print(traceback.format_exc(), file=sys.stderr)
        return []

def calculate_alpha_rank_velocity(
    sector_codes: List[str],
    benchmark_code: str = "000001.SH",
    end_date: str = None
) -> pd.DataFrame:
    """
    è®¡ç®—ç”³ä¸‡äºŒçº§è¡Œä¸šçš„Alphaæ’åä¸Šå‡é€Ÿåº¦
    
    å‚æ•°:
        sector_codes: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
        benchmark_code: åŸºå‡†æŒ‡æ•°ä»£ç 
        end_date: ç»“æŸæ—¥æœŸï¼ˆNoneæˆ–ç©ºå­—ç¬¦ä¸²æ—¶ä½¿ç”¨ä»Šå¤©ï¼‰
    
    è¿”å›:
        åŒ…å«æ’åä¸Šå‡é€Ÿåº¦çš„DataFrameï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š
        - sector_code: æ¿å—ä»£ç 
        - current_alpha: å½“å¤©alphaå€¼
        - current_rank: å½“å¤©æ’å
        - rank_change_1d: ç›¸è¾ƒæ˜¨æ—¥ä¸Šå‡ä½æ•°ï¼ˆæ­£æ•°è¡¨ç¤ºä¸Šå‡ï¼‰
        - rank_change_2d: ç›¸è¾ƒå‰å¤©ä¸Šå‡ä½æ•°ï¼ˆæ­£æ•°è¡¨ç¤ºä¸Šå‡ï¼‰
    """
    # å¦‚æœend_dateä¸ºç©ºå­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºNone
    if end_date == "":
        end_date = None
    
    # ç¡®å®šè¦åˆ†æçš„åŸºå‡†æ—¥æœŸ
    if end_date is None or end_date == "":
        # å¦‚æœæœªæŒ‡å®šæ—¥æœŸï¼Œä½¿ç”¨ä»Šå¤©
        today = datetime.now().strftime('%Y%m%d')
        end_date = today
    
    # è·å–æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥ï¼ˆåŒ…æ‹¬end_dateåŠä¹‹å‰çš„äº¤æ˜“æ—¥ï¼‰
    # æ³¨æ„ï¼šå¦‚æœend_dateæ˜¯å‘¨æœ«ï¼Œget_previous_trading_datesä¼šè‡ªåŠ¨è¿”å›end_dateä¹‹å‰çš„äº¤æ˜“æ—¥
    # è·å–5ä¸ªäº¤æ˜“æ—¥ä»¥ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®è¿›è¡Œæ¯”è¾ƒ
    trading_dates = get_previous_trading_dates(end_date, days=5)
    
    if len(trading_dates) < 1:
        print(f"è­¦å‘Šï¼šæ— æ³•è·å–äº¤æ˜“æ—¥ï¼Œend_date={end_date}", file=sys.stderr)
        return pd.DataFrame()
    
    # ç¡®ä¿è·å–åˆ°çš„äº¤æ˜“æ—¥ä¸é‡å¤ï¼ˆä¿æŒé¡ºåºï¼‰
    trading_dates = list(dict.fromkeys([str(d) for d in trading_dates]))
    
    print(f"è°ƒè¯•ï¼šè·å–åˆ°çš„äº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆå»é‡åï¼‰={trading_dates}", file=sys.stderr)
    
    # trading_dates[0] åº”è¯¥æ˜¯æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼ˆå¯èƒ½æ˜¯end_dateï¼Œä¹Ÿå¯èƒ½æ˜¯end_dateä¹‹å‰çš„äº¤æ˜“æ—¥ï¼‰
    current_date = str(trading_dates[0])  # å½“å¤©ï¼ˆæœ€è¿‘çš„äº¤æ˜“æ—¥ï¼‰ï¼Œç¡®ä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„äº¤æ˜“æ—¥
    if len(trading_dates) < 2:
        print(f"è­¦å‘Šï¼šåªèƒ½è·å–åˆ°1ä¸ªäº¤æ˜“æ—¥ï¼Œæ— æ³•è®¡ç®—æ’åå˜åŒ–", file=sys.stderr)
        yesterday_date = None
        day_before_yesterday_date = None
    else:
        # ä½¿ç”¨ç¬¬2ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå¯¹æ¯”æ—¥æœŸ1ï¼ˆå‰1ä¸ªäº¤æ˜“æ—¥ï¼‰
        yesterday_date = str(trading_dates[1]) if len(trading_dates) > 1 else None
        # ä½¿ç”¨ç¬¬3ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå¯¹æ¯”æ—¥æœŸ2ï¼ˆå‰2ä¸ªäº¤æ˜“æ—¥ï¼‰
        # å¦‚æœåªæœ‰2ä¸ªäº¤æ˜“æ—¥ï¼Œday_before_yesterday_date å°†ä¸º None
        day_before_yesterday_date = str(trading_dates[2]) if len(trading_dates) > 2 else None
    
    # éªŒè¯æ—¥æœŸä¸é‡å¤
    if current_date == yesterday_date:
        print(f"é”™è¯¯ï¼šå½“å‰æ—¥æœŸå’Œæ˜¨å¤©æ—¥æœŸç›¸åŒï¼current_date={current_date}, yesterday_date={yesterday_date}", file=sys.stderr)
        print(f"è°ƒè¯•ï¼šäº¤æ˜“æ—¥åˆ—è¡¨={trading_dates}, end_date={end_date}", file=sys.stderr)
        # å¦‚æœæ—¥æœŸé‡å¤ï¼Œå°è¯•è·å–æ›´å¤šäº¤æ˜“æ—¥
        more_dates = get_previous_trading_dates(end_date, days=10)
        more_dates = list(dict.fromkeys([str(d) for d in more_dates]))  # å»é‡
        if len(more_dates) >= 2 and more_dates[0] != more_dates[1]:
            current_date = str(more_dates[0])
            yesterday_date = str(more_dates[1]) if len(more_dates) > 1 else None
            day_before_yesterday_date = str(more_dates[2]) if len(more_dates) > 2 else None
            print(f"è°ƒè¯•ï¼šé‡æ–°è·å–äº¤æ˜“æ—¥ - å½“å¤©={current_date}, æ˜¨å¤©={yesterday_date}, å‰å¤©={day_before_yesterday_date}", file=sys.stderr)
        else:
            print(f"é”™è¯¯ï¼šæ— æ³•è·å–è¶³å¤Ÿçš„äº¤æ˜“æ—¥è¿›è¡Œæ¯”è¾ƒï¼Œmore_dates={more_dates}", file=sys.stderr)
            yesterday_date = None
            day_before_yesterday_date = None
    
    # å¦‚æœend_dateæ˜¯å‘¨æœ«ï¼Œcurrent_dateä¼šæ˜¯æœ€è¿‘çš„äº¤æ˜“æ—¥ï¼Œç»™å‡ºæç¤º
    if current_date != end_date:
        print(f"è°ƒè¯•ï¼šend_date={end_date}ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥={current_date}", file=sys.stderr)
    
    print(f"è°ƒè¯•ï¼šäº¤æ˜“æ—¥ - å½“å¤©={current_date}, æ˜¨å¤©={yesterday_date}, å‰å¤©={day_before_yesterday_date}", file=sys.stderr)
    
    # è®¡ç®—å½“å¤©æ’å
    try:
        df_current = rank_sectors_alpha(sector_codes, benchmark_code, current_date)
        if df_current.empty:
            print(f"è­¦å‘Šï¼šæ— æ³•è·å–å½“å¤©æ’åï¼Œcurrent_date={current_date}", file=sys.stderr)
            print(f"æç¤ºï¼šå¯èƒ½æ˜¯APIé™æµæˆ–ç½‘ç»œé—®é¢˜ï¼Œè¯·ç¨åé‡è¯•", file=sys.stderr)
            return pd.DataFrame()
        
        print(f"è°ƒè¯•ï¼šå½“å¤©æ’åè·å–æˆåŠŸï¼Œå…±{len(df_current)}ä¸ªè¡Œä¸š", file=sys.stderr)
    except Exception as e:
        print(f"é”™è¯¯ï¼šè·å–å½“å¤©æ’åæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}", file=sys.stderr)
        import traceback
        print(traceback.format_exc(), file=sys.stderr)
        return pd.DataFrame()
    
    # è®¡ç®—æ˜¨å¤©æ’åï¼ˆæ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™æµï¼‰
    df_yesterday = pd.DataFrame()
    if yesterday_date:
        try:
            import time
            time.sleep(0.5)  # å»¶è¿Ÿ0.5ç§’ï¼Œé¿å…APIé™æµ
            df_yesterday = rank_sectors_alpha(sector_codes, benchmark_code, yesterday_date)
            if df_yesterday.empty:
                print(f"è­¦å‘Šï¼šæ— æ³•è·å–æ˜¨å¤©æ’åï¼Œyesterday_date={yesterday_date}", file=sys.stderr)
            else:
                print(f"è°ƒè¯•ï¼šæ˜¨å¤©æ’åè·å–æˆåŠŸï¼Œå…±{len(df_yesterday)}ä¸ªè¡Œä¸š", file=sys.stderr)
        except Exception as e:
            print(f"è­¦å‘Šï¼šè·å–æ˜¨å¤©æ’åæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}", file=sys.stderr)
            df_yesterday = pd.DataFrame()
    
    # è®¡ç®—å‰å¤©æ’åï¼ˆæ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™æµï¼‰
    df_day_before = pd.DataFrame()
    if day_before_yesterday_date:
        try:
            import time
            time.sleep(0.5)  # å»¶è¿Ÿ0.5ç§’ï¼Œé¿å…APIé™æµ
            df_day_before = rank_sectors_alpha(sector_codes, benchmark_code, day_before_yesterday_date)
            if df_day_before.empty:
                print(f"è­¦å‘Šï¼šæ— æ³•è·å–å‰å¤©æ’åï¼Œday_before_yesterday_date={day_before_yesterday_date}", file=sys.stderr)
                print(f"æç¤ºï¼šå¯èƒ½æ˜¯è¯¥æ—¥æœŸæ•°æ®å°šæœªæ›´æ–°æˆ–APIé™æµï¼Œéƒ¨åˆ†è¡Œä¸šå°†æ— æ³•æ˜¾ç¤ºæ’åå˜åŒ–", file=sys.stderr)
            else:
                print(f"è°ƒè¯•ï¼šå‰å¤©æ’åè·å–æˆåŠŸï¼Œå…±{len(df_day_before)}ä¸ªè¡Œä¸š", file=sys.stderr)
                # æ£€æŸ¥è·å–åˆ°çš„è¡Œä¸šæ•°é‡æ˜¯å¦è¶³å¤Ÿ
                if len(df_day_before) < len(sector_codes) * 0.8:  # å¦‚æœè·å–åˆ°çš„è¡Œä¸šå°‘äº80%ï¼Œç»™å‡ºè­¦å‘Š
                    print(f"è­¦å‘Šï¼šå‰å¤©æ’åæ•°æ®ä¸å®Œæ•´ï¼Œä»…è·å–åˆ°{len(df_day_before)}/{len(sector_codes)}ä¸ªè¡Œä¸š", file=sys.stderr)
        except Exception as e:
            print(f"è­¦å‘Šï¼šè·å–å‰å¤©æ’åæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}", file=sys.stderr)
            import traceback
            print(traceback.format_exc(), file=sys.stderr)
            df_day_before = pd.DataFrame()
    
    # åˆå¹¶æ•°æ®
    result_df = df_current[['sector_code', 'score', 'rank']].copy()
    result_df.rename(columns={'score': 'current_alpha', 'rank': 'current_rank'}, inplace=True)
    
    # åˆ›å»ºæ’åæ˜ å°„å­—å…¸
    rank_map_yesterday = {}
    if not df_yesterday.empty:
        rank_map_yesterday = dict(zip(df_yesterday['sector_code'], df_yesterday['rank']))
        print(f"è°ƒè¯•ï¼šæ˜¨å¤©æ’åæ˜ å°„åŒ…å«{len(rank_map_yesterday)}ä¸ªè¡Œä¸š", file=sys.stderr)
    
    rank_map_day_before = {}
    if not df_day_before.empty:
        rank_map_day_before = dict(zip(df_day_before['sector_code'], df_day_before['rank']))
        print(f"è°ƒè¯•ï¼šå‰å¤©æ’åæ˜ å°„åŒ…å«{len(rank_map_day_before)}ä¸ªè¡Œä¸š", file=sys.stderr)
    
    # è®¡ç®—æ’åå˜åŒ–
    rank_change_1d = []
    rank_change_2d = []
    
    for sector_code in result_df['sector_code']:
        current_rank = result_df[result_df['sector_code'] == sector_code]['current_rank'].iloc[0]
        
        # è®¡ç®—ç›¸è¾ƒæ˜¨æ—¥ä¸Šå‡ä½æ•°
        if sector_code in rank_map_yesterday:
            yesterday_rank = rank_map_yesterday[sector_code]
            change_1d = yesterday_rank - current_rank  # æ­£æ•°è¡¨ç¤ºä¸Šå‡
        else:
            change_1d = None
            # è°ƒè¯•ä¿¡æ¯ï¼šå¦‚æœè¡Œä¸šåœ¨å½“å¤©æ’åä¸­ä½†ä¸åœ¨æ˜¨å¤©æ’åä¸­
            if not df_yesterday.empty:
                print(f"è°ƒè¯•ï¼šè¡Œä¸š{sector_code}åœ¨å½“å¤©æ’åä¸­ä½†ä¸åœ¨æ˜¨å¤©æ’åä¸­", file=sys.stderr)
        
        # è®¡ç®—ç›¸è¾ƒå‰å¤©ä¸Šå‡ä½æ•°
        if sector_code in rank_map_day_before:
            day_before_rank = rank_map_day_before[sector_code]
            change_2d = day_before_rank - current_rank  # æ­£æ•°è¡¨ç¤ºä¸Šå‡
        else:
            change_2d = None
            # è°ƒè¯•ä¿¡æ¯ï¼šå¦‚æœè¡Œä¸šåœ¨å½“å¤©æ’åä¸­ä½†ä¸åœ¨å‰å¤©æ’åä¸­
            if not df_day_before.empty:
                print(f"è°ƒè¯•ï¼šè¡Œä¸š{sector_code}åœ¨å½“å¤©æ’åä¸­ä½†ä¸åœ¨å‰å¤©æ’åä¸­ï¼ˆday_before_yesterday_date={day_before_yesterday_date}ï¼‰", file=sys.stderr)
            elif day_before_yesterday_date:
                # å¦‚æœå‰å¤©æ’åæ•°æ®ä¸ºç©ºï¼Œè¯´æ˜è·å–å¤±è´¥
                print(f"è°ƒè¯•ï¼šæ— æ³•è·å–{day_before_yesterday_date}çš„æ’åæ•°æ®ï¼Œè¡Œä¸š{sector_code}çš„æ’åå˜åŒ–æ— æ³•è®¡ç®—", file=sys.stderr)
        
        rank_change_1d.append(change_1d)
        rank_change_2d.append(change_2d)
    
    result_df['rank_change_1d'] = rank_change_1d
    result_df['rank_change_2d'] = rank_change_2d
    
    # ç»Ÿè®¡æœ‰æ’åå˜åŒ–æ•°æ®çš„è¡Œä¸šæ•°é‡
    has_1d_data = sum(1 for x in rank_change_1d if x is not None)
    has_2d_data = sum(1 for x in rank_change_2d if x is not None)
    print(f"è°ƒè¯•ï¼šæ’åå˜åŒ–ç»Ÿè®¡ - æœ‰1æ—¥æ•°æ®ï¼š{has_1d_data}/{len(result_df)}, æœ‰2æ—¥æ•°æ®ï¼š{has_2d_data}/{len(result_df)}", file=sys.stderr)
    
    # å°†æ—¥æœŸä¿¡æ¯æ·»åŠ åˆ°DataFrameçš„å…ƒæ•°æ®ä¸­
    # ä½¿ç”¨attrså±æ€§ï¼ˆpandas 1.3.0+æ”¯æŒï¼‰
    if not hasattr(result_df, 'attrs'):
        result_df.attrs = {}
    result_df.attrs['current_date'] = current_date
    result_df.attrs['yesterday_date'] = yesterday_date
    result_df.attrs['day_before_yesterday_date'] = day_before_yesterday_date
    
    print(f"è°ƒè¯•ï¼šæ—¥æœŸä¿¡æ¯å·²æ·»åŠ åˆ°DataFrame - current_date={current_date}, yesterday_date={yesterday_date}, day_before_yesterday_date={day_before_yesterday_date}", file=sys.stderr)
    
    return result_df

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    token = get_tushare_token()
    if token:
        ts.set_token(token)
        
        # ç”³ä¸‡ä¸€çº§è¡Œä¸šä»£ç 
        sector_codes = [
            "801010.SI", "801030.SI", "801040.SI", "801050.SI", "801080.SI",
            "801110.SI", "801120.SI", "801130.SI", "801140.SI", "801150.SI",
            "801160.SI", "801170.SI", "801180.SI", "801200.SI", "801210.SI",
            "801230.SI", "801710.SI", "801720.SI", "801730.SI", "801740.SI",
            "801750.SI", "801760.SI", "801770.SI", "801780.SI", "801790.SI",
            "801880.SI", "801890.SI", "801950.SI", "801960.SI", "801970.SI",
            "801980.SI"
        ]
        
        # åˆ†ææ‰€æœ‰æ¿å—
        df = rank_sectors_alpha(sector_codes)
        print(format_alpha_analysis(df))

