"""ä¸­è§‚å…¨å‘¨æœŸæ‰«æ MCP å·¥å…· (Meso 2.5 Analysis)

è¯¥æ¨¡å—æä¾›æ¦‚å¿µæ¿å—ä¸­è§‚åˆ†æå·¥å…·ï¼Œç»¼åˆåˆ†æä¸»çº¿å®šä½ã€å‡¤å‡°ç­–ç•¥å’Œèµ„é‡‘éªŒä¼ªã€‚

åˆ†æç»´åº¦:
- æ¨¡å—Aï¼šä¸»çº¿å®šä½ - Alphaæ’å + æ¶¨åœæ¢¯é˜Ÿ + å‘¨æœŸå®šä½
- æ¨¡å—Bï¼šå‡¤å‡°ç­–ç•¥ - è¶…è·Œåå¼¹æœºä¼š
- æ¨¡å—Cï¼šèµ„é‡‘éªŒä¼ª - ä¸»åŠ›èµ„é‡‘æµå‘éªŒè¯
"""
import tushare as ts
import pandas as pd
import json
import re
from datetime import datetime, timedelta
from typing import TYPE_CHECKING, Optional, Dict, Any, List, Tuple
from config.token_manager import get_tushare_token
from cache.cache_manager import cache_manager

if TYPE_CHECKING:
    from mcp.server.fastmcp import FastMCP


def register_meso_scan_tools(mcp: "FastMCP"):
    """æ³¨å†Œä¸­è§‚å…¨å‘¨æœŸæ‰«æå·¥å…·"""
    
    @mcp.tool()
    def meso_scan(
        trade_date: str = "",
        top_n: int = 20,
        price_change_5d_max: float = -0.05,
        vol_ratio_threshold: float = 1.3,
        outflow_warning: float = 1.0,
        limit_up_threshold: int = 5
    ) -> str:
        """
        ä¸­è§‚å…¨å‘¨æœŸæ‰«æ (Meso 2.5 Analysis) - æ¦‚å¿µæ¿å—ç»¼åˆåˆ†æ
        
        å‚æ•°:
            trade_date: åˆ†ææ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥ï¼‰
            top_n: Alphaæ’åå–å‰Nä¸ªæ¦‚å¿µï¼ˆé»˜è®¤20ï¼‰
            price_change_5d_max: å‡¤å‡°ç­–ç•¥ï¼šè¿‘5æ—¥è·Œå¹…é˜ˆå€¼ï¼ˆé»˜è®¤-0.05å³-5%ï¼‰
            vol_ratio_threshold: å‡¤å‡°ç­–ç•¥ï¼šä»Šæ—¥æ”¾é‡é˜ˆå€¼ï¼ˆé»˜è®¤1.3ï¼‰
            outflow_warning: èµ„é‡‘èƒŒç¦»ï¼šä¸»åŠ›å‡€æµå‡ºè­¦æˆ’çº¿ï¼ˆäº¿å…ƒï¼Œé»˜è®¤1.0ï¼‰
            limit_up_threshold: æ¶¨åœå®¶æ•°åˆ†ç•Œé˜ˆå€¼ï¼ˆé»˜è®¤5å®¶ï¼‰
        
        è¿”å›:
            åŒ…å«ä¸‰ä¸ªåˆ†ææ¨¡å—çš„ä¸­è§‚å…¨å‘¨æœŸæ‰«ææŠ¥å‘Š
        
        åˆ†ææ¨¡å—:
            A. ä¸»çº¿å®šä½ - Alphaæ’åã€æ’åå˜åŒ–ã€æ¶¨åœæ¢¯é˜Ÿã€å‘¨æœŸçŠ¶æ€
            B. å‡¤å‡°ç­–ç•¥ - è¶…è·Œåå¼¹æœºä¼šï¼ˆè¿‘5æ—¥ä¸‹è·Œ+ä»Šæ—¥æ”¾é‡ï¼‰
            C. èµ„é‡‘éªŒä¼ª - ä¸»åŠ›èµ„é‡‘æµå‘éªŒè¯ï¼Œå‰”é™¤èƒŒç¦»æ¿å—
        
        è¯´æ˜:
            - è¯­ä¹‰å½’ç±»ï¼ˆå¦‚Sora/Kimiâ†’AIåº”ç”¨ï¼‰è¯·åœ¨AIå¯¹è¯å±‚å®Œæˆ
            - æœ¬å·¥å…·è¿”å›åŸå§‹æ•°æ®åˆ—è¡¨ï¼Œä¾¿äºAIè¿›è¡Œæ™ºèƒ½å½’ç±»
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        try:
            # ç¡®å®šåˆ†ææ—¥æœŸ
            if not trade_date:
                trade_date = _get_latest_trade_date()
            
            # æ‰§è¡Œä¸‰ä¸ªåˆ†ææ¨¡å—
            mainline_result = _analyze_mainline_lifecycle(trade_date, top_n, limit_up_threshold)
            phoenix_result = _analyze_phoenix_rebound(trade_date, price_change_5d_max, vol_ratio_threshold)
            money_result = _analyze_money_validation(trade_date, mainline_result, phoenix_result, outflow_warning)
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            report = _format_meso_scan_report(
                trade_date,
                mainline_result,
                phoenix_result,
                money_result,
                top_n
            )
            
            return report
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"ä¸­è§‚å…¨å‘¨æœŸæ‰«æå¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"


def _get_latest_trade_date() -> str:
    """è·å–æœ€æ–°äº¤æ˜“æ—¥"""
    today = datetime.now()
    # å¦‚æœæ˜¯å‘¨æœ«ï¼Œå›é€€åˆ°å‘¨äº”
    while today.weekday() >= 5:
        today -= timedelta(days=1)
    return today.strftime("%Y%m%d")


def _clean_concept_name(name: str) -> str:
    """
    æ¸…æ´—æ¦‚å¿µæ¿å—åç§°ï¼Œç”¨äºè·¨æ•°æ®æºåŒ¹é…
    
    å¤„ç†:
    1. å»æ‰"æ¦‚å¿µ"ã€"æ¿å—"ã€"æŒ‡æ•°"åç¼€
    2. å»é™¤æ‹¬å·åŠæ‹¬å·å†…å®¹
    3. å»é™¤ç©ºæ ¼
    """
    if not name:
        return ""
    # å»æ‰å¸¸è§åç¼€
    for suffix in ["æ¦‚å¿µ", "æ¿å—", "æŒ‡æ•°"]:
        name = name.replace(suffix, "")
    # å»æ‰æ‹¬å·å†…å®¹
    name = re.sub(r'[ï¼ˆ\(].*?[ï¼‰\)]', '', name)
    return name.strip()


def _analyze_mainline_lifecycle(trade_date: str, top_n: int, limit_up_threshold: int) -> Dict[str, Any]:
    """
    æ¨¡å—A: ä¸»çº¿å®šä½ (Mainline & Lifecycle)
    
    æ•°æ®è·å–:
    1. rank_concepts_by_alpha â†’ Top N Alpha æ¦‚å¿µ
    2. rank_concepts_alpha_velocity â†’ æ’åå˜åŒ–
    3. get_limit_cpt_list â†’ æ¶¨åœæ¢¯é˜Ÿ
    
    ä½¿ç”¨æ¿å—åç§°ä½œä¸º Join Key è§£å†³æ•°æ®æºå¼‚æ„é—®é¢˜
    """
    result = {
        "success": False,
        "concepts": [],
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        
        # 1. è·å– Top N Alpha æ¦‚å¿µæ¿å—ï¼ˆä¸œè´¢ä½“ç³»ï¼‰
        from tools.concept_tools import get_hot_concept_codes, rank_sectors_alpha
        
        concept_codes = get_hot_concept_codes(trade_date, limit=80)
        if not concept_codes:
            result["error"] = "æ— æ³•è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨"
            return result
        
        alpha_df = rank_sectors_alpha(concept_codes, "000300.SH", trade_date)
        if alpha_df.empty:
            result["error"] = "æ— æ³•è·å–Alphaæ’åæ•°æ®"
            return result
        
        # å–å‰ top_n å
        alpha_df = alpha_df.head(top_n)
        
        # è·å–æ¿å—åç§°
        try:
            concept_codes_str = ','.join(alpha_df['sector_code'].tolist())
            name_df = pro.dc_index(ts_code=concept_codes_str, trade_date=trade_date)
            name_map = {}
            if not name_df.empty:
                for _, row in name_df.iterrows():
                    name_map[row['ts_code']] = row.get('name', row['ts_code'])
            alpha_df['name'] = alpha_df['sector_code'].map(name_map).fillna(alpha_df['sector_code'])
        except Exception:
            alpha_df['name'] = alpha_df['sector_code']
        
        # 2. è·å–æ’åå˜åŒ–ï¼ˆå°è¯•è·å–å†å²æ’åå¯¹æ¯”ï¼‰
        from tools.concept_tools import calculate_alpha_rank_velocity
        try:
            velocity_df = calculate_alpha_rank_velocity(concept_codes, "000300.SH", trade_date)
            if not velocity_df.empty:
                velocity_map = dict(zip(velocity_df['sector_code'], velocity_df['rank_change_1d']))
            else:
                velocity_map = {}
        except Exception:
            velocity_map = {}
        
        alpha_df['rank_change'] = alpha_df['sector_code'].map(velocity_map).fillna(0)
        
        # 3. è·å–æ¶¨åœæ¢¯é˜Ÿï¼ˆTushareä½“ç³»ï¼‰
        try:
            limit_df = pro.limit_cpt_list(trade_date=trade_date)
            if limit_df is not None and not limit_df.empty:
                # æ¸…æ´—åç§°ç”¨äºåŒ¹é…
                limit_df['clean_name'] = limit_df['name'].apply(_clean_concept_name)
                limit_name_map = dict(zip(limit_df['clean_name'], limit_df['limit_up_num']))
            else:
                limit_name_map = {}
        except Exception:
            limit_name_map = {}
        
        # 4. åŒ¹é…æ¶¨åœå®¶æ•°ï¼ˆä½¿ç”¨æ¸…æ´—åçš„åç§°ï¼‰
        alpha_df['clean_name'] = alpha_df['name'].apply(_clean_concept_name)
        alpha_df['limit_up_count'] = alpha_df['clean_name'].map(limit_name_map).fillna(0).astype(int)
        
        # 5. å‘¨æœŸå®šä½
        concepts = []
        for _, row in alpha_df.iterrows():
            rank_change = row.get('rank_change', 0)
            limit_up_count = row.get('limit_up_count', 0)
            
            # å‘¨æœŸå®šä½çŸ©é˜µ
            rank_up = rank_change > 0 if pd.notna(rank_change) else False
            limit_high = limit_up_count >= limit_up_threshold
            
            if rank_up and limit_high:
                status = "ğŸ”¥ [é«˜æ½®æœŸ]"
            elif rank_up and not limit_high:
                status = "ğŸš€ [å¯åŠ¨æœŸ]"
            elif not rank_up and limit_high:
                status = "âš¡ [åˆ†æ­§æ»æ¶¨]"
            else:
                status = "â„ï¸ [é€€æ½®æœŸ]"
            
            concepts.append({
                "code": row['sector_code'],
                "name": row['name'],
                "alpha": row['score'] * 100 if pd.notna(row.get('score')) else 0,
                "rank_change": int(rank_change) if pd.notna(rank_change) else 0,
                "limit_up_count": int(limit_up_count),
                "status": status
            })
        
        result["success"] = True
        result["concepts"] = concepts
        
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _analyze_phoenix_rebound(trade_date: str, price_change_5d_max: float, vol_ratio_threshold: float) -> Dict[str, Any]:
    """
    æ¨¡å—B: å‡¤å‡°ç­–ç•¥ (Phoenix Rebound)
    
    ç­›é€‰"è·Œæ— å¯è·Œä¸”èµ„é‡‘å›æµ"çš„æ¿å—
    """
    result = {
        "success": False,
        "rebounds": [],
        "error": None
    }
    
    try:
        from tools.concept_tools import scan_concept_volume_anomaly
        
        # æ‰«æè¶…è·Œåå¼¹æœºä¼š
        scan_result = scan_concept_volume_anomaly(
            end_date=trade_date,
            vol_ratio_threshold=vol_ratio_threshold,
            price_change_5d_min=-0.30,  # æ’é™¤æš´è·Œè¶…30%çš„
            price_change_5d_max=price_change_5d_max,  # è¿‘5æ—¥ä¸‹è·Œ
            hot_limit=100
        )
        
        if scan_result and scan_result.get('matched_count', 0) > 0:
            for match in scan_result.get('matches', []):
                result["rebounds"].append({
                    "code": match.get('concept_code', ''),
                    "name": match.get('concept_name', ''),
                    "price_change_5d": match.get('price_change_5d', 0) * 100,
                    "vol_ratio": match.get('vol_ratio', 0),
                    "turnover_rate": match.get('turnover_rate', 0)
                })
            result["success"] = True
        else:
            # æ²¡æœ‰åŒ¹é…ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ¥è¿‘çš„
            closest = scan_result.get('closest_results', [])
            if closest:
                for item in closest[:5]:
                    result["rebounds"].append({
                        "code": item.get('concept_code', ''),
                        "name": item.get('concept_name', ''),
                        "price_change_5d": item.get('price_change_5d', 0) * 100,
                        "vol_ratio": item.get('vol_ratio', 0),
                        "turnover_rate": item.get('turnover_rate', 0),
                        "note": "æ¥è¿‘é˜ˆå€¼"
                    })
            result["success"] = True
            result["note"] = "æ— å®Œå…¨ç¬¦åˆæ¡ä»¶çš„æ¿å—ï¼Œå±•ç¤ºæœ€æ¥è¿‘çš„å€™é€‰"
            
    except Exception as e:
        result["error"] = str(e)
        result["success"] = True  # å³ä½¿å¤±è´¥ä¹Ÿä¸å½±å“å…¶ä»–æ¨¡å—
    
    return result


def _analyze_money_validation(
    trade_date: str,
    mainline_result: Dict[str, Any],
    phoenix_result: Dict[str, Any],
    outflow_warning: float
) -> Dict[str, Any]:
    """
    æ¨¡å—C: èµ„é‡‘éªŒä¼ª (Money Validation)
    
    æ‰¹é‡è·å–å…¨å¸‚åœºèµ„é‡‘æµå‘ï¼Œå†…å­˜è¿‡æ»¤åŒ¹é…
    """
    result = {
        "success": False,
        "warnings": [],
        "golden_list": [],
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        
        # æ‰¹é‡è·å–å½“æ—¥å…¨å¸‚åœºèµ„é‡‘æµå‘ï¼ˆä¸ä¼  ts_codeï¼‰
        cache_params = {'trade_date': trade_date, 'content_type': 'æ¦‚å¿µ'}
        moneyflow_df = cache_manager.get_dataframe('moneyflow_ind_dc', **cache_params)
        
        if moneyflow_df is None or cache_manager.is_expired('moneyflow_ind_dc', **cache_params):
            try:
                moneyflow_df = pro.moneyflow_ind_dc(trade_date=trade_date, content_type='æ¦‚å¿µ')
                if moneyflow_df is not None and not moneyflow_df.empty:
                    cache_manager.set('moneyflow_ind_dc', moneyflow_df, **cache_params)
            except Exception:
                moneyflow_df = None
        
        if moneyflow_df is None or moneyflow_df.empty:
            result["success"] = True
            result["note"] = "æ— æ³•è·å–èµ„é‡‘æµå‘æ•°æ®"
            # ç›´æ¥è¿”å›æ‰€æœ‰ä¸»çº¿ä½œä¸ºé»„é‡‘åˆ—è¡¨
            if mainline_result.get("success"):
                result["golden_list"] = mainline_result.get("concepts", [])[:10]
            return result
        
        # æ¸…æ´—èµ„é‡‘æµå‘æ•°æ®çš„åç§°ç”¨äºåŒ¹é…
        moneyflow_df['clean_name'] = moneyflow_df['name'].apply(_clean_concept_name)
        
        # åˆ›å»ºèµ„é‡‘æµå‘æ˜ å°„ (ä¸»åŠ›å‡€æµå…¥ï¼Œå•ä½ï¼šä¸‡å…ƒ -> äº¿å…ƒ)
        moneyflow_map = {}
        for _, row in moneyflow_df.iterrows():
            clean_name = row['clean_name']
            # net_mf_amount æ˜¯ä¸»åŠ›å‡€æµå…¥é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰
            net_inflow = row.get('net_mf_amount', 0)
            if pd.notna(net_inflow):
                moneyflow_map[clean_name] = net_inflow / 10000  # è½¬æ¢ä¸ºäº¿å…ƒ
        
        # éªŒè¯ä¸»çº¿æ¿å—
        warnings = []
        golden_list = []
        
        if mainline_result.get("success"):
            for concept in mainline_result.get("concepts", []):
                clean_name = _clean_concept_name(concept.get("name", ""))
                net_inflow = moneyflow_map.get(clean_name, 0)
                concept["net_inflow"] = net_inflow
                
                status = concept.get("status", "")
                # èƒŒç¦»æ£€æµ‹ï¼šå¯åŠ¨æœŸæˆ–é«˜æ½®æœŸï¼Œä½†ä¸»åŠ›å‡€æµå‡ºè¶…è¿‡é˜ˆå€¼
                is_positive_phase = "[é«˜æ½®æœŸ]" in status or "[å¯åŠ¨æœŸ]" in status
                is_outflow = net_inflow < -outflow_warning
                
                if is_positive_phase and is_outflow:
                    concept["warning"] = f"ä¸»åŠ›å‡€æµå‡º {abs(net_inflow):.1f} äº¿"
                    warnings.append(concept)
                else:
                    golden_list.append(concept)
        
        # éªŒè¯å‡¤å‡°ç­–ç•¥æ¿å—
        if phoenix_result.get("success"):
            for rebound in phoenix_result.get("rebounds", []):
                clean_name = _clean_concept_name(rebound.get("name", ""))
                net_inflow = moneyflow_map.get(clean_name, 0)
                rebound["net_inflow"] = net_inflow
                rebound["status"] = "âš¡ [è¶…è·Œåå¼¹]"
                
                # è¶…è·Œåå¼¹éœ€è¦æœ‰èµ„é‡‘æµå…¥
                if net_inflow > 0:
                    golden_list.append(rebound)
        
        result["success"] = True
        result["warnings"] = warnings
        result["golden_list"] = golden_list[:15]  # æœ€å¤šå±•ç¤º15ä¸ª
        
    except Exception as e:
        result["error"] = str(e)
        result["success"] = True
    
    return result


def _format_meso_scan_report(
    trade_date: str,
    mainline_result: Dict[str, Any],
    phoenix_result: Dict[str, Any],
    money_result: Dict[str, Any],
    top_n: int
) -> str:
    """æ ¼å¼åŒ–ä¸­è§‚å…¨å‘¨æœŸæ‰«ææŠ¥å‘Š"""
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    formatted_date = f"{trade_date[:4]}-{trade_date[4:6]}-{trade_date[6:8]}" if len(trade_date) == 8 else trade_date
    
    lines = []
    lines.append("ğŸ“Š ä¸­è§‚å…¨å‘¨æœŸæ‰«ææŠ¥å‘Š (Meso 2.5 Analysis)")
    lines.append("=" * 60)
    lines.append(f"ğŸ“… åˆ†ææ—¥æœŸ: {formatted_date}")
    lines.append("")
    
    # æ¨¡å—A: ä¸»çº¿å®šä½
    lines.append("ã€æ¨¡å—Aï¼šä¸»çº¿å®šä½ã€‘")
    lines.append("â”" * 60)
    
    if mainline_result.get("success") and mainline_result.get("concepts"):
        lines.append(f"ğŸ“‹ Top {top_n} Alpha æ¦‚å¿µæ¿å—ï¼ˆè¯· AI è¿›è¡Œè¯­ä¹‰å½’ç±»ï¼‰:")
        lines.append("")
        lines.append("| æ’å | æ¦‚å¿µåç§°         | Alpha    | æ’åå˜åŒ– | æ¶¨åœæ•° | çŠ¶æ€          |")
        lines.append("|-----|-----------------|----------|---------|-------|---------------|")
        
        for i, concept in enumerate(mainline_result["concepts"], 1):
            name = concept.get("name", "")[:12]
            alpha = f"{concept.get('alpha', 0):+.2f}%"
            rank_change = concept.get("rank_change", 0)
            rank_str = f"{rank_change:+d}" if rank_change != 0 else "0"
            if rank_change > 0:
                rank_str += " â¬†ï¸"
            elif rank_change < 0:
                rank_str += " â¬‡ï¸"
            limit_up = concept.get("limit_up_count", 0)
            status = concept.get("status", "")
            
            lines.append(f"| {i:<3} | {name:<15} | {alpha:<8} | {rank_str:<7} | {limit_up:<5} | {status} |")
        
        lines.append("")
        lines.append("ğŸ’¡ æç¤ºï¼šå»ºè®®å°†è¯­ä¹‰ç›¸è¿‘çš„æ¦‚å¿µåˆå¹¶åˆ†æï¼ˆå¦‚ Sora+Kimi â†’ AIåº”ç”¨ï¼‰")
    else:
        lines.append(f"âš ï¸ æ•°æ®è·å–å¤±è´¥: {mainline_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # æ¨¡å—B: å‡¤å‡°ç­–ç•¥
    lines.append("ã€æ¨¡å—Bï¼šå‡¤å‡°ç­–ç•¥ã€‘")
    lines.append("â”" * 60)
    
    if phoenix_result.get("success") and phoenix_result.get("rebounds"):
        if phoenix_result.get("note"):
            lines.append(f"ğŸ“Œ {phoenix_result['note']}")
        else:
            lines.append("âš¡ã€è¶…è·Œåå¼¹å…³æ³¨ã€‘(é€‚åˆä½å¸)")
        lines.append("")
        lines.append("| æ¿å—åç§°         | 5æ—¥è·Œå¹…  | ä»Šæ—¥é‡æ¯” | æ¢æ‰‹ç‡  |")
        lines.append("|-----------------|---------|---------|--------|")
        
        for rebound in phoenix_result["rebounds"][:10]:
            name = rebound.get("name", "")[:12]
            price_chg = f"{rebound.get('price_change_5d', 0):.1f}%"
            vol_ratio = f"{rebound.get('vol_ratio', 0):.2f}"
            turnover = f"{rebound.get('turnover_rate', 0):.1f}%"
            
            lines.append(f"| {name:<15} | {price_chg:<7} | {vol_ratio:<7} | {turnover:<6} |")
    else:
        lines.append("ğŸ“Œ å½“å‰æ— ç¬¦åˆå‡¤å‡°ç­–ç•¥æ¡ä»¶çš„æ¿å—")
    lines.append("")
    
    # æ¨¡å—C: èµ„é‡‘éªŒä¼ª
    lines.append("ã€æ¨¡å—Cï¼šèµ„é‡‘éªŒä¼ªã€‘")
    lines.append("â”" * 60)
    
    if money_result.get("success"):
        # èµ„é‡‘èƒŒç¦»é¢„è­¦
        if money_result.get("warnings"):
            lines.append(f"âš ï¸ èµ„é‡‘èƒŒç¦»é¢„è­¦ (ä¸»åŠ›å‡€æµå‡º > 1äº¿ï¼Œè°¨æ…è¿½é«˜):")
            lines.append("| æ¿å—åç§°         | çŠ¶æ€          | ä¸»åŠ›å‡€æµå‡º  |")
            lines.append("|-----------------|--------------|------------|")
            
            for warn in money_result["warnings"][:5]:
                name = warn.get("name", "")[:12]
                status = warn.get("status", "")
                outflow = f"{abs(warn.get('net_inflow', 0)):.1f} äº¿"
                lines.append(f"| {name:<15} | {status:<12} | {outflow:<10} |")
            lines.append("")
        
        # é»„é‡‘æ¿å—åˆ—è¡¨
        if money_result.get("golden_list"):
            lines.append("âœ… é»„é‡‘æ¿å—åˆ—è¡¨ (èµ„é‡‘éªŒè¯é€šè¿‡):")
            lines.append("| æ¿å—åç§°         | çŠ¶æ€          | Alpha    | ä¸»åŠ›å‡€æµå…¥  |")
            lines.append("|-----------------|--------------|----------|------------|")
            
            for golden in money_result["golden_list"][:10]:
                name = golden.get("name", "")[:12]
                status = golden.get("status", "")
                alpha = f"{golden.get('alpha', 0):+.2f}%" if golden.get('alpha') else "-"
                inflow = golden.get("net_inflow", 0)
                inflow_str = f"{inflow:+.1f} äº¿" if inflow != 0 else "-"
                lines.append(f"| {name:<15} | {status:<12} | {alpha:<8} | {inflow_str:<10} |")
        else:
            lines.append("ğŸ“Œ æ— èµ„é‡‘éªŒè¯é€šè¿‡çš„æ¿å—")
    else:
        lines.append(f"âš ï¸ èµ„é‡‘éªŒè¯å¤±è´¥: {money_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    lines.append("")
    lines.append("=" * 60)
    lines.append("ğŸ“ ä½¿ç”¨è¯´æ˜ï¼š")
    lines.append("  â€¢ [é«˜æ½®æœŸ]: æ’åä¸Šå‡ + æ¶¨åœå¤šï¼Œè€ƒè™‘å…‘ç°")
    lines.append("  â€¢ [å¯åŠ¨æœŸ]: æ’åä¸Šå‡ + æ¶¨åœå°‘ï¼Œå¯å…³æ³¨")
    lines.append("  â€¢ [åˆ†æ­§æ»æ¶¨]: æ’åä¸‹é™ + æ¶¨åœå¤šï¼Œé¾™å¤´æ¶¨åæ’è·Œ")
    lines.append("  â€¢ [é€€æ½®æœŸ]: æ’åä¸‹é™ + æ¶¨åœå°‘ï¼Œå›é¿")
    lines.append("  â€¢ è¯­ä¹‰å½’ç±»è¯·è®© AI æ ¹æ®æ¿å—åç§°æ™ºèƒ½åˆå¹¶")
    
    return "\n".join(lines)
