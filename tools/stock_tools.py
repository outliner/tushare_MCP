"""è‚¡ç¥¨ç›¸å…³MCPå·¥å…·"""
import tushare as ts
import pandas as pd
from typing import TYPE_CHECKING, Optional, List
from datetime import datetime
from config.token_manager import get_tushare_token

if TYPE_CHECKING:
    from mcp.server.fastmcp import FastMCP

from cache.cache_manager import cache_manager
from cache.stock_daily_cache_manager import stock_daily_cache_manager
from cache.stock_weekly_cache_manager import stock_weekly_cache_manager
from cache.index_daily_cache_manager import index_daily_cache_manager
from cache.stk_surv_cache_manager import stk_surv_cache_manager
from cache.cyq_perf_cache_manager import cyq_perf_cache_manager
from cache.daily_basic_cache_manager import daily_basic_cache_manager
from cache.mapping_cache_manager import mapping_cache_manager
from cache.stock_intraday_cache_manager import stock_intraday_cache_manager
from utils.common import format_date

def register_stock_tools(mcp: "FastMCP"):
    """æ³¨å†Œè‚¡ç¥¨ç›¸å…³å·¥å…·"""
    
    @mcp.tool()
    def get_stock_basic_info(ts_code: str = "", name: str = "") -> str:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001.SZï¼‰
            name: è‚¡ç¥¨åç§°ï¼ˆå¦‚ï¼šå¹³å®‰é“¶è¡Œï¼‰
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        try:
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {'ts_code': ts_code, 'name': name}
            df = cache_manager.get_dataframe('stock_basic', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True  # æœªæ‰¾åˆ°æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
            elif cache_manager.is_expired('stock_basic', **cache_params):
                need_update = True  # æ•°æ®è¿‡æœŸï¼Œéœ€è¦æ›´æ–°
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                pro = ts.pro_api()
                filters = {}
                if ts_code:
                    filters['ts_code'] = ts_code
                if name:
                    filters['name'] = name
                    
                df = pro.stock_basic(**filters)
                
                # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                if not df.empty:
                    cache_manager.set('stock_basic', df, **cache_params)
            
            if df.empty:
                return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨"
                
            # æ ¼å¼åŒ–è¾“å‡º
            result = []
            for _, row in df.iterrows():
                # è·å–æ‰€æœ‰å¯ç”¨çš„åˆ—
                available_fields = row.index.tolist()
                
                # æ„å»ºåŸºæœ¬ä¿¡æ¯
                info_parts = []
                
                # å¿…è¦å­—æ®µ
                if 'ts_code' in available_fields:
                    info_parts.append(f"è‚¡ç¥¨ä»£ç : {row['ts_code']}")
                if 'name' in available_fields:
                    info_parts.append(f"è‚¡ç¥¨åç§°: {row['name']}")
                    
                # å¯é€‰å­—æ®µ
                optional_fields = {
                    'area': 'æ‰€å±åœ°åŒº',
                    'industry': 'æ‰€å±è¡Œä¸š',
                    'list_date': 'ä¸Šå¸‚æ—¥æœŸ',
                    'market': 'å¸‚åœºç±»å‹',
                    'exchange': 'äº¤æ˜“æ‰€',
                    'curr_type': 'å¸ç§',
                    'list_status': 'ä¸Šå¸‚çŠ¶æ€',
                    'delist_date': 'é€€å¸‚æ—¥æœŸ'
                }
                
                for field, label in optional_fields.items():
                    if field in available_fields and not pd.isna(row[field]):
                        info_parts.append(f"{label}: {row[field]}")
                
                info = "\n".join(info_parts)
                info += "\n------------------------"
                result.append(info)
                
            return "\n".join(result)
            
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"

    @mcp.tool()
    def collect_stock_sector_mapping() -> str:
        """
        å…¨é‡æ‹‰å–å¹¶å»ºç«‹è‚¡ç¥¨ä¸ç”³ä¸‡äºŒçº§è¡Œä¸šã€ä¸œè´¢è¡Œä¸šã€ä¸œè´¢æ¦‚å¿µçš„æ˜ å°„å…³ç³»
        
        è¯´æ˜ï¼š
        - è¿™æ˜¯ä¸€ä¸ªé‡å‹å·¥å…·ï¼Œä¼šå¤šæ¬¡è¯·æ±‚Tushareå’Œä¸œè´¢æ¥å£
        - ç»“æœä¼šæŒä¹…åŒ–åˆ°æœ¬åœ°æ•°æ®åº“ï¼Œæ”¯æŒåç»­ç­›é€‰å’Œåˆ†æ
        - æ‰§è¡Œæ—¶é—´å¯èƒ½è¾ƒé•¿ï¼ˆå‡ åˆ†é’Ÿåˆ°åå‡ åˆ†é’Ÿä¸ç­‰ï¼‰
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
            
        try:
            pro = ts.pro_api()
            print("ğŸš€ å¼€å§‹å…¨é‡æ˜ å°„é‡‡é›†...", file=__import__('sys').stderr)
            
            # 1. è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            print("ğŸ“¥ æ­£åœ¨è¯»å–è‚¡ç¥¨åˆ—è¡¨...", file=__import__('sys').stderr)
            df_basic = pro.stock_basic(list_status='L', fields='ts_code,name,industry')
            if df_basic.empty:
                return "æœªèƒ½è·å–åˆ°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"
            
            # åˆå§‹åŒ–æ±‡æ€»å­—å…¸
            # stock_map = {ts_code: {name, industry, sw_l2_code, sw_l2_name, em_ind_code, em_ind_name, em_concept_codes: [], em_concept_names: []}}
            stock_map = {}
            for _, row in df_basic.iterrows():
                code = row['ts_code']
                stock_map[code] = {
                    'ts_code': code,
                    'name': row['name'],
                    'sw_l2_code': '',
                    'sw_l2_name': '',
                    'em_industry_code': '',
                    'em_industry_name': '',
                    'em_concept_codes': [],
                    'em_concept_names': []
                }

            # 2. é‡‡é›†ç”³ä¸‡äºŒçº§è¡Œä¸šæ˜ å°„
            print("ğŸ“¥ æ­£åœ¨é‡‡é›†ç”³ä¸‡äºŒçº§è¡Œä¸šæ˜ å°„...", file=__import__('sys').stderr)
            # è·å–æ‰€æœ‰ç”³ä¸‡äºŒçº§è¡Œä¸šåˆ†ç±» (SW2021)
            sw_l2_classify = pro.index_classify(level='L2', src='SW2021')
            if not sw_l2_classify.empty:
                for _, ind in sw_l2_classify.iterrows():
                    l2_code = ind['index_code']
                    l2_name = ind['industry_name']
                    # è·å–è¯¥è¡Œä¸šæˆåˆ†è‚¡
                    try:
                        members = pro.index_member_all(l2_code=l2_code)
                        if members is not None and not members.empty:
                            for _, member in members.iterrows():
                                m_code = member['ts_code']
                                if m_code in stock_map:
                                    stock_map[m_code]['sw_l2_code'] = l2_code
                                    stock_map[m_code]['sw_l2_name'] = l2_name
                    except:
                        continue

            # 3. é‡‡é›†ä¸œè´¢è¡Œä¸šå’Œæ¦‚å¿µæ˜ å°„
            # å¯¼å…¥ç°æœ‰çš„é‡‡é›†å·¥å…·ä»¥ä¿æŒé€»è¾‘ä¸€è‡´
            from tools.concept_tools import get_dc_board_codes
            
            # 3.1 ä¸œè´¢è¡Œä¸š
            print("ğŸ“¥ æ­£åœ¨é‡‡é›†ä¸œè´¢è¡Œä¸šæ¿å—æ˜ å°„...", file=__import__('sys').stderr)
            ind_boards_str = get_dc_board_codes(board_type='è¡Œä¸šæ¿å—')
            # get_dc_board_codes è¿”å›çš„æ˜¯æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬éœ€è¦è§£æå®ƒæˆ–ç›´æ¥è°ƒç”¨æ¥å£
            # ç®€åŒ–èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨æ¥å£è·å–ä»£ç åˆ—è¡¨
            try:
                # pro.dc_index åªæ”¯æŒæ¦‚å¿µï¼Œæˆ‘ä»¬éœ€è¦ç”¨ dc_daily æˆ–å…¶ä»–æ–¹å¼è·å–è¡Œä¸šåˆ—è¡¨
                # å®é™…ä¸Šä» pro.dc_index è·å–æ‰€æœ‰ä»£ç æ›´ç¨³å¦¥
                all_boards = pro.dc_index() # è·å–ä¸œè´¢æ‰€æœ‰æŒ‡æ•°ä¿¡æ¯
                if not all_boards.empty:
                    # è¡Œä¸šæ¿å—
                    industry_boards = all_boards[all_boards['type'] == 'è¡Œä¸š']
                    for _, board in industry_boards.iterrows():
                        b_code = board['ts_code']
                        b_name = board['name']
                        try:
                            m = pro.dc_index_member(ts_code=b_code)
                            if m is not None and not m.empty:
                                for _, member in m.iterrows():
                                    m_code = member['con_code']
                                    if m_code in stock_map:
                                        stock_map[m_code]['em_industry_code'] = b_code
                                        stock_map[m_code]['em_industry_name'] = b_name
                        except:
                            continue
                    
                    # 3.2 ä¸œè´¢æ¦‚å¿µ
                    print("ğŸ“¥ æ­£åœ¨é‡‡é›†ä¸œè´¢æ¦‚å¿µæ¿å—æ˜ å°„...", file=__import__('sys').stderr)
                    concept_boards = all_boards[all_boards['type'] == 'æ¦‚å¿µ']
                    for _, board in concept_boards.iterrows():
                        b_code = board['ts_code']
                        b_name = board['name']
                        try:
                            m = pro.dc_index_member(ts_code=b_code)
                            if m is not None and not m.empty:
                                for _, member in m.iterrows():
                                    m_code = member['con_code']
                                    if m_code in stock_map:
                                        if b_code not in stock_map[m_code]['em_concept_codes']:
                                            stock_map[m_code]['em_concept_codes'].append(b_code)
                                            stock_map[m_code]['em_concept_names'].append(b_name)
                        except:
                            continue
            except Exception as e:
                print(f"é‡‡é›†ä¸œè´¢æ¿å—æ•°æ®å‡ºé”™: {str(e)}", file=__import__('sys').stderr)

            # 4. æ±‡æ€»ä¸å…¥åº“
            print("ğŸ’¾ æ­£åœ¨åŒæ­¥åŒæ­¥åˆ°æœ¬åœ°æ•°æ®åº“...", file=__import__('sys').stderr)
            final_list = list(stock_map.values())
            df_final = pd.DataFrame(final_list)
            
            saved_count = mapping_cache_manager.save_mapping(df_final)
            
            return f"âœ… å…¨é‡æ˜ å°„é‡‡é›†å®Œæˆï¼\n- æ‰«æè‚¡ç¥¨æ€»æ•°: {len(df_basic)}\n- æˆåŠŸå…¥åº“/æ›´æ–°è®°å½•: {saved_count}\n- åŒ…å«ç”³ä¸‡L2ã€ä¸œè´¢è¡Œä¸šåŠæ¦‚å¿µæ¿å—æ˜ å°„æ•°æ®"
            
        except Exception as e:
            import traceback
            return f"âŒ æ˜ å°„é‡‡é›†å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
    
    @mcp.tool()
    def get_stock_sector_mapping(ts_code: str) -> str:
        """
        è·å–å•åªè‚¡ç¥¨çš„ç”³ä¸‡äºŒçº§è¡Œä¸šã€ä¸œè´¢è¡Œä¸šåŠæ¦‚å¿µæ˜ å°„
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600519.SHï¼‰
        """
        try:
            mapping = mapping_cache_manager.get_mapping_by_code(ts_code)
            if not mapping:
                return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {ts_code} çš„æ˜ å°„æ•°æ®ã€‚è¯·å…ˆè¿è¡Œ collect_stock_sector_mapping è¿›è¡ŒåŒæ­¥ã€‚"
            
            result = [
                f"è‚¡ç¥¨: {mapping['name']} ({mapping['ts_code']})",
                f"ç”³ä¸‡äºŒçº§è¡Œä¸š: {mapping['sw_l2_name']} ({mapping['sw_l2_code']})",
                f"ä¸œè´¢è¡Œä¸š: {mapping['em_industry_name']} ({mapping['em_industry_code']})",
                f"ä¸œè´¢æ¦‚å¿µ: {', '.join(mapping['em_concept_names'])}",
                f"æ›´æ–°æ—¶é—´: {datetime.fromtimestamp(mapping['updated_at']).strftime('%Y-%m-%d %H:%M:%S')}"
            ]
            return "\n".join(result)
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥: {str(e)}"

    @mcp.tool()
    def get_stocks_by_sector(sector_code: str, sector_type: str = "em_concept") -> str:
        """
        æ ¹æ®æ¿å—ä»£ç è·å–æ‰€å±çš„æ‰€æœ‰è‚¡ç¥¨
        
        å‚æ•°:
            sector_code: æ¿å—ä»£ç ï¼ˆå¦‚ï¼šBK1184.DC, 801053.SIï¼‰
            sector_type: æ¿å—ç±»å‹ ('sw_l2', 'em_industry', 'em_concept')
        """
        try:
            df = mapping_cache_manager.search_by_sector(sector_type, sector_code)
            if df.empty:
                return f"æœªæ‰¾åˆ°è¯¥æ¿å—ä¸‹çš„è‚¡ç¥¨ã€‚è¯·ç¡®ä¿ä»£ç æ­£ç¡®ä¸”å·²è¿è¡Œ collect_stock_sector_mapping åŒæ­¥ã€‚"
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = [f"### æ¿å— {sector_code} ä¸‹çš„è‚¡ç¥¨åˆ—è¡¨ ({len(df)} åª):\n"]
            result.append("| è‚¡ç¥¨ä»£ç  | è‚¡ç¥¨åç§° | ç”³ä¸‡äºŒçº§ | ä¸œè´¢è¡Œä¸š |")
            result.append("| --- | --- | --- | --- |")
            
            for _, row in df.iterrows():
                result.append(f"| {row['ts_code']} | {row['name']} | {row['sw_l2_name']} | {row['em_industry_name']} |")
                
            return "\n".join(result)
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
    
    @mcp.tool()
    def get_stock_intraday_history(ts_code: str, trade_date: str, trade_time: str) -> str:
        """
        è·å–å•åªè‚¡ç¥¨åœ¨å†å²æŸä¸€æ—¶åˆ»çš„å¿«ç…§æ•°æ®ï¼ˆç”¨äºåŒåˆ»é‡æ¯”è®¡ç®—ï¼‰
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç 
            trade_date: å†å²æ—¥æœŸ (YYYYMMDD)
            trade_time: å†å²æ—¶é—´ (HH:MM:SS)
        """
        try:
            snapshot = stock_intraday_cache_manager.get_historical_snapshot(ts_code, trade_date, trade_time)
            if not snapshot:
                return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {ts_code} åœ¨ {trade_date} {trade_time} ä¹‹å‰çš„å¿«ç…§æ•°æ®ã€‚"
            
            result = [
                f"### å†å²æ—¶åˆ»å¿«ç…§æ•°æ®: {ts_code}",
                f"- **åŒ¹é…æ—¥æœŸ**: {snapshot['trade_date']}",
                f"- **åŒ¹é…æ—¶åˆ»**: {snapshot['trade_time']}",
                f"- **å½“æ—¶ä»·æ ¼**: {snapshot['close']}",
                f"- **ç´¯è®¡æˆäº¤é‡**: {snapshot['vol']} æ‰‹",
                f"- **ç´¯è®¡æˆäº¤é¢**: {snapshot['amount']} åƒå…ƒ",
                f"- **æ•°æ®é‡‡é›†æ—¶é—´**: {datetime.fromtimestamp(snapshot['created_at']).strftime('%Y-%m-%d %H:%M:%S')}"
            ]
            return "\n".join(result)
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥: {str(e)}"

    @mcp.tool()
    def scan_realtime_strong_sectors(sector_type: str = "em_concept", top_n: int = 15) -> str:
        """
        å®æ—¶å¼ºåŠ¿æ¿å—æ‰«æ
        
        å‚æ•°:
            sector_type: æ¿å—ç»´åº¦ ('sw_l2', 'em_industry', 'em_concept')
            top_n: è¿”å›æ’åå‰Nçš„æ¿å—
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
            
        try:
            pro = ts.pro_api()
            now = datetime.now()
            current_time_str = now.strftime("%H:%M:%S")
            
            # 1. è·å–å…¨å¸‚åœºå®æ—¶è¡Œæƒ…
            print(f"[{current_time_str}] ğŸš€ æ­£åœ¨æŠ“å–å®æ—¶è¡Œæƒ…...", file=__import__('sys').stderr)
            patterns = ['6*.SH', '0*.SZ', '3*.SZ', '4*.BJ', '8*.BJ']
            rt_dfs = []
            for p in patterns:
                try:
                    df_p = pro.rt_k(ts_code=p)
                    if df_p is not None and not df_p.empty:
                        rt_dfs.append(df_p)
                except:
                    continue
            
            if not rt_dfs:
                return "æœªèƒ½è·å–åˆ°å®æ—¶è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–APIæƒé™ã€‚"
            df_rt = pd.concat(rt_dfs).set_index('ts_code')
            
            # 2. è·å–è‚¡ç¥¨-æ¿å—æ˜ å°„
            from cache.mapping_cache_manager import mapping_cache_manager
            db_conn = mapping_cache_manager.conn
            df_mapping = pd.read_sql_query("SELECT * FROM stock_sector_mapping", db_conn)
            
            if df_mapping.empty:
                return "æ˜ å°„æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ collect_stock_sector_mappingã€‚"

            # 3. å‡†å¤‡æ˜¨æ—¥æ•°æ®å¯¹æ¯”æ—¥æœŸ
            cursor = db_conn.cursor()
            cursor.execute("SELECT MAX(trade_date) FROM stock_intraday_data")
            last_date_row = cursor.fetchone()
            hist_date = last_date_row[0] if last_date_row and last_date_row[0] else None

            # 4. èšåˆè®¡ç®—
            sector_data = {} 
            
            for _, row in df_mapping.iterrows():
                ts_code = row['ts_code']
                if ts_code not in df_rt.index:
                    continue
                
                target_sectors = []
                if sector_type == 'sw_l2':
                    if row['sw_l2_name']: target_sectors.append(row['sw_l2_name'])
                elif sector_type == 'em_industry':
                    if row['em_industry_name']: target_sectors.append(row['em_industry_name'])
                elif sector_type == 'em_concept':
                    try:
                        names = json.loads(row['em_concept_names'])
                        target_sectors.extend(names)
                    except: pass
                
                rt_row = df_rt.loc[ts_code]
                pct = rt_row.get('pct_chg', 0)
                if pd.isna(pct) and 'pre_close' in df_rt.columns and rt_row['pre_close'] > 0:
                    pct = (rt_row['close'] - rt_row['pre_close']) / rt_row['pre_close'] * 100
                
                vol_now = rt_row.get('vol', 0)
                vol_hist = 0
                if hist_date:
                    hist_snap = stock_intraday_cache_manager.get_historical_snapshot(ts_code, hist_date, current_time_str)
                    if hist_snap:
                        try:
                            t1 = datetime.strptime(current_time_str, "%H:%M:%S")
                            t2 = datetime.strptime(hist_snap['trade_time'], "%H:%M:%S")
                            if abs((t1 - t2).total_seconds()) <= 600:
                                vol_hist = hist_snap.get('vol', 0)
                        except: pass
                
                for s_name in target_sectors:
                    if s_name not in sector_data:
                        sector_data[s_name] = {'count': 0, 'sum_pct': 0, 'sum_vol_now': 0, 'sum_vol_hist': 0, 'rising': 0}
                    sector_data[s_name]['count'] += 1
                    sector_data[s_name]['sum_pct'] += pct
                    sector_data[s_name]['sum_vol_now'] += vol_now
                    sector_data[s_name]['sum_vol_hist'] += vol_hist
                    if pct > 0: sector_data[s_name]['rising'] += 1

            results = []
            for name, d in sector_data.items():
                if d['count'] < 3: continue 
                avg_pct = d['sum_pct'] / d['count']
                vr = d['sum_vol_now'] / d['sum_vol_hist'] if d['sum_vol_hist'] > 0 else 1.0
                rising_ratio = d['rising'] / d['count'] * 100
                vr_score = min(vr, 5.0) / 5.0 * 100 
                score = avg_pct * 5 + vr_score * 0.3 + rising_ratio * 0.2
                results.append({
                    'æ¿å—åç§°': name, 'å¹³å‡æ¶¨å¹…': f"{avg_pct:.2f}%", 'å®æ—¶é‡æ¯”': f"{vr:.2f}",
                    'ä¸Šæ¶¨å®¶æ•°æ¯”': f"{rising_ratio:.1f}%", 'æˆåˆ†è‚¡æ•°': d['count'], 'score': score
                })
            
            df_res = pd.DataFrame(results).sort_values('score', ascending=False).head(top_n)
            if df_res.empty: return "æœªæ‰«æåˆ°æ˜¾è‘—å¼ºåŠ¿çš„æ¿å—ã€‚"

            output = [f"### å®æ—¶å¼ºåŠ¿æ¿å—æ‰«æ (ç»´åº¦: {sector_type}, æ—¶é—´: {current_time_str})"]
            output.append("| æ¿å—åç§° | å¹³å‡æ¶¨å¹… | å®æ—¶é‡æ¯” | ä¸Šæ¶¨å æ¯” | æˆåˆ†è‚¡æ•° | ç»¼åˆè¯„åˆ† |")
            output.append("| --- | --- | --- | --- | --- | --- |")
            for _, r in df_res.iterrows():
                output.append(f"| {r['æ¿å—åç§°']} | {r['å¹³å‡æ¶¨å¹…']} | {r['å®æ—¶é‡æ¯”']} | {r['ä¸Šæ¶¨å®¶æ•°æ¯”']} | {r['æˆåˆ†è‚¡æ•°']} | {r['score']:.2f} |")
            return "\n".join(output)
        except Exception as e:
            import traceback
            return f"æ‰«æå¤±è´¥: {str(e)}\n{traceback.format_exc()}"

    @mcp.tool()
    def analyze_sector_health(sector_type: str = "em_industry", benchmark_code: str = "000001.SH", top_n: int = 15) -> str:
        """
        æ¿å—èµ°åŠ¿å¥åº·åº¦åˆ†æï¼ˆåŸºäºæ—¶åºç»Ÿè®¡å’Œçº¿æ€§å›å½’ï¼‰
        
        å‚æ•°:
            sector_type: æ¿å—ç»´åº¦ ('sw_l2', 'em_industry', 'em_concept')
            benchmark_code: åŸºå‡†æŒ‡æ•° (é»˜è®¤ 000001.SH ä¸Šè¯æŒ‡æ•°)
            top_n: è¿”å›å‰Nä¸ªå¥åº·æ¿å—
        """
        token = get_tushare_token()
        if not token: return "è¯·æŸ¥è¯¢Tushare token"
        
        try:
            import numpy as np
            pro = ts.pro_api()
            now = datetime.now()
            trade_date = now.strftime("%Y%m%d")
            
            # 1. è·å–åŸºå‡†è¡Œæƒ…
            df_benchmark = pro.rt_k(ts_code=benchmark_code)
            benchmark_pct = 0
            if not df_benchmark.empty:
                row = df_benchmark.iloc[0]
                benchmark_pct = (row['close'] - row['pre_close']) / row['pre_close'] * 100 if row['pre_close'] > 0 else 0

            # 2. ä»æ•°æ®åº“åŠ è½½æœ€è¿‘ 1 å°æ—¶çš„è¯„åˆ†å¿«ç…§ (12ä¸ªå‘¨æœŸ)
            from cache.sector_strength_cache_manager import sector_strength_cache_manager
            db_conn = sector_strength_cache_manager.conn
            query = f"""
            SELECT sector_name, trade_time, avg_pct, volume_ratio, rising_ratio, score 
            FROM sector_strength_data 
            WHERE trade_date = '{trade_date}' AND sector_type = '{sector_type}'
            ORDER BY sector_name, trade_time DESC
            """
            df_hist = pd.read_sql_query(query, db_conn)
            if df_hist.empty: return "ä»Šå¤©å°šæœªè®°å½•æ¿å—å¼ºåº¦ç»Ÿè®¡æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ sector_strength_collector.pyã€‚"
                
            health_results = []
            for name, group in df_hist.groupby('sector_name'):
                if len(group) < 3: continue 
                group = group.head(12).iloc[::-1] 
                y = group['score'].values
                x = np.arange(len(y))
                slope = np.polyfit(x, y, 1)[0] if len(y) > 1 else 0
                vol_stability = (group['volume_ratio'] > 1.2).sum() / len(group)
                avg_breadth = group['rising_ratio'].mean()
                current_avg_pct = group.iloc[-1]['avg_pct']
                relative_strength = current_avg_pct - benchmark_pct
                
                slope_score = np.clip(slope * 10, -50, 50) 
                health_score = (slope_score + 50) * 0.4 + (vol_stability * 100) * 0.3 + avg_breadth * 0.2 + (relative_strength * 10 + 50) * 0.1
                rating = "C (è§‚æœ›)"
                if health_score > 75 and slope > 0: rating = "A (å¼ºåŠ¿å¥åº·)"
                elif health_score > 60 and slope > -0.1: rating = "B (å¹³ç¨³è¿è¡Œ)"
                
                health_results.append({
                    'æ¿å—åç§°': name, 'è¶‹åŠ¿æ–œç‡': f"{slope:.3f}", 'é‡èƒ½çƒ­åº¦': f"{vol_stability*100:.1f}%",
                    'å†…ç”Ÿå¹¿åº¦': f"{avg_breadth:.1f}%", 'ç›¸å¯¹å¤§ç›˜': f"{relative_strength:+.2f}%",
                    'å¥åº·åˆ†': health_score, 'è¯„çº§': rating
                })
                
            df_health = pd.DataFrame(health_results).sort_values('å¥åº·åˆ†', ascending=False).head(top_n)
            if df_health.empty: return "æš‚æ— æ•°æ®ç¬¦åˆå¥åº·åº¦åˆ†ææ ‡å‡†ã€‚"
                
            output = [f"### æ¿å—èµ°åŠ¿å¥åº·åº¦åˆ†æè¡¨ (å‘¨æœŸ: 1å°æ—¶, åŸºå‡†: {benchmark_code})"]
            output.append("| æ¿å—åç§° | å¥åº·è¯„çº§ | è¶‹åŠ¿æ–œç‡ | é‡èƒ½è¿è´¯æ€§ | å¹³å‡å¹¿åº¦ | ç›¸å¯¹å¼ºåº¦ | ç»¼åˆåˆ† |")
            output.append("| --- | --- | --- | --- | --- | --- | --- |")
            for _, r in df_health.iterrows():
                output.append(f"| {r['æ¿å—åç§°']} | **{r['è¯„çº§']}** | {r['è¶‹åŠ¿æ–œç‡']} | {r['é‡èƒ½çƒ­åº¦']} | {r['å†…ç”Ÿå¹¿åº¦']} | {r['ç›¸å¯¹å¤§ç›˜']} | {r['å¥åº·åˆ†']:.1f} |")
            return "\n".join(output)
        except Exception as e:
            import traceback
            return f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}\n{traceback.format_exc()}"

    @mcp.tool()
    def get_index_rt_k(ts_code: str = "") -> str:
        """
        è·å–æ²ªæ·±äº¬å®æ—¶æ—¥çº¿æŒ‡æ ‡æ¥å£ï¼ˆæŒ‡æ•°ä¸“ç”¨ï¼‰
        
        å‚æ•°:
            ts_code: æ”¯æŒé€šé…ç¬¦æ–¹å¼ï¼Œä¾‹å¦‚ 6*.SHã€3*.SZã€600000.SH
        """
        token = get_tushare_token()
        if not token: return "è¯·å…ˆé…ç½®Tushare token"
        if not ts_code: return "è¯·æä¾›ts_code"
        try:
            pro = ts.pro_api()
            df = pro.rt_k(ts_code=ts_code)
            if df is None or df.empty: return f"æœªæ‰¾åˆ°æ•°æ®: {ts_code}"
            
            # è®¡ç®—æ¶¨è·Œå¹…
            if 'pre_close' in df.columns and 'close' in df.columns:
                df['pct_chg'] = (df['close'] - df['pre_close']) / df['pre_close'] * 100
                
            df = df.sort_values('vol', ascending=False, na_position='last')
            
            output = [f"### å®æ—¶æ—¥çº¿å¿«ç…§ ({ts_code})"]
            cols = ['ts_code', 'name', 'pre_close', 'open', 'close', 'high', 'low', 'pct_chg', 'vol', 'amount']
            col_names = ['ä»£ç ', 'åç§°', 'æ˜¨æ”¶', 'å¼€ç›˜', 'ç°ä»·', 'æœ€é«˜', 'æœ€ä½', 'æ¶¨å¹…', 'æˆäº¤é‡', 'é‡‘é¢']
            output.append("| " + " | ".join(col_names) + " |")
            output.append("| " + " | ".join(["---"] * len(col_names)) + " |")
            
            for _, r in df.iterrows():
                vals = [
                    str(r.get('ts_code','')), str(r.get('name','')), f"{r.get('pre_close',0):.2f}",
                    f"{r.get('open',0):.2f}", f"{r.get('close',0):.2f}", f"{r.get('high',0):.2f}",
                    f"{r.get('low',0):.2f}", f"{r.get('pct_chg',0):+.2f}%", f"{r.get('vol',0)/10000:.0f}ä¸‡",
                    f"{r.get('amount',0)/100000000:.2f}äº¿"
                ]
                output.append("| " + " | ".join(vals) + " |")
            return "\n".join(output)
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
    
    @mcp.tool()
    def search_stocks(keyword: str) -> str:
        """
        æœç´¢è‚¡ç¥¨
        
        å‚æ•°:
            keyword: å…³é”®è¯ï¼ˆå¯ä»¥æ˜¯è‚¡ç¥¨ä»£ç çš„ä¸€éƒ¨åˆ†æˆ–è‚¡ç¥¨åç§°çš„ä¸€éƒ¨åˆ†ï¼‰
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        try:
            # å°è¯•ä»ç¼“å­˜è·å–å®Œæ•´çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            df = cache_manager.get_dataframe('stock_search', keyword='all')
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True  # æœªæ‰¾åˆ°æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
            elif cache_manager.is_expired('stock_search', keyword='all'):
                need_update = True  # æ•°æ®è¿‡æœŸï¼Œéœ€è¦æ›´æ–°
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                pro = ts.pro_api()
                df = pro.stock_basic()
                # ä¿å­˜å®Œæ•´åˆ—è¡¨åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                if not df.empty:
                    cache_manager.set('stock_search', df, keyword='all')
            
            # åœ¨ä»£ç å’Œåç§°ä¸­æœç´¢å…³é”®è¯
            mask = (df['ts_code'].str.contains(keyword, case=False)) | \
                   (df['name'].str.contains(keyword, case=False))
            results = df[mask]
            
            if results.empty:
                return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨"
                
            # æ ¼å¼åŒ–è¾“å‡º
            output = []
            for _, row in results.iterrows():
                output.append(f"{row['ts_code']} - {row['name']}")
                
            return "\n".join(output)
            
        except Exception as e:
            return f"æœç´¢å¤±è´¥ï¼š{str(e)}"
    
    @mcp.tool()
    def get_stock_daily(ts_code: str = "", trade_date: str = "", start_date: str = "", end_date: str = "") -> str:
        """
        è·å–Aè‚¡æ—¥çº¿è¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001.SZï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨åŒæ—¶æå–ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ï¼š000001.SZ,600000.SHï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241231ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        æ³¨æ„ï¼š
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - æ•°æ®è¯´æ˜ï¼šäº¤æ˜“æ—¥æ¯å¤©15ç‚¹ï½16ç‚¹ä¹‹é—´å…¥åº“ï¼Œæœ¬æ¥å£æ˜¯æœªå¤æƒè¡Œæƒ…ï¼Œåœç‰ŒæœŸé—´ä¸æä¾›æ•°æ®
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code and not trade_date:
            return "è¯·è‡³å°‘æä¾›è‚¡ç¥¨ä»£ç (ts_code)æˆ–äº¤æ˜“æ—¥æœŸ(trade_date)ä¹‹ä¸€"
        
        try:
            # å‚æ•°å¤„ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸º Noneï¼Œä¾¿äºåç»­å¤„ç†
            ts_code = ts_code.strip() if ts_code else None
            trade_date = trade_date.strip() if trade_date else None
            start_date = start_date.strip() if start_date else None
            end_date = end_date.strip() if end_date else None
            
            if trade_date and (start_date or end_date):
                # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
                start_date = None
                end_date = None
            
            # ä»ä¸“ç”¨ç¼“å­˜è¡¨æŸ¥è¯¢æ•°æ®ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
            df = None
            need_fetch_from_api = False
            
            if trade_date:
                # æŸ¥è¯¢ç‰¹å®šæ—¥æœŸ
                if ts_code:
                    df = stock_daily_cache_manager.get_stock_daily_data(
                        ts_code=ts_code,
                        trade_date=trade_date
                    )
                else:
                    # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æ•°æ®
                    df = stock_daily_cache_manager.get_stock_daily_data(
                        trade_date=trade_date
                    )
                if df is None or df.empty:
                    need_fetch_from_api = True
            elif start_date or end_date:
                # æŸ¥è¯¢æ—¥æœŸèŒƒå›´ï¼ˆè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ—¥æœŸå‚æ•°ï¼‰
                if ts_code:
                    df = stock_daily_cache_manager.get_stock_daily_data(
                        ts_code=ts_code,
                        start_date=start_date,
                        end_date=end_date
                    )
                    # æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å®Œæ•´è¦†ç›–è¯·æ±‚çš„æ—¥æœŸèŒƒå›´
                    if df is None or df.empty:
                        need_fetch_from_api = True
                    elif not stock_daily_cache_manager.is_cache_data_complete(ts_code, start_date, end_date):
                        # ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»APIè·å–å®Œæ•´æ•°æ®
                        need_fetch_from_api = True
                else:
                    # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨åœ¨æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
                    df = stock_daily_cache_manager.get_stock_daily_data(
                        start_date=start_date,
                        end_date=end_date
                    )
                    if df is None or df.empty:
                        need_fetch_from_api = True
            else:
                # æŸ¥è¯¢æœ€è¿‘æ•°æ®ï¼ˆä»ç¼“å­˜è·å–æœ€æ–°æ•°æ®ï¼‰
                if ts_code:
                    df = stock_daily_cache_manager.get_stock_daily_data(
                        ts_code=ts_code,
                        limit=20,
                        order_by='DESC'
                    )
                else:
                    return "æŸ¥è¯¢æœ€è¿‘æ•°æ®æ—¶ï¼Œè¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)"
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
                if df is None or df.empty:
                    need_fetch_from_api = True
            
            # å¦‚æœéœ€è¦ä»APIè·å–æ•°æ®
            if need_fetch_from_api:
                pro = ts.pro_api()
                params = {}
                
                if ts_code:
                    params['ts_code'] = ts_code
                
                # ä¼˜å…ˆä½¿ç”¨trade_dateï¼Œå¦åˆ™ä½¿ç”¨æ—¥æœŸèŒƒå›´
                if trade_date:
                    params['trade_date'] = trade_date
                else:
                    if start_date:
                        params['start_date'] = start_date
                    if end_date:
                        params['end_date'] = end_date
                
                df = pro.daily(**params)
                
                # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜è¡¨ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
                if not df.empty:
                    saved_count = stock_daily_cache_manager.save_stock_daily_data(df)
                    # å¦‚æœæŸ¥è¯¢çš„æ˜¯ç‰¹å®šæ—¥æœŸæˆ–èŒƒå›´ï¼Œé‡æ–°ä»ç¼“å­˜è¯»å–ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if trade_date:
                        if ts_code:
                            df = stock_daily_cache_manager.get_stock_daily_data(
                                ts_code=ts_code,
                                trade_date=trade_date
                            )
                        else:
                            df = stock_daily_cache_manager.get_stock_daily_data(
                                trade_date=trade_date
                            )
                    elif start_date or end_date:
                        if ts_code:
                            df = stock_daily_cache_manager.get_stock_daily_data(
                                ts_code=ts_code,
                                start_date=start_date,
                                end_date=end_date
                            )
                        else:
                            df = stock_daily_cache_manager.get_stock_daily_data(
                                start_date=start_date,
                                end_date=end_date
                            )
                    else:
                        # æŸ¥è¯¢æœ€è¿‘æ•°æ®
                        if ts_code:
                            df = stock_daily_cache_manager.get_stock_daily_data(
                                ts_code=ts_code,
                                limit=20,
                                order_by='DESC'
                            )
            
            if df is None or df.empty:
                if ts_code:
                    stock_info = f"è‚¡ç¥¨ {ts_code}"
                else:
                    stock_info = "è‚¡ç¥¨"
                
                if trade_date:
                    date_info = f"æ—¥æœŸ {trade_date}"
                elif start_date or end_date:
                    if start_date and end_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ {start_date} è‡³ {end_date}"
                    elif start_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ä» {start_date} å¼€å§‹"
                    else:
                        date_info = f"æ—¥æœŸèŒƒå›´åˆ° {end_date} ç»“æŸ"
                else:
                    date_info = "æœ€è¿‘æ•°æ®"
                return f"æœªæ‰¾åˆ° {stock_info} åœ¨ {date_info} çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®"
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_stock_daily_data(df, ts_code or "")
            
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"
    
    @mcp.tool()
    def get_stock_weekly(ts_code: str = "", trade_date: str = "", start_date: str = "", end_date: str = "") -> str:
        """
        è·å–Aè‚¡å‘¨çº¿è¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001.SZï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨åŒæ—¶æå–ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ï¼š000001.SZ,600000.SHï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼ŒæŸ¥è¯¢æŒ‡å®šå‘¨çš„æ•°æ®ï¼Œtrade_dateä¸ºè¯¥å‘¨çš„æœ€åäº¤æ˜“æ—¥ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241231ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        æ³¨æ„ï¼š
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šå‘¨çš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„å‘¨çº¿æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - trade_dateä¸ºè¯¥å‘¨çš„æœ€åäº¤æ˜“æ—¥ï¼ˆé€šå¸¸æ˜¯å‘¨äº”ï¼‰
            - æ•°æ®è¯´æ˜ï¼šå‘¨çº¿æ•°æ®æ¯å‘¨æ›´æ–°ä¸€æ¬¡ï¼Œæœ¬æ¥å£æ˜¯æœªå¤æƒè¡Œæƒ…
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code:
            return "è¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)"
        
        try:
            # å‚æ•°å¤„ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸º Noneï¼Œä¾¿äºåç»­å¤„ç†
            ts_code = ts_code.strip() if ts_code else None
            trade_date = trade_date.strip() if trade_date else None
            start_date = start_date.strip() if start_date else None
            end_date = end_date.strip() if end_date else None
            
            if trade_date and (start_date or end_date):
                # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
                start_date = None
                end_date = None
            
            # ä»ä¸“ç”¨ç¼“å­˜è¡¨æŸ¥è¯¢æ•°æ®ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
            df = None
            need_fetch_from_api = False
            
            if trade_date:
                # æŸ¥è¯¢ç‰¹å®šå‘¨
                df = stock_weekly_cache_manager.get_stock_weekly_data(
                    ts_code=ts_code,
                    trade_date=trade_date
                )
                if df is None or df.empty:
                    need_fetch_from_api = True
            elif start_date or end_date:
                # æŸ¥è¯¢æ—¥æœŸèŒƒå›´ï¼ˆè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ—¥æœŸå‚æ•°ï¼‰
                df = stock_weekly_cache_manager.get_stock_weekly_data(
                    ts_code=ts_code,
                    start_date=start_date,
                    end_date=end_date
                )
                # æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å®Œæ•´è¦†ç›–è¯·æ±‚çš„æ—¥æœŸèŒƒå›´
                if df is None or df.empty:
                    need_fetch_from_api = True
                elif not stock_weekly_cache_manager.is_cache_data_complete(ts_code, start_date, end_date):
                    # ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»APIè·å–å®Œæ•´æ•°æ®
                    need_fetch_from_api = True
            else:
                # æŸ¥è¯¢æœ€è¿‘æ•°æ®ï¼ˆä»ç¼“å­˜è·å–æœ€æ–°æ•°æ®ï¼‰
                df = stock_weekly_cache_manager.get_stock_weekly_data(
                    ts_code=ts_code,
                    limit=20,
                    order_by='DESC'
                )
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
                if df is None or df.empty:
                    need_fetch_from_api = True
            
            # å¦‚æœéœ€è¦ä»APIè·å–æ•°æ®
            if need_fetch_from_api:
                pro = ts.pro_api()
                params = {}
                
                if ts_code:
                    params['ts_code'] = ts_code
                
                # ä¼˜å…ˆä½¿ç”¨trade_dateï¼Œå¦åˆ™ä½¿ç”¨æ—¥æœŸèŒƒå›´
                if trade_date:
                    params['trade_date'] = trade_date
                else:
                    if start_date:
                        params['start_date'] = start_date
                    if end_date:
                        params['end_date'] = end_date
                
                df = pro.weekly(**params)
                
                # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜è¡¨ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
                if not df.empty:
                    saved_count = stock_weekly_cache_manager.save_stock_weekly_data(df)
                    # å¦‚æœæŸ¥è¯¢çš„æ˜¯ç‰¹å®šå‘¨æˆ–èŒƒå›´ï¼Œé‡æ–°ä»ç¼“å­˜è¯»å–ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if trade_date:
                        df = stock_weekly_cache_manager.get_stock_weekly_data(
                            ts_code=ts_code,
                            trade_date=trade_date
                        )
                    elif start_date or end_date:
                        df = stock_weekly_cache_manager.get_stock_weekly_data(
                            ts_code=ts_code,
                            start_date=start_date,
                            end_date=end_date
                        )
                    else:
                        # æŸ¥è¯¢æœ€è¿‘æ•°æ®
                        df = stock_weekly_cache_manager.get_stock_weekly_data(
                            ts_code=ts_code,
                            limit=20,
                            order_by='DESC'
                        )
            
            if df is None or df.empty:
                stock_info = f"è‚¡ç¥¨ {ts_code}"
                
                if trade_date:
                    date_info = f"å‘¨ {trade_date}"
                elif start_date or end_date:
                    if start_date and end_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ {start_date} è‡³ {end_date}"
                    elif start_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ä» {start_date} å¼€å§‹"
                    else:
                        date_info = f"æ—¥æœŸèŒƒå›´åˆ° {end_date} ç»“æŸ"
                else:
                    date_info = "æœ€è¿‘æ•°æ®"
                return f"æœªæ‰¾åˆ° {stock_info} åœ¨ {date_info} çš„å‘¨çº¿è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®"
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_stock_weekly_data(df, ts_code or "")
            
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"
    
    @mcp.tool()
    def get_etf_daily(ts_code: str = "", trade_date: str = "", start_date: str = "", end_date: str = "") -> str:
        """
        è·å–ETFæ—¥çº¿è¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: ETFåŸºé‡‘ä»£ç ï¼ˆå¦‚ï¼š510330.SHæ²ªæ·±300ETFåå¤ï¼Œæ”¯æŒå¤šä¸ªETFåŒæ—¶æå–ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ï¼š510330.SH,510300.SHï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241231ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
        
        æ³¨æ„ï¼š
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - æ•°æ®è¯´æ˜ï¼šè·å–ETFè¡Œæƒ…æ¯æ—¥æ”¶ç›˜åæˆäº¤æ•°æ®ï¼Œå†å²è¶…è¿‡10å¹´
            - é™é‡ï¼šå•æ¬¡æœ€å¤§2000è¡Œè®°å½•ï¼Œå¯ä»¥æ ¹æ®ETFä»£ç å’Œæ—¥æœŸå¾ªç¯è·å–å†å²
        
        å¸¸ç”¨ETFä»£ç ç¤ºä¾‹ï¼š
            - 510330.SH: æ²ªæ·±300ETFåå¤
            - 510300.SH: æ²ªæ·±300ETF
            - 159919.SZ: æ²ªæ·±300ETF
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code and not trade_date:
            return "è¯·è‡³å°‘æä¾›ETFä»£ç (ts_code)æˆ–äº¤æ˜“æ—¥æœŸ(trade_date)ä¹‹ä¸€"
        
        try:
            # å‚æ•°å¤„ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸º Noneï¼Œä¾¿äºåç»­å¤„ç†
            ts_code = ts_code.strip() if ts_code else None
            trade_date = trade_date.strip() if trade_date else None
            start_date = start_date.strip() if start_date else None
            end_date = end_date.strip() if end_date else None
            
            if trade_date and (start_date or end_date):
                # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
                start_date = None
                end_date = None
            
            # ä»ä¸“ç”¨ç¼“å­˜è¡¨æŸ¥è¯¢æ•°æ®ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
            df = None
            need_fetch_from_api = False
            
            if trade_date:
                # æŸ¥è¯¢ç‰¹å®šæ—¥æœŸ
                if ts_code:
                    df = index_daily_cache_manager.get_index_daily_data(
                        ts_code=ts_code,
                        trade_date=trade_date
                    )
                else:
                    # æŸ¥è¯¢æ‰€æœ‰ETFåœ¨ç‰¹å®šæ—¥æœŸçš„æ•°æ®
                    df = index_daily_cache_manager.get_index_daily_data(
                        trade_date=trade_date
                    )
                if df is None or df.empty:
                    need_fetch_from_api = True
            elif start_date or end_date:
                # æŸ¥è¯¢æ—¥æœŸèŒƒå›´ï¼ˆè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ—¥æœŸå‚æ•°ï¼‰
                if ts_code:
                    df = index_daily_cache_manager.get_index_daily_data(
                        ts_code=ts_code,
                        start_date=start_date,
                        end_date=end_date
                    )
                    # æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å®Œæ•´è¦†ç›–è¯·æ±‚çš„æ—¥æœŸèŒƒå›´
                    if df is None or df.empty:
                        need_fetch_from_api = True
                    elif not index_daily_cache_manager.is_cache_data_complete(ts_code, start_date, end_date):
                        # ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»APIè·å–å®Œæ•´æ•°æ®
                        need_fetch_from_api = True
                else:
                    # æŸ¥è¯¢æ‰€æœ‰ETFåœ¨æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
                    df = index_daily_cache_manager.get_index_daily_data(
                        start_date=start_date,
                        end_date=end_date
                    )
                    if df is None or df.empty:
                        need_fetch_from_api = True
            else:
                # æŸ¥è¯¢æœ€è¿‘æ•°æ®ï¼ˆä»ç¼“å­˜è·å–æœ€æ–°æ•°æ®ï¼‰
                if ts_code:
                    df = index_daily_cache_manager.get_index_daily_data(
                        ts_code=ts_code,
                        limit=20,
                        order_by='DESC'
                    )
                else:
                    return "æŸ¥è¯¢æœ€è¿‘æ•°æ®æ—¶ï¼Œè¯·æä¾›ETFä»£ç (ts_code)"
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
                if df is None or df.empty:
                    need_fetch_from_api = True
            
            # å¦‚æœéœ€è¦ä»APIè·å–æ•°æ®
            if need_fetch_from_api:
                pro = ts.pro_api()
                params = {}
                
                if ts_code:
                    params['ts_code'] = ts_code
                
                # ä¼˜å…ˆä½¿ç”¨trade_dateï¼Œå¦åˆ™ä½¿ç”¨æ—¥æœŸèŒƒå›´
                if trade_date:
                    params['trade_date'] = trade_date
                else:
                    if start_date:
                        params['start_date'] = start_date
                    if end_date:
                        params['end_date'] = end_date
                
                # ä½¿ç”¨fund_dailyæ¥å£è·å–ETFæ—¥çº¿è¡Œæƒ…æ•°æ®
                df = pro.fund_daily(**params)
                
                # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜è¡¨ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
                if not df.empty:
                    saved_count = index_daily_cache_manager.save_index_daily_data(df)
                    # å¦‚æœæŸ¥è¯¢çš„æ˜¯ç‰¹å®šæ—¥æœŸæˆ–èŒƒå›´ï¼Œé‡æ–°ä»ç¼“å­˜è¯»å–ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if trade_date:
                        if ts_code:
                            df = index_daily_cache_manager.get_index_daily_data(
                                ts_code=ts_code,
                                trade_date=trade_date
                            )
                        else:
                            df = index_daily_cache_manager.get_index_daily_data(
                                trade_date=trade_date
                            )
                    elif start_date or end_date:
                        if ts_code:
                            df = index_daily_cache_manager.get_index_daily_data(
                                ts_code=ts_code,
                                start_date=start_date,
                                end_date=end_date
                            )
                        else:
                            df = index_daily_cache_manager.get_index_daily_data(
                                start_date=start_date,
                                end_date=end_date
                            )
                    else:
                        # æŸ¥è¯¢æœ€è¿‘æ•°æ®
                        if ts_code:
                            df = index_daily_cache_manager.get_index_daily_data(
                                ts_code=ts_code,
                                limit=20,
                                order_by='DESC'
                            )
            
            if df is None or df.empty:
                if ts_code:
                    etf_info = f"ETF {ts_code}"
                else:
                    etf_info = "ETF"
                
                if trade_date:
                    date_info = f"æ—¥æœŸ {trade_date}"
                elif start_date or end_date:
                    if start_date and end_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ {start_date} è‡³ {end_date}"
                    elif start_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ä» {start_date} å¼€å§‹"
                    else:
                        date_info = f"æ—¥æœŸèŒƒå›´åˆ° {end_date} ç»“æŸ"
                else:
                    date_info = "æœ€è¿‘æ•°æ®"
                return f"æœªæ‰¾åˆ° {etf_info} åœ¨ {date_info} çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®"
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_etf_daily_data(df, ts_code or "")
            
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"
    
    @mcp.tool()
    def get_index_daily(ts_code: str = "", trade_date: str = "", start_date: str = "", end_date: str = "") -> str:
        """
        è·å–Aè‚¡æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: æŒ‡æ•°ä»£ç ï¼ˆå¦‚ï¼š000300.SHæ²ªæ·±300ã€000001.SHä¸Šè¯æŒ‡æ•°ã€399001.SZæ·±è¯æˆæŒ‡ç­‰ï¼Œæ”¯æŒå¤šä¸ªæŒ‡æ•°åŒæ—¶æå–ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ï¼š000300.SH,000001.SHï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241231ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
        
        æ³¨æ„ï¼š
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - æ•°æ®è¯´æ˜ï¼šäº¤æ˜“æ—¥æ¯å¤©15ç‚¹ï½16ç‚¹ä¹‹é—´å…¥åº“ï¼Œæœ¬æ¥å£æ˜¯æœªå¤æƒè¡Œæƒ…
        
        å¸¸ç”¨æŒ‡æ•°ä»£ç ï¼š
            - 000300.SH: æ²ªæ·±300æŒ‡æ•°
            - 000001.SH: ä¸Šè¯æŒ‡æ•°
            - 399001.SZ: æ·±è¯æˆæŒ‡
            - 399006.SZ: åˆ›ä¸šæ¿æŒ‡
            - 000016.SH: ä¸Šè¯50æŒ‡æ•°
            - 399005.SZ: ä¸­å°æ¿æŒ‡
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code and not trade_date:
            return "è¯·è‡³å°‘æä¾›æŒ‡æ•°ä»£ç (ts_code)æˆ–äº¤æ˜“æ—¥æœŸ(trade_date)ä¹‹ä¸€"
        
        try:
            # å‚æ•°å¤„ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸º Noneï¼Œä¾¿äºåç»­å¤„ç†
            ts_code = ts_code.strip() if ts_code else None
            trade_date = trade_date.strip() if trade_date else None
            start_date = start_date.strip() if start_date else None
            end_date = end_date.strip() if end_date else None
            
            if trade_date and (start_date or end_date):
                # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
                start_date = None
                end_date = None
            
            # ä»ä¸“ç”¨ç¼“å­˜è¡¨æŸ¥è¯¢æ•°æ®ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
            df = None
            need_fetch_from_api = False
            
            if trade_date:
                # æŸ¥è¯¢ç‰¹å®šæ—¥æœŸ
                if ts_code:
                    df = index_daily_cache_manager.get_index_daily_data(
                        ts_code=ts_code,
                        trade_date=trade_date
                    )
                else:
                    # æŸ¥è¯¢æ‰€æœ‰æŒ‡æ•°åœ¨ç‰¹å®šæ—¥æœŸçš„æ•°æ®
                    df = index_daily_cache_manager.get_index_daily_data(
                        trade_date=trade_date
                    )
                if df is None or df.empty:
                    need_fetch_from_api = True
            elif start_date or end_date:
                # æŸ¥è¯¢æ—¥æœŸèŒƒå›´ï¼ˆè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ—¥æœŸå‚æ•°ï¼‰
                if ts_code:
                    df = index_daily_cache_manager.get_index_daily_data(
                        ts_code=ts_code,
                        start_date=start_date,
                        end_date=end_date
                    )
                    # æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å®Œæ•´è¦†ç›–è¯·æ±‚çš„æ—¥æœŸèŒƒå›´
                    if df is None or df.empty:
                        need_fetch_from_api = True
                    elif not index_daily_cache_manager.is_cache_data_complete(ts_code, start_date, end_date):
                        # ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»APIè·å–å®Œæ•´æ•°æ®
                        need_fetch_from_api = True
                else:
                    # æŸ¥è¯¢æ‰€æœ‰æŒ‡æ•°åœ¨æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
                    df = index_daily_cache_manager.get_index_daily_data(
                        start_date=start_date,
                        end_date=end_date
                    )
                    if df is None or df.empty:
                        need_fetch_from_api = True
            else:
                # æŸ¥è¯¢æœ€è¿‘æ•°æ®ï¼ˆä»ç¼“å­˜è·å–æœ€æ–°æ•°æ®ï¼‰
                if ts_code:
                    df = index_daily_cache_manager.get_index_daily_data(
                        ts_code=ts_code,
                        limit=20,
                        order_by='DESC'
                    )
                else:
                    return "æŸ¥è¯¢æœ€è¿‘æ•°æ®æ—¶ï¼Œè¯·æä¾›æŒ‡æ•°ä»£ç (ts_code)"
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
                if df is None or df.empty:
                    need_fetch_from_api = True
            
            # å¦‚æœéœ€è¦ä»APIè·å–æ•°æ®
            if need_fetch_from_api:
                pro = ts.pro_api()
                params = {}
                
                if ts_code:
                    params['ts_code'] = ts_code
                
                # ä¼˜å…ˆä½¿ç”¨trade_dateï¼Œå¦åˆ™ä½¿ç”¨æ—¥æœŸèŒƒå›´
                if trade_date:
                    params['trade_date'] = trade_date
                else:
                    if start_date:
                        params['start_date'] = start_date
                    if end_date:
                        params['end_date'] = end_date
                
                # ä½¿ç”¨index_dailyæ¥å£è·å–Aè‚¡æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®
                df = pro.index_daily(**params)
                
                # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜è¡¨ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
                if not df.empty:
                    saved_count = index_daily_cache_manager.save_index_daily_data(df)
                    # å¦‚æœæŸ¥è¯¢çš„æ˜¯ç‰¹å®šæ—¥æœŸæˆ–èŒƒå›´ï¼Œé‡æ–°ä»ç¼“å­˜è¯»å–ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if trade_date:
                        if ts_code:
                            df = index_daily_cache_manager.get_index_daily_data(
                                ts_code=ts_code,
                                trade_date=trade_date
                            )
                        else:
                            df = index_daily_cache_manager.get_index_daily_data(
                                trade_date=trade_date
                            )
                    elif start_date or end_date:
                        if ts_code:
                            df = index_daily_cache_manager.get_index_daily_data(
                                ts_code=ts_code,
                                start_date=start_date,
                                end_date=end_date
                            )
                        else:
                            df = index_daily_cache_manager.get_index_daily_data(
                                start_date=start_date,
                                end_date=end_date
                            )
                    else:
                        # æŸ¥è¯¢æœ€è¿‘æ•°æ®
                        if ts_code:
                            df = index_daily_cache_manager.get_index_daily_data(
                                ts_code=ts_code,
                                limit=20,
                                order_by='DESC'
                            )
            
            if df is None or df.empty:
                if ts_code:
                    index_info = f"æŒ‡æ•° {ts_code}"
                else:
                    index_info = "æŒ‡æ•°"
                
                if trade_date:
                    date_info = f"æ—¥æœŸ {trade_date}"
                elif start_date or end_date:
                    if start_date and end_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ {start_date} è‡³ {end_date}"
                    elif start_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ä» {start_date} å¼€å§‹"
                    else:
                        date_info = f"æ—¥æœŸèŒƒå›´åˆ° {end_date} ç»“æŸ"
                else:
                    date_info = "æœ€è¿‘æ•°æ®"
                return f"æœªæ‰¾åˆ° {index_info} åœ¨ {date_info} çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®"
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_index_daily_data(df, ts_code or "")
            
        except Exception as e:
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"
    
    @mcp.tool()
    def get_stock_holder_trade(
        ts_code: str = "",
        ann_date: str = "",
        start_date: str = "",
        end_date: str = "",
        trade_type: str = "",
        holder_type: str = ""
    ) -> str:
        """
        è·å–ä¸Šå¸‚å…¬å¸è‚¡ä¸œå¢å‡æŒæ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š300766.SZï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨ï¼‰
            ann_date: å…¬å‘Šæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240426ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„å¢å‡æŒæ•°æ®ï¼‰
            start_date: å…¬å‘Šå¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: å…¬å‘Šç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
            trade_type: äº¤æ˜“ç±»å‹ï¼ˆINå¢æŒï¼ŒDEå‡æŒï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰ç±»å‹ï¼‰
            holder_type: è‚¡ä¸œç±»å‹ï¼ˆCå…¬å¸ï¼ŒPä¸ªäººï¼ŒGé«˜ç®¡ï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰ç±»å‹ï¼‰
        
        è¿”å›:
            åŒ…å«è‚¡ä¸œå¢å‡æŒæ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºäºä¸Šå¸‚å…¬å¸å…¬å‘Š
            - æ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç ã€å…¬å‘Šæ—¥æœŸã€äº¤æ˜“ç±»å‹ã€è‚¡ä¸œç±»å‹ç­›é€‰
            - æ˜¾ç¤ºå¢å‡æŒæ•°é‡ã€å æµé€šæ¯”ä¾‹ã€å¹³å‡ä»·æ ¼ç­‰ä¿¡æ¯
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not ann_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šè‚¡ç¥¨ä»£ç (ts_code)ã€å…¬å‘Šæ—¥æœŸ(ann_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if ann_date:
                params['ann_date'] = ann_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            if trade_type:
                params['trade_type'] = trade_type
            if holder_type:
                params['holder_type'] = holder_type
            
            # è·å–å¢å‡æŒæ•°æ®
            df = pro.stk_holdertrade(**params)
            
            if df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                if ann_date:
                    param_info.append(f"å…¬å‘Šæ—¥æœŸ: {ann_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                if trade_type:
                    param_info.append(f"äº¤æ˜“ç±»å‹: {trade_type}")
                if holder_type:
                    param_info.append(f"è‚¡ä¸œç±»å‹: {holder_type}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¢å‡æŒæ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'ann_date' in df.columns:
                df = df.sort_values('ann_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = []
            result.append("ğŸ“Š ä¸Šå¸‚å…¬å¸è‚¡ä¸œå¢å‡æŒæ•°æ®")
            result.append("=" * 120)
            result.append("")
            
            # æ˜¾ç¤ºæŸ¥è¯¢æ¡ä»¶
            query_info = []
            if ts_code:
                query_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
            if ann_date:
                query_info.append(f"å…¬å‘Šæ—¥æœŸ: {ann_date}")
            if start_date or end_date:
                date_range = f"{start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}"
                query_info.append(f"æ—¥æœŸèŒƒå›´: {date_range}")
            if trade_type:
                trade_type_name = "å¢æŒ" if trade_type == "IN" else "å‡æŒ" if trade_type == "DE" else trade_type
                query_info.append(f"äº¤æ˜“ç±»å‹: {trade_type_name}")
            if holder_type:
                holder_type_name = {"C": "å…¬å¸", "P": "ä¸ªäºº", "G": "é«˜ç®¡"}.get(holder_type, holder_type)
                query_info.append(f"è‚¡ä¸œç±»å‹: {holder_type_name}")
            
            if query_info:
                result.append("æŸ¥è¯¢æ¡ä»¶:")
                for info in query_info:
                    result.append(f"  - {info}")
                result.append("")
            
            # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
            result.append(f"ğŸ“ˆ å…±æ‰¾åˆ° {len(df)} æ¡å¢å‡æŒè®°å½•")
            result.append("")
            
            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤ºï¼ˆå¦‚æœæŸ¥è¯¢äº†å¤šä¸ªè‚¡ç¥¨ï¼‰
            if not ts_code:
                # å¦‚æœæœªæŒ‡å®šè‚¡ç¥¨ä»£ç ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
                codes = df['ts_code'].unique()
                for code in codes[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªè‚¡ç¥¨
                    code_df = df[df['ts_code'] == code].copy()
                    result.append(format_holder_trade_data(code_df, code))
                    result.append("")
                
                if len(codes) > 10:
                    result.append(f"ï¼ˆå…± {len(codes)} ä¸ªè‚¡ç¥¨ï¼Œä»…æ˜¾ç¤ºå‰ 10 ä¸ªï¼‰")
            else:
                # å•ä¸ªè‚¡ç¥¨ï¼Œç›´æ¥æ˜¾ç¤º
                result.append(format_holder_trade_data(df, ts_code))
            
            result.append("")
            result.append("ğŸ“ è¯´æ˜ï¼š")
            result.append("  - æ•°æ®æ¥æºäºä¸Šå¸‚å…¬å¸å…¬å‘Š")
            result.append("  - IN: å¢æŒï¼ŒDE: å‡æŒ")
            result.append("  - è‚¡ä¸œç±»å‹ï¼šCå…¬å¸ï¼ŒPä¸ªäººï¼ŒGé«˜ç®¡")
            result.append("  - change_ratio: å æµé€šæ¯”ä¾‹ï¼ˆ%ï¼‰")
            result.append("  - avg_price: å¹³å‡äº¤æ˜“ä»·æ ¼")
            
            return "\n".join(result)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_stock_holder_number(
        ts_code: str = "",
        ann_date: str = "",
        enddate: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–ä¸Šå¸‚å…¬å¸è‚¡ä¸œæˆ·æ•°æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š300766.SZï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨ï¼‰
            ann_date: å…¬å‘Šæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240426ï¼ŒæŸ¥è¯¢æŒ‡å®šå…¬å‘Šæ—¥æœŸçš„æ•°æ®ï¼‰
            enddate: æˆªæ­¢æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240930ï¼ŒæŸ¥è¯¢æŒ‡å®šæˆªæ­¢æ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å…¬å‘Šå¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: å…¬å‘Šç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«è‚¡ä¸œæˆ·æ•°æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºäºä¸Šå¸‚å…¬å¸å®šæœŸæŠ¥å‘Šï¼Œä¸å®šæœŸå…¬å¸ƒ
            - æ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç ã€å…¬å‘Šæ—¥æœŸã€æˆªæ­¢æ—¥æœŸã€æ—¥æœŸèŒƒå›´ç­›é€‰
            - è‚¡ä¸œæˆ·æ•°å˜åŒ–å¯ä»¥åæ˜ è‚¡ç¥¨çš„é›†ä¸­åº¦å˜åŒ–è¶‹åŠ¿
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not ann_date and not enddate and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šè‚¡ç¥¨ä»£ç (ts_code)ã€å…¬å‘Šæ—¥æœŸ(ann_date)ã€æˆªæ­¢æ—¥æœŸ(enddate)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if ann_date:
                params['ann_date'] = ann_date
            if enddate:
                params['enddate'] = enddate
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # è·å–è‚¡ä¸œæˆ·æ•°æ•°æ®
            df = pro.stk_holdernumber(**params)
            
            if df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                if ann_date:
                    param_info.append(f"å…¬å‘Šæ—¥æœŸ: {ann_date}")
                if enddate:
                    param_info.append(f"æˆªæ­¢æ—¥æœŸ: {enddate}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ä¸œæˆ·æ•°æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'ann_date' in df.columns:
                df = df.sort_values('ann_date', ascending=False)
            elif 'end_date' in df.columns:
                df = df.sort_values('end_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = []
            result.append("ğŸ“Š ä¸Šå¸‚å…¬å¸è‚¡ä¸œæˆ·æ•°æ•°æ®")
            result.append("=" * 100)
            result.append("")
            
            # æ˜¾ç¤ºæŸ¥è¯¢æ¡ä»¶
            query_info = []
            if ts_code:
                query_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
            if ann_date:
                query_info.append(f"å…¬å‘Šæ—¥æœŸ: {ann_date}")
            if enddate:
                query_info.append(f"æˆªæ­¢æ—¥æœŸ: {enddate}")
            if start_date or end_date:
                date_range = f"{start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}"
                query_info.append(f"æ—¥æœŸèŒƒå›´: {date_range}")
            
            if query_info:
                result.append("æŸ¥è¯¢æ¡ä»¶:")
                for info in query_info:
                    result.append(f"  - {info}")
                result.append("")
            
            # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
            result.append(f"ğŸ“ˆ å…±æ‰¾åˆ° {len(df)} æ¡è‚¡ä¸œæˆ·æ•°è®°å½•")
            result.append("")
            
            # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤ºï¼ˆå¦‚æœæŸ¥è¯¢äº†å¤šä¸ªè‚¡ç¥¨ï¼‰
            if not ts_code:
                # å¦‚æœæœªæŒ‡å®šè‚¡ç¥¨ä»£ç ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
                codes = df['ts_code'].unique()
                for code in codes[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªè‚¡ç¥¨
                    code_df = df[df['ts_code'] == code].copy()
                    result.append(format_holder_number_data(code_df, code))
                    result.append("")
                
                if len(codes) > 10:
                    result.append(f"ï¼ˆå…± {len(codes)} ä¸ªè‚¡ç¥¨ï¼Œä»…æ˜¾ç¤ºå‰ 10 ä¸ªï¼‰")
            else:
                # å•ä¸ªè‚¡ç¥¨ï¼Œç›´æ¥æ˜¾ç¤º
                result.append(format_holder_number_data(df, ts_code))
            
            result.append("")
            result.append("ğŸ“ è¯´æ˜ï¼š")
            result.append("  - æ•°æ®æ¥æºäºä¸Šå¸‚å…¬å¸å®šæœŸæŠ¥å‘Šï¼Œä¸å®šæœŸå…¬å¸ƒ")
            result.append("  - è‚¡ä¸œæˆ·æ•°å¢åŠ é€šå¸¸è¡¨ç¤ºæŒè‚¡åˆ†æ•£ï¼Œå‡å°‘è¡¨ç¤ºæŒè‚¡é›†ä¸­")
            result.append("  - å»ºè®®ç»“åˆè‚¡ä»·èµ°åŠ¿åˆ†æè‚¡ä¸œæˆ·æ•°å˜åŒ–è¶‹åŠ¿")
            
            return "\n".join(result)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_stock_moneyflow_dc(
        ts_code: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–ä¸œæ–¹è´¢å¯Œä¸ªè‚¡èµ„é‡‘æµå‘æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600111.SHï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨ï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241011ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«èµ„é‡‘æµå‘æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œï¼Œæ¯æ—¥ç›˜åæ›´æ–°ï¼Œæ•°æ®å¼€å§‹äº20230911
            - æ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç ã€äº¤æ˜“æ—¥æœŸã€æ—¥æœŸèŒƒå›´ç­›é€‰
            - æ˜¾ç¤ºä¸»åŠ›å‡€æµå…¥é¢ã€è¶…å¤§å•/å¤§å•/ä¸­å•/å°å•çš„å‡€æµå…¥é¢å’Œå æ¯”
            - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†
            - é™é‡ï¼šå•æ¬¡æœ€å¤§è·å–6000æ¡æ•°æ®ï¼Œå¯æ ¹æ®æ—¥æœŸæˆ–è‚¡ç¥¨ä»£ç å¾ªç¯æå–
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not trade_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šè‚¡ç¥¨ä»£ç (ts_code)ã€äº¤æ˜“æ—¥æœŸ(trade_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if trade_date:
                params['trade_date'] = trade_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'ts_code': ts_code or '',
                'trade_date': trade_date or '',
                'start_date': start_date or '',
                'end_date': end_date or ''
            }
            df = cache_manager.get_dataframe('moneyflow_dc', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('moneyflow_dc', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                df = pro.moneyflow_dc(**params)
                
                # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                if not df.empty:
                    cache_manager.set('moneyflow_dc', df, **cache_params)
            
            if df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„èµ„é‡‘æµå‘æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰äº¤æ˜“æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'trade_date' in df.columns:
                df = df.sort_values('trade_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_moneyflow_dc_data(df, ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_stock_survey(
        ts_code: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–ä¸Šå¸‚å…¬å¸æœºæ„è°ƒç ”è®°å½•æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š002223.SZï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨ï¼‰
            trade_date: è°ƒç ”æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20211024ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„è°ƒç ”æ•°æ®ï¼‰
            start_date: è°ƒç ”å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: è°ƒç ”ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«æœºæ„è°ƒç ”æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºäºä¸Šå¸‚å…¬å¸æŠ«éœ²çš„æœºæ„è°ƒç ”è®°å½•
            - æ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç ã€è°ƒç ”æ—¥æœŸã€æ—¥æœŸèŒƒå›´ç­›é€‰
            - æ˜¾ç¤ºæœºæ„å‚ä¸äººå‘˜ã€æ¥å¾…åœ°ç‚¹ã€æ¥å¾…æ–¹å¼ã€æ¥å¾…å…¬å¸ç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†
            - é™é‡ï¼šå•æ¬¡æœ€å¤§è·å–100æ¡æ•°æ®ï¼Œå¯å¾ªç¯æˆ–åˆ†é¡µæå–
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not trade_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šè‚¡ç¥¨ä»£ç (ts_code)ã€è°ƒç ”æ—¥æœŸ(trade_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            # å‚æ•°å¤„ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸º Noneï¼Œä¾¿äºåç»­å¤„ç†
            ts_code = ts_code.strip() if ts_code else None
            trade_date = trade_date.strip() if trade_date else None
            start_date = start_date.strip() if start_date else None
            end_date = end_date.strip() if end_date else None
            
            if trade_date and (start_date or end_date):
                # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
                start_date = None
                end_date = None
            
            # ä»ä¸“ç”¨ç¼“å­˜è¡¨æŸ¥è¯¢æ•°æ®ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
            df = None
            need_fetch_from_api = False
            
            if trade_date:
                # æŸ¥è¯¢ç‰¹å®šæ—¥æœŸ
                if ts_code:
                    df = stk_surv_cache_manager.get_stk_surv_data(
                        ts_code=ts_code,
                        trade_date=trade_date
                    )
                else:
                    # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æ•°æ®
                    df = stk_surv_cache_manager.get_stk_surv_data(
                        trade_date=trade_date
                    )
                if df is None or df.empty:
                    need_fetch_from_api = True
            elif start_date or end_date:
                # æŸ¥è¯¢æ—¥æœŸèŒƒå›´ï¼ˆè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ—¥æœŸå‚æ•°ï¼‰
                if ts_code:
                    df = stk_surv_cache_manager.get_stk_surv_data(
                        ts_code=ts_code,
                        start_date=start_date,
                        end_date=end_date
                    )
                    # æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å®Œæ•´è¦†ç›–è¯·æ±‚çš„æ—¥æœŸèŒƒå›´
                    if df is None or df.empty:
                        need_fetch_from_api = True
                    elif not stk_surv_cache_manager.is_cache_data_complete(ts_code, start_date, end_date):
                        # ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»APIè·å–å®Œæ•´æ•°æ®
                        need_fetch_from_api = True
                else:
                    # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨åœ¨æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
                    df = stk_surv_cache_manager.get_stk_surv_data(
                        start_date=start_date,
                        end_date=end_date
                    )
                    if df is None or df.empty:
                        need_fetch_from_api = True
            else:
                # æŸ¥è¯¢æœ€è¿‘æ•°æ®ï¼ˆä»ç¼“å­˜è·å–æœ€æ–°æ•°æ®ï¼‰
                if ts_code:
                    df = stk_surv_cache_manager.get_stk_surv_data(
                        ts_code=ts_code,
                        limit=100,
                        order_by='DESC'
                    )
                else:
                    return "æŸ¥è¯¢æœ€è¿‘æ•°æ®æ—¶ï¼Œè¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)"
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
                if df is None or df.empty:
                    need_fetch_from_api = True
            
            # å¦‚æœéœ€è¦ä»APIè·å–æ•°æ®
            if need_fetch_from_api:
                pro = ts.pro_api()
                params = {}
                
                if ts_code:
                    params['ts_code'] = ts_code
                
                # ä¼˜å…ˆä½¿ç”¨trade_dateï¼Œå¦åˆ™ä½¿ç”¨æ—¥æœŸèŒƒå›´
                if trade_date:
                    params['trade_date'] = trade_date
                else:
                    if start_date:
                        params['start_date'] = start_date
                    if end_date:
                        params['end_date'] = end_date
                
                df = pro.stk_surv(**params)
                
                # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜è¡¨ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
                if not df.empty:
                    saved_count = stk_surv_cache_manager.save_stk_surv_data(df)
                    # å¦‚æœæŸ¥è¯¢çš„æ˜¯ç‰¹å®šæ—¥æœŸæˆ–èŒƒå›´ï¼Œé‡æ–°ä»ç¼“å­˜è¯»å–ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if trade_date:
                        if ts_code:
                            df = stk_surv_cache_manager.get_stk_surv_data(
                                ts_code=ts_code,
                                trade_date=trade_date
                            )
                        else:
                            df = stk_surv_cache_manager.get_stk_surv_data(
                                trade_date=trade_date
                            )
                    elif start_date or end_date:
                        if ts_code:
                            df = stk_surv_cache_manager.get_stk_surv_data(
                                ts_code=ts_code,
                                start_date=start_date,
                                end_date=end_date
                            )
                        else:
                            df = stk_surv_cache_manager.get_stk_surv_data(
                                start_date=start_date,
                                end_date=end_date
                            )
                    else:
                        # æŸ¥è¯¢æœ€è¿‘æ•°æ®
                        df = stk_surv_cache_manager.get_stk_surv_data(
                            ts_code=ts_code,
                            limit=100,
                            order_by='DESC'
                        )
            
            if df is None or df.empty:
                stock_info = f"è‚¡ç¥¨ {ts_code}" if ts_code else "è‚¡ç¥¨"
                
                if trade_date:
                    date_info = f"è°ƒç ”æ—¥æœŸ {trade_date}"
                elif start_date or end_date:
                    if start_date and end_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ {start_date} è‡³ {end_date}"
                    elif start_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ä» {start_date} å¼€å§‹"
                    else:
                        date_info = f"æ—¥æœŸèŒƒå›´åˆ° {end_date} ç»“æŸ"
                else:
                    date_info = "æœ€è¿‘æ•°æ®"
                return f"æœªæ‰¾åˆ° {stock_info} åœ¨ {date_info} çš„æœºæ„è°ƒç ”æ•°æ®ï¼Œè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®"
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_stock_survey_data(df, ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_cyq_perf(
        ts_code: str,
        trade_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–Aè‚¡æ¯æ—¥ç­¹ç å¹³å‡æˆæœ¬å’Œèƒœç‡æƒ…å†µ
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¿…å¡«ï¼Œå¦‚ï¼š600000.SHï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20220429ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20220101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20220429ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«æ¯æ—¥ç­¹ç åŠèƒœç‡æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬è®¡ç®—çš„ç­¹ç é›†ä¸­åº¦
        
        è¯´æ˜:
            - æ•°æ®æ¯å¤©17~18ç‚¹å·¦å³æ›´æ–°ï¼Œæ•°æ®ä»2018å¹´å¼€å§‹
            - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†æ¯å¤©20000æ¬¡ï¼Œ10000ç§¯åˆ†æ¯å¤©200000æ¬¡ï¼Œ15000ç§¯åˆ†æ¯å¤©ä¸é™æ€»é‡
            - é™é‡ï¼šå•æ¬¡æœ€å¤§5000æ¡ï¼Œå¯ä»¥åˆ†é¡µæˆ–è€…å¾ªç¯æå–
            - ç­¹ç é›†ä¸­åº¦è®¡ç®—å…¬å¼ï¼šé›†ä¸­åº¦ = (cost_95pct - cost_5pct) / (cost_95pct + cost_5pct)
            - é›†ä¸­åº¦è¶Šå°ï¼Œè¯´æ˜ç­¹ç è¶Šé›†ä¸­ï¼›é›†ä¸­åº¦è¶Šå¤§ï¼Œè¯´æ˜ç­¹ç è¶Šåˆ†æ•£
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code:
            return "è¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)"
        
        try:
            # å‚æ•°å¤„ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸º Noneï¼Œä¾¿äºåç»­å¤„ç†
            ts_code = ts_code.strip()
            trade_date = trade_date.strip() if trade_date else None
            start_date = start_date.strip() if start_date else None
            end_date = end_date.strip() if end_date else None
            
            if trade_date and (start_date or end_date):
                # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
                start_date = None
                end_date = None
            
            # ä»ä¸“ç”¨ç¼“å­˜è¡¨æŸ¥è¯¢æ•°æ®ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
            df = None
            need_fetch_from_api = False
            
            if trade_date:
                # æŸ¥è¯¢ç‰¹å®šæ—¥æœŸ
                df = cyq_perf_cache_manager.get_cyq_perf_data(
                    ts_code=ts_code,
                    trade_date=trade_date
                )
                if df is None or df.empty:
                    need_fetch_from_api = True
            elif start_date or end_date:
                # æŸ¥è¯¢æ—¥æœŸèŒƒå›´ï¼ˆè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ—¥æœŸå‚æ•°ï¼‰
                df = cyq_perf_cache_manager.get_cyq_perf_data(
                    ts_code=ts_code,
                    start_date=start_date,
                    end_date=end_date
                )
                # æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å®Œæ•´è¦†ç›–è¯·æ±‚çš„æ—¥æœŸèŒƒå›´
                if df is None or df.empty:
                    need_fetch_from_api = True
                elif not cyq_perf_cache_manager.is_cache_data_complete(ts_code, start_date, end_date):
                    # ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»APIè·å–å®Œæ•´æ•°æ®
                    need_fetch_from_api = True
            else:
                # æŸ¥è¯¢æœ€è¿‘æ•°æ®ï¼ˆä»ç¼“å­˜è·å–æœ€æ–°æ•°æ®ï¼‰
                df = cyq_perf_cache_manager.get_cyq_perf_data(
                    ts_code=ts_code,
                    limit=30,
                    order_by='DESC'
                )
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
                if df is None or df.empty:
                    need_fetch_from_api = True
            
            # å¦‚æœéœ€è¦ä»APIè·å–æ•°æ®
            if need_fetch_from_api:
                pro = ts.pro_api()
                params = {'ts_code': ts_code}
                
                # ä¼˜å…ˆä½¿ç”¨trade_dateï¼Œå¦åˆ™ä½¿ç”¨æ—¥æœŸèŒƒå›´
                if trade_date:
                    params['trade_date'] = trade_date
                else:
                    if start_date:
                        params['start_date'] = start_date
                    if end_date:
                        params['end_date'] = end_date
                
                df = pro.cyq_perf(**params)
                
                # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜è¡¨ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
                if not df.empty:
                    saved_count = cyq_perf_cache_manager.save_cyq_perf_data(df)
                    # å¦‚æœæŸ¥è¯¢çš„æ˜¯ç‰¹å®šæ—¥æœŸæˆ–èŒƒå›´ï¼Œé‡æ–°ä»ç¼“å­˜è¯»å–ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if trade_date:
                        df = cyq_perf_cache_manager.get_cyq_perf_data(
                            ts_code=ts_code,
                            trade_date=trade_date
                        )
                    elif start_date or end_date:
                        df = cyq_perf_cache_manager.get_cyq_perf_data(
                            ts_code=ts_code,
                            start_date=start_date,
                            end_date=end_date
                        )
                    else:
                        # æŸ¥è¯¢æœ€è¿‘æ•°æ®
                        df = cyq_perf_cache_manager.get_cyq_perf_data(
                            ts_code=ts_code,
                            limit=30,
                            order_by='DESC'
                        )
            
            if df is None or df.empty:
                if trade_date:
                    date_info = f"æ—¥æœŸ {trade_date}"
                elif start_date or end_date:
                    if start_date and end_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ {start_date} è‡³ {end_date}"
                    elif start_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ä» {start_date} å¼€å§‹"
                    else:
                        date_info = f"æ—¥æœŸèŒƒå›´åˆ° {end_date} ç»“æŸ"
                else:
                    date_info = "æœ€è¿‘æ•°æ®"
                return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {ts_code} åœ¨ {date_info} çš„æ¯æ—¥ç­¹ç åŠèƒœç‡æ•°æ®ï¼Œè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®"
            
            # è®¡ç®—ç­¹ç é›†ä¸­åº¦
            # é›†ä¸­åº¦ = (cost_95pct - cost_5pct) / (cost_95pct + cost_5pct)
            if 'cost_95pct' in df.columns and 'cost_5pct' in df.columns:
                df['concentration'] = (df['cost_95pct'] - df['cost_5pct']) / (df['cost_95pct'] + df['cost_5pct'])
                # å¤„ç†é™¤é›¶æƒ…å†µ
                df['concentration'] = df['concentration'].replace([float('inf'), float('-inf')], None)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_cyq_perf_data(df, ts_code)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_daily_basic(
        ts_code: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–æ¯æ—¥æŒ‡æ ‡æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600230.SHï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨åŒæ—¶æå–ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ï¼š600230.SH,600237.SHï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20180726ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20180101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20181231ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        æ³¨æ„:
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - æ•°æ®è¯´æ˜ï¼šè·å–æ¯æ—¥æŒ‡æ ‡æ•°æ®ï¼ŒåŒ…æ‹¬ä¼°å€¼æŒ‡æ ‡ï¼ˆPEã€PBã€PSï¼‰ã€æ¢æ‰‹ç‡ã€é‡æ¯”ã€å¸‚å€¼ç­‰
        
        è¿”å›:
            åŒ…å«æ¯æ—¥æŒ‡æ ‡æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not trade_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šè‚¡ç¥¨ä»£ç (ts_code)ã€äº¤æ˜“æ—¥æœŸ(trade_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            # å‚æ•°å¤„ç†ï¼šå°†ç©ºå­—ç¬¦ä¸²è½¬æ¢ä¸º Noneï¼Œä¾¿äºåç»­å¤„ç†
            ts_code = ts_code.strip() if ts_code else None
            trade_date = trade_date.strip() if trade_date else None
            start_date = start_date.strip() if start_date else None
            end_date = end_date.strip() if end_date else None
            
            if trade_date and (start_date or end_date):
                # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
                start_date = None
                end_date = None
            
            # ä»ä¸“ç”¨ç¼“å­˜è¡¨æŸ¥è¯¢æ•°æ®ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
            df = None
            need_fetch_from_api = False
            
            if trade_date:
                # æŸ¥è¯¢ç‰¹å®šæ—¥æœŸ
                if ts_code:
                    df = daily_basic_cache_manager.get_daily_basic_data(
                        ts_code=ts_code,
                        trade_date=trade_date
                    )
                else:
                    # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æ•°æ®
                    df = daily_basic_cache_manager.get_daily_basic_data(
                        trade_date=trade_date
                    )
                if df is None or df.empty:
                    need_fetch_from_api = True
            elif start_date or end_date:
                # æŸ¥è¯¢æ—¥æœŸèŒƒå›´ï¼ˆè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæ—¥æœŸå‚æ•°ï¼‰
                if ts_code:
                    df = daily_basic_cache_manager.get_daily_basic_data(
                        ts_code=ts_code,
                        start_date=start_date,
                        end_date=end_date
                    )
                    # æ£€æŸ¥ç¼“å­˜æ•°æ®æ˜¯å¦å®Œæ•´è¦†ç›–è¯·æ±‚çš„æ—¥æœŸèŒƒå›´
                    if df is None or df.empty:
                        need_fetch_from_api = True
                    elif not daily_basic_cache_manager.is_cache_data_complete(ts_code, start_date, end_date):
                        # ç¼“å­˜æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»APIè·å–å®Œæ•´æ•°æ®
                        need_fetch_from_api = True
                else:
                    # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨åœ¨æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
                    df = daily_basic_cache_manager.get_daily_basic_data(
                        start_date=start_date,
                        end_date=end_date
                    )
                    if df is None or df.empty:
                        need_fetch_from_api = True
            else:
                # æŸ¥è¯¢æœ€è¿‘æ•°æ®ï¼ˆä»ç¼“å­˜è·å–æœ€æ–°æ•°æ®ï¼‰
                if ts_code:
                    df = daily_basic_cache_manager.get_daily_basic_data(
                        ts_code=ts_code,
                        limit=30,
                        order_by='DESC'
                    )
                else:
                    return "æŸ¥è¯¢æœ€è¿‘æ•°æ®æ—¶ï¼Œè¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)"
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œéœ€è¦ä»APIè·å–
                if df is None or df.empty:
                    need_fetch_from_api = True
            
            # å¦‚æœéœ€è¦ä»APIè·å–æ•°æ®
            if need_fetch_from_api:
                pro = ts.pro_api()
                params = {}
                
                if ts_code:
                    params['ts_code'] = ts_code
                
                # ä¼˜å…ˆä½¿ç”¨trade_dateï¼Œå¦åˆ™ä½¿ç”¨æ—¥æœŸèŒƒå›´
                if trade_date:
                    params['trade_date'] = trade_date
                else:
                    if start_date:
                        params['start_date'] = start_date
                    if end_date:
                        params['end_date'] = end_date
                
                df = pro.daily_basic(**params)
                
                # ä¿å­˜åˆ°ä¸“ç”¨ç¼“å­˜è¡¨ï¼ˆæ°¸ä¸å¤±æ•ˆï¼‰
                if not df.empty:
                    saved_count = daily_basic_cache_manager.save_daily_basic_data(df)
                    # å¦‚æœæŸ¥è¯¢çš„æ˜¯ç‰¹å®šæ—¥æœŸæˆ–èŒƒå›´ï¼Œé‡æ–°ä»ç¼“å­˜è¯»å–ä»¥ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
                    if trade_date:
                        if ts_code:
                            df = daily_basic_cache_manager.get_daily_basic_data(
                                ts_code=ts_code,
                                trade_date=trade_date
                            )
                        else:
                            df = daily_basic_cache_manager.get_daily_basic_data(
                                trade_date=trade_date
                            )
                    elif start_date or end_date:
                        if ts_code:
                            df = daily_basic_cache_manager.get_daily_basic_data(
                                ts_code=ts_code,
                                start_date=start_date,
                                end_date=end_date
                            )
                        else:
                            df = daily_basic_cache_manager.get_daily_basic_data(
                                start_date=start_date,
                                end_date=end_date
                            )
                    else:
                        # æŸ¥è¯¢æœ€è¿‘æ•°æ®
                        df = daily_basic_cache_manager.get_daily_basic_data(
                            ts_code=ts_code,
                            limit=30,
                            order_by='DESC'
                        )
            
            if df is None or df.empty:
                stock_info = f"è‚¡ç¥¨ {ts_code}" if ts_code else "è‚¡ç¥¨"
                
                if trade_date:
                    date_info = f"æ—¥æœŸ {trade_date}"
                elif start_date or end_date:
                    if start_date and end_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ {start_date} è‡³ {end_date}"
                    elif start_date:
                        date_info = f"æ—¥æœŸèŒƒå›´ä» {start_date} å¼€å§‹"
                    else:
                        date_info = f"æ—¥æœŸèŒƒå›´åˆ° {end_date} ç»“æŸ"
                else:
                    date_info = "æœ€è¿‘æ•°æ®"
                return f"æœªæ‰¾åˆ° {stock_info} åœ¨ {date_info} çš„æ¯æ—¥æŒ‡æ ‡æ•°æ®ï¼Œè¯·æ£€æŸ¥å‚æ•°æ˜¯å¦æ­£ç¡®"
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_daily_basic_data(df, ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_top_list(
        trade_date: str = "",
        ts_code: str = ""
    ) -> str:
        """
        è·å–é¾™è™æ¦œæ¯æ—¥äº¤æ˜“æ˜ç»†æ•°æ®
        
        å‚æ•°:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20180928ï¼Œå¿…å¡«ï¼‰
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š002219.SZï¼Œå¯é€‰ï¼‰
        
        è¿”å›:
            åŒ…å«é¾™è™æ¦œäº¤æ˜“æ˜ç»†æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare top_listæ¥å£
            - æ•°æ®å†å²ï¼š2005å¹´è‡³ä»Š
            - æ˜¾ç¤ºæ”¶ç›˜ä»·ã€æ¶¨è·Œå¹…ã€æ¢æ‰‹ç‡ã€æ€»æˆäº¤é¢ã€é¾™è™æ¦œä¹°å…¥/å–å‡ºé¢ã€å‡€ä¹°å…¥é¢ç­‰æ•°æ®
            - æ˜¾ç¤ºä¸Šæ¦œç†ç”±ï¼ˆå¦‚ï¼šæ—¥æ¶¨å¹…åç¦»å€¼è¾¾åˆ°7%ã€æ—¥æ¢æ‰‹ç‡è¾¾åˆ°20%ç­‰ï¼‰
            - æƒé™è¦æ±‚ï¼š2000ç§¯åˆ†
            - é™é‡ï¼šå•æ¬¡è¯·æ±‚è¿”å›æœ€å¤§10000è¡Œæ•°æ®
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼štrade_dateæ˜¯å¿…å¡«å‚æ•°
        if not trade_date:
            return "è¯·æä¾›äº¤æ˜“æ—¥æœŸ(trade_date)ï¼Œæ ¼å¼ï¼šYYYYMMDDï¼ˆå¦‚ï¼š20180928ï¼‰"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                'trade_date': trade_date
            }
            if ts_code:
                params['ts_code'] = ts_code
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'trade_date': trade_date,
                'ts_code': ts_code or ''
            }
            df = cache_manager.get_dataframe('top_list', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('top_list', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.top_list(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('top_list', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼štop_list\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°2000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤top_listæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿ"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°2000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥"
            
            if df is None or df.empty:
                param_info = f"äº¤æ˜“æ—¥æœŸ: {trade_date}"
                if ts_code:
                    param_info += f", è‚¡ç¥¨ä»£ç : {ts_code}"
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é¾™è™æ¦œæ•°æ®\næŸ¥è¯¢æ¡ä»¶: {param_info}\n\næç¤ºï¼š\n- è¯·ç¡®è®¤è¯¥æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n- è¯¥æ—¥æœŸæ˜¯å¦æœ‰è‚¡ç¥¨ä¸Šæ¦œé¾™è™æ¦œ"
            
            # æŒ‰è‚¡ç¥¨ä»£ç å’Œäº¤æ˜“æ—¥æœŸæ’åº
            if 'ts_code' in df.columns:
                df = df.sort_values(['ts_code', 'trade_date'], ascending=[True, False])
            elif 'trade_date' in df.columns:
                df = df.sort_values('trade_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_top_list_data(df, trade_date, ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_top_inst(
        trade_date: str = "",
        ts_code: str = ""
    ) -> str:
        """
        è·å–é¾™è™æ¦œæœºæ„æˆäº¤æ˜ç»†æ•°æ®
        
        å‚æ•°:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20210525ï¼Œå¿…å¡«ï¼‰
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000592.SZï¼Œå¯é€‰ï¼‰
        
        è¿”å›:
            åŒ…å«é¾™è™æ¦œæœºæ„æˆäº¤æ˜ç»†æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare top_instæ¥å£
            - æ˜¾ç¤ºè¥ä¸šéƒ¨åç§°ã€ä¹°å–ç±»å‹ã€ä¹°å…¥é¢ã€å–å‡ºé¢ã€å‡€æˆäº¤é¢ç­‰æ•°æ®
            - ä¹°å–ç±»å‹ï¼š0=ä¹°å…¥é‡‘é¢æœ€å¤§çš„å‰5åï¼Œ1=å–å‡ºé‡‘é¢æœ€å¤§çš„å‰5å
            - æ˜¾ç¤ºä¸Šæ¦œç†ç”±ï¼ˆå¦‚ï¼šæ¶¨å¹…åç¦»å€¼è¾¾7%ã€è¿ç»­ä¸‰ä¸ªäº¤æ˜“æ—¥å†…æ¶¨å¹…åç¦»å€¼ç´¯è®¡è¾¾20%ç­‰ï¼‰
            - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†
            - é™é‡ï¼šå•æ¬¡è¯·æ±‚æœ€å¤§è¿”å›10000è¡Œæ•°æ®
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼štrade_dateæ˜¯å¿…å¡«å‚æ•°
        if not trade_date:
            return "è¯·æä¾›äº¤æ˜“æ—¥æœŸ(trade_date)ï¼Œæ ¼å¼ï¼šYYYYMMDDï¼ˆå¦‚ï¼š20210525ï¼‰"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                'trade_date': trade_date
            }
            if ts_code:
                params['ts_code'] = ts_code
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'trade_date': trade_date,
                'ts_code': ts_code or ''
            }
            df = cache_manager.get_dataframe('top_inst', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('top_inst', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.top_inst(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('top_inst', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼štop_inst\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°5000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤top_instæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿ"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°5000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥"
            
            if df is None or df.empty:
                param_info = f"äº¤æ˜“æ—¥æœŸ: {trade_date}"
                if ts_code:
                    param_info += f", è‚¡ç¥¨ä»£ç : {ts_code}"
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é¾™è™æ¦œæœºæ„æ˜ç»†æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {param_info}\n\næç¤ºï¼š\n- è¯·ç¡®è®¤è¯¥æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n- è¯¥æ—¥æœŸæ˜¯å¦æœ‰æœºæ„ä¸Šæ¦œé¾™è™æ¦œ"
            
            # æŒ‰è‚¡ç¥¨ä»£ç ã€ä¹°å–ç±»å‹å’Œäº¤æ˜“æ—¥æœŸæ’åº
            if 'ts_code' in df.columns:
                df = df.sort_values(['ts_code', 'side', 'trade_date'], ascending=[True, True, False])
            elif 'side' in df.columns:
                df = df.sort_values(['side', 'trade_date'], ascending=[True, False])
            elif 'trade_date' in df.columns:
                df = df.sort_values('trade_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_top_inst_data(df, trade_date, ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    # ==================== Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ… ç‹¬ç«‹å‡½æ•° ====================
    def _fetch_stock_min_data(
        ts_code: str = "",
        freq: str = "1MIN",
        date_str: str = ""
    ) -> str:
        """
        è·å–Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æ•°æ®ï¼ˆç‹¬ç«‹å®ç°å‡½æ•°ï¼‰
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¿…å¡«ï¼Œå¦‚ï¼š600000.SHï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ï¼š600000.SH,000001.SZï¼‰
            freq: åˆ†é’Ÿé¢‘åº¦ï¼ˆå¿…å¡«ï¼Œé»˜è®¤1MINï¼‰
                - 1MIN: 1åˆ†é’Ÿ
                - 5MIN: 5åˆ†é’Ÿ
                - 15MIN: 15åˆ†é’Ÿ
                - 30MIN: 30åˆ†é’Ÿ
                - 60MIN: 60åˆ†é’Ÿ
            date_str: å›æ”¾æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼Œé»˜è®¤ä¸ºäº¤æ˜“å½“æ—¥ï¼Œæ”¯æŒå›æº¯ä¸€å¤©ï¼‰
                å¦‚æœæä¾›æ­¤å‚æ•°ï¼Œå°†ä½¿ç”¨rt_min_dailyæ¥å£è·å–å½“æ—¥å¼€ç›˜ä»¥æ¥çš„æ‰€æœ‰å†å²åˆ†é’Ÿæ•°æ®
        
        è¿”å›:
            åŒ…å«Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare rt_minæ¥å£ï¼ˆå®æ—¶ï¼‰æˆ–rt_min_dailyæ¥å£ï¼ˆå†å²å›æ”¾ï¼‰
            - æ”¯æŒ1min/5min/15min/30min/60minè¡Œæƒ…
            - æ˜¾ç¤ºå¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ã€æˆäº¤é‡ã€æˆäº¤é¢ç­‰æ•°æ®
            - æƒé™è¦æ±‚ï¼šæ­£å¼æƒé™è¯·å‚é˜…æƒé™è¯´æ˜
            - é™é‡ï¼šå•æ¬¡æœ€å¤§1000è¡Œæ•°æ®ï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨åŒæ—¶æå–
            - æ³¨æ„ï¼šrt_min_dailyæ¥å£ä»…æ”¯æŒå•ä¸ªè‚¡ç¥¨æå–ï¼Œä¸èƒ½åŒæ—¶æå–å¤šä¸ª
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code:
            return "è¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)ï¼Œå¦‚ï¼š600000.SHï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨ï¼ˆé€—å·åˆ†éš”ï¼‰"
        
        # éªŒè¯freqå‚æ•°
        valid_freqs = ['1MIN', '5MIN', '15MIN', '30MIN', '60MIN']
        if freq.upper() not in valid_freqs:
            return f"æ— æ•ˆçš„åˆ†é’Ÿé¢‘åº¦: {freq}\næ”¯æŒçš„é¢‘åº¦ï¼š{', '.join(valid_freqs)}"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                'ts_code': ts_code,
                'freq': freq.upper()
            }
            
            # åˆ¤æ–­ä½¿ç”¨å“ªä¸ªæ¥å£
            use_daily = bool(date_str)
            if use_daily:
                params['date_str'] = date_str
                # å¦‚æœæä¾›äº†date_strï¼Œä½¿ç”¨rt_min_dailyæ¥å£ï¼ˆåªæ”¯æŒå•ä¸ªè‚¡ç¥¨ï¼‰
                codes = [code.strip() for code in ts_code.split(',')]
                if len(codes) > 1:
                    return "rt_min_dailyæ¥å£åªæ”¯æŒä¸€æ¬¡ä¸€ä¸ªè‚¡ç¥¨çš„å›æ”¾ï¼Œè¯·æä¾›å•ä¸ªè‚¡ç¥¨ä»£ç "
            
            # å®æ—¶æ•°æ®ä¸ç¼“å­˜ï¼Œå†å²å›æ”¾æ•°æ®å¯ä»¥ç¼“å­˜
            df = None
            if use_daily:
                cache_params = {
                    'ts_code': ts_code,
                    'freq': freq.upper(),
                    'date_str': date_str
                }
                df = cache_manager.get_dataframe('stock_min_daily', **cache_params)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
                need_update = False
                if df is None:
                    need_update = True
                elif cache_manager.is_expired('stock_min_daily', **cache_params):
                    need_update = True
                
                if need_update:
                    # ä½¿ç”¨rt_min_dailyæ¥å£è·å–å†å²åˆ†é’Ÿæ•°æ®
                    try:
                        df = pro.rt_min_daily(**params)
                        
                        # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                        if not df.empty:
                            cache_manager.set('stock_min_daily', df, **cache_params)
                    except Exception as api_error:
                        error_msg = str(api_error)
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                        if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                            return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šrt_min_daily\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. æ˜¯å¦å·²å¼€é€šAè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æƒé™\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚ï¼š600000.SHï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤rt_min_dailyæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥æ˜¯å¦å·²å¼€é€šç›¸åº”æƒé™"
                        else:
                            return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. æ˜¯å¦å·²å¼€é€šAè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æƒé™\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®"
            else:
                # ä½¿ç”¨rt_minæ¥å£è·å–å®æ—¶åˆ†é’Ÿæ•°æ®ï¼ˆä¸ç¼“å­˜ï¼‰
                try:
                    df = pro.rt_min(**params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šrt_min\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. æ˜¯å¦å·²å¼€é€šAè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æƒé™\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚ï¼š600000.SHï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤rt_minæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥æ˜¯å¦å·²å¼€é€šç›¸åº”æƒé™"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. æ˜¯å¦å·²å¼€é€šAè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æƒé™\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®"
            
            if df is None or df.empty:
                param_info = []
                param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                param_info.append(f"åˆ†é’Ÿé¢‘åº¦: {freq}")
                if date_str:
                    param_info.append(f"å›æ”¾æ—¥æœŸ: {date_str}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„Aè‚¡åˆ†é’Ÿè¡Œæƒ…æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'time' in df.columns:
                df = df.sort_values('time', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_stock_min_data(df, ts_code, freq.upper(), date_str)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    # ==================== Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ… MCP Tool ====================
    @mcp.tool()
    def get_stock_min(
        ts_code: str = "",
        freq: str = "1MIN",
        date_str: str = ""
    ) -> str:
        """
        è·å–Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¿…å¡«ï¼Œå¦‚ï¼š600000.SHï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ï¼š600000.SH,000001.SZï¼‰
            freq: åˆ†é’Ÿé¢‘åº¦ï¼ˆå¿…å¡«ï¼Œé»˜è®¤1MINï¼‰
                - 1MIN: 1åˆ†é’Ÿ
                - 5MIN: 5åˆ†é’Ÿ
                - 15MIN: 15åˆ†é’Ÿ
                - 30MIN: 30åˆ†é’Ÿ
                - 60MIN: 60åˆ†é’Ÿ
            date_str: å›æ”¾æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼Œé»˜è®¤ä¸ºäº¤æ˜“å½“æ—¥ï¼Œæ”¯æŒå›æº¯ä¸€å¤©ï¼‰
                å¦‚æœæä¾›æ­¤å‚æ•°ï¼Œå°†ä½¿ç”¨rt_min_dailyæ¥å£è·å–å½“æ—¥å¼€ç›˜ä»¥æ¥çš„æ‰€æœ‰å†å²åˆ†é’Ÿæ•°æ®
        
        è¿”å›:
            åŒ…å«Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare rt_minæ¥å£ï¼ˆå®æ—¶ï¼‰æˆ–rt_min_dailyæ¥å£ï¼ˆå†å²å›æ”¾ï¼‰
            - æ”¯æŒ1min/5min/15min/30min/60minè¡Œæƒ…
            - æ˜¾ç¤ºå¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ã€æˆäº¤é‡ã€æˆäº¤é¢ç­‰æ•°æ®
            - æƒé™è¦æ±‚ï¼šæ­£å¼æƒé™è¯·å‚é˜…æƒé™è¯´æ˜
            - é™é‡ï¼šå•æ¬¡æœ€å¤§1000è¡Œæ•°æ®ï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨åŒæ—¶æå–
            - æ³¨æ„ï¼šrt_min_dailyæ¥å£ä»…æ”¯æŒå•ä¸ªè‚¡ç¥¨æå–ï¼Œä¸èƒ½åŒæ—¶æå–å¤šä¸ª
        """
        return _fetch_stock_min_data(ts_code=ts_code, freq=freq, date_str=date_str)
    
    @mcp.tool()
    def get_stock_rt_k(
        ts_code: str = ""
    ) -> str:
        """
        è·å–æ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¿…å¡«ï¼Œæ”¯æŒé€šé…ç¬¦æ–¹å¼ï¼‰
                - å•ä¸ªè‚¡ç¥¨ï¼š600000.SHã€000001.SZã€430047.BJ
                - é€šé…ç¬¦æ–¹å¼ï¼š6*.SHï¼ˆæ‰€æœ‰6å¼€å¤´çš„æ²ªå¸‚è‚¡ç¥¨ï¼‰ã€301*.SZï¼ˆæ‰€æœ‰301å¼€å¤´çš„æ·±å¸‚è‚¡ç¥¨ï¼‰ã€0*.SZï¼ˆæ‰€æœ‰0å¼€å¤´çš„æ·±å¸‚è‚¡ç¥¨ï¼‰ã€9*.BJï¼ˆæ‰€æœ‰9å¼€å¤´çš„åŒ—äº¤æ‰€è‚¡ç¥¨ï¼‰
                - å¤šä¸ªè‚¡ç¥¨æˆ–é€šé…ç¬¦ï¼š600000.SH,000001.SZ æˆ– 6*.SH,0*.SZ
                - æ³¨æ„ï¼šä»£ç å¿…é¡»å¸¦.SH/.SZ/.BJåç¼€
        
        è¿”å›:
            åŒ…å«æ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare rt_kæ¥å£
            - è·å–å®æ—¶æ—¥kçº¿è¡Œæƒ…ï¼Œæ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç åŠè‚¡ç¥¨ä»£ç é€šé…ç¬¦ä¸€æ¬¡æ€§æå–å…¨éƒ¨è‚¡ç¥¨å®æ—¶æ—¥kçº¿è¡Œæƒ…
            - æ˜¾ç¤ºå¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ï¼ˆæœ€æ–°ä»·ï¼‰ã€æˆäº¤é‡ã€æˆäº¤é‡‘é¢ã€æˆäº¤ç¬”æ•°ã€å§”æ‰˜ä¹°å–ç›˜ç­‰æ•°æ®
            - æƒé™è¦æ±‚ï¼šæœ¬æ¥å£æ˜¯å•ç‹¬å¼€æƒé™çš„æ•°æ®ï¼Œå•ç‹¬ç”³è¯·æƒé™è¯·å‚è€ƒæƒé™åˆ—è¡¨
            - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯æå–6000æ¡æ•°æ®ï¼Œç­‰åŒäºä¸€æ¬¡æå–å…¨å¸‚åœº
            - æ³¨æ„ï¼šä¸å»ºè®®ä¸€æ¬¡æå–å…¨å¸‚åœºï¼Œå¯åˆ†æ‰¹æå–æ€§èƒ½æ›´å¥½
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code:
            return "è¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)ï¼Œæ”¯æŒé€šé…ç¬¦æ–¹å¼ï¼Œå¦‚ï¼š600000.SHã€6*.SHã€301*.SZç­‰ï¼Œä»£ç å¿…é¡»å¸¦.SH/.SZ/.BJåç¼€"
        
        # éªŒè¯ä»£ç æ ¼å¼ï¼ˆå¿…é¡»åŒ…å«.SH/.SZ/.BJåç¼€ï¼‰
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            if not (code.endswith('.SH') or code.endswith('.SZ') or code.endswith('.BJ')):
                return f"è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯ï¼š{code}\nä»£ç å¿…é¡»å¸¦.SH/.SZ/.BJåç¼€ï¼Œå¦‚ï¼š600000.SHã€000001.SZã€430047.BJ"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                'ts_code': ts_code
            }
            
            # å®æ—¶æ•°æ®ä¸ç¼“å­˜
            try:
                df = pro.rt_k(**params)
            except Exception as api_error:
                error_msg = str(api_error)
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                    return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šrt_k\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. æ˜¯å¦å·²å¼€é€šæ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æƒé™\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå¿…é¡»å¸¦.SH/.SZ/.BJåç¼€ï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤rt_kæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥æ˜¯å¦å·²å¼€é€šç›¸åº”æƒé™"
                else:
                    return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. æ˜¯å¦å·²å¼€é€šæ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æƒé™\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®"
            
            if df is None or df.empty:
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æ•°æ®\næŸ¥è¯¢æ¡ä»¶: è‚¡ç¥¨ä»£ç : {ts_code}"
            
            # æŒ‰æˆäº¤é‡æ’åºï¼ˆé™åºï¼‰ï¼Œæ˜¾ç¤ºæœ€æ´»è·ƒçš„è‚¡ç¥¨
            if 'vol' in df.columns:
                df = df.sort_values('vol', ascending=False, na_position='last')
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_stock_rt_k_data(df, ts_code)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_share_float(
        ts_code: str = "",
        ann_date: str = "",
        float_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–é™å”®è‚¡è§£ç¦æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000998.SZï¼Œå¯é€‰ï¼‰
            ann_date: å…¬å‘Šæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20181220ï¼Œå¯é€‰ï¼‰
            float_date: è§£ç¦æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¯é€‰ï¼‰
            start_date: è§£ç¦å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: è§£ç¦ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«é™å”®è‚¡è§£ç¦æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare share_floatæ¥å£
            - æ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç ã€å…¬å‘Šæ—¥æœŸã€è§£ç¦æ—¥æœŸã€æ—¥æœŸèŒƒå›´ç­›é€‰
            - æ˜¾ç¤ºè§£ç¦æ—¥æœŸã€æµé€šè‚¡ä»½ã€æµé€šè‚¡ä»½å æ€»è‚¡æœ¬æ¯”ç‡ã€è‚¡ä¸œåç§°ã€è‚¡ä»½ç±»å‹ç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼š2000ç§¯åˆ†
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not ann_date and not float_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šè‚¡ç¥¨ä»£ç (ts_code)ã€å…¬å‘Šæ—¥æœŸ(ann_date)ã€è§£ç¦æ—¥æœŸ(float_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå¿…é¡»åŒæ—¶æä¾›start_dateå’Œend_date
        if (start_date and not end_date) or (end_date and not start_date):
            return "å¦‚æœä½¿ç”¨æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œè¯·åŒæ—¶æä¾›start_dateå’Œend_date"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if ann_date:
                params['ann_date'] = ann_date
            if float_date:
                params['float_date'] = float_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†ann_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨ann_date
            if ann_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å¦‚æœåŒæ—¶æä¾›äº†float_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨float_date
            if float_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'ts_code': ts_code or '',
                'ann_date': ann_date or '',
                'float_date': float_date or '',
                'start_date': start_date or '',
                'end_date': end_date or ''
            }
            df = cache_manager.get_dataframe('share_float', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('share_float', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.share_float(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('share_float', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šshare_float\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°2000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤share_floatæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿ"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°2000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸"
            
            if df is None or df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                if ann_date:
                    param_info.append(f"å…¬å‘Šæ—¥æœŸ: {ann_date}")
                if float_date:
                    param_info.append(f"è§£ç¦æ—¥æœŸ: {float_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é™å”®è‚¡è§£ç¦æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰è§£ç¦æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'float_date' in df.columns:
                df = df.sort_values('float_date', ascending=False)
            elif 'ann_date' in df.columns:
                df = df.sort_values('ann_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_share_float_data(df, ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_stock_repurchase(
        ann_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–ä¸Šå¸‚å…¬å¸è‚¡ç¥¨å›è´­æ•°æ®
        
        å‚æ•°:
            ann_date: å…¬å‘Šæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20181010ï¼Œå¯é€‰ï¼‰
            start_date: å…¬å‘Šå¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20180101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: å…¬å‘Šç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20180510ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«è‚¡ç¥¨å›è´­æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare repurchaseæ¥å£
            - æ”¯æŒæŒ‰å…¬å‘Šæ—¥æœŸã€æ—¥æœŸèŒƒå›´ç­›é€‰
            - æ˜¾ç¤ºå…¬å‘Šæ—¥æœŸã€æˆªæ­¢æ—¥æœŸã€è¿›åº¦ã€è¿‡æœŸæ—¥æœŸã€å›è´­æ•°é‡ã€å›è´­é‡‘é¢ã€å›è´­æœ€é«˜ä»·ã€å›è´­æœ€ä½ä»·ç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼š600ç§¯åˆ†
            - æ³¨æ„ï¼šå¦‚æœéƒ½ä¸å¡«å‚æ•°ï¼Œå•æ¬¡é»˜è®¤è¿”å›2000æ¡æ•°æ®
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šå¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå¿…é¡»åŒæ—¶æä¾›start_dateå’Œend_date
        if (start_date and not end_date) or (end_date and not start_date):
            return "å¦‚æœä½¿ç”¨æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œè¯·åŒæ—¶æä¾›start_dateå’Œend_date"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ann_date:
                params['ann_date'] = ann_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†ann_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨ann_date
            if ann_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'ann_date': ann_date or '',
                'start_date': start_date or '',
                'end_date': end_date or ''
            }
            df = cache_manager.get_dataframe('repurchase', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('repurchase', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.repurchase(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('repurchase', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šrepurchase\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°600åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤repurchaseæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿ"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°600åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸"
            
            if df is None or df.empty:
                param_info = []
                if ann_date:
                    param_info.append(f"å…¬å‘Šæ—¥æœŸ: {ann_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                if not param_info:
                    param_info.append("æ— ç­›é€‰æ¡ä»¶ï¼ˆé»˜è®¤è¿”å›2000æ¡ï¼‰")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨å›è´­æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'ann_date' in df.columns:
                df = df.sort_values('ann_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_repurchase_data(df, ann_date or start_date or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_pledge_detail(
        ts_code: str = ""
    ) -> str:
        """
        è·å–è‚¡ç¥¨è‚¡æƒè´¨æŠ¼æ˜ç»†æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¿…å¡«ï¼Œå¦‚ï¼š000014.SZï¼‰
        
        è¿”å›:
            åŒ…å«è‚¡æƒè´¨æŠ¼æ˜ç»†æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare pledge_detailæ¥å£
            - æ˜¾ç¤ºè‚¡ç¥¨è´¨æŠ¼æ˜ç»†æ•°æ®ï¼ŒåŒ…æ‹¬å…¬å‘Šæ—¥æœŸã€è‚¡ä¸œåç§°ã€è´¨æŠ¼æ•°é‡ã€è´¨æŠ¼å¼€å§‹/ç»“æŸæ—¥æœŸã€æ˜¯å¦å·²è§£æŠ¼ã€è§£æŠ¼æ—¥æœŸã€è´¨æŠ¼æ–¹ã€æŒè‚¡æ€»æ•°ã€è´¨æŠ¼æ€»æ•°ã€è´¨æŠ¼æ¯”ä¾‹ç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼š500ç§¯åˆ†
            - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è°ƒå–1000æ¡æ•°æ®
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯
        if not ts_code:
            return "è¯·æä¾›è‚¡ç¥¨ä»£ç (ts_code)ï¼Œå¦‚ï¼š000014.SZ"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {
                'ts_code': ts_code
            }
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'ts_code': ts_code
            }
            df = cache_manager.get_dataframe('pledge_detail', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('pledge_detail', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.pledge_detail(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('pledge_detail', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼špledge_detail\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°500åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚ï¼š000014.SZï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤pledge_detailæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿ"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°500åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®"
            
            if df is None or df.empty:
                return f"æœªæ‰¾åˆ° {ts_code} çš„è‚¡æƒè´¨æŠ¼æ˜ç»†æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®"
            
            # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'ann_date' in df.columns:
                df = df.sort_values('ann_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_pledge_detail_data(df, ts_code)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_block_trade(
        ts_code: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–å¤§å®—äº¤æ˜“æ•°æ®
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š600436.SHï¼Œå¯é€‰ï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20181227ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«å¤§å®—äº¤æ˜“æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare block_tradeæ¥å£
            - æ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç ã€äº¤æ˜“æ—¥æœŸã€æ—¥æœŸèŒƒå›´ç­›é€‰
            - æ˜¾ç¤ºäº¤æ˜“æ—¥æœŸã€æˆäº¤ä»·ã€æˆäº¤é‡ã€æˆäº¤é‡‘é¢ã€ä¹°æ–¹è¥ä¸šéƒ¨ã€å–æ–¹è¥ä¸šéƒ¨ç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼šè¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤å…·ä½“æƒé™è¦æ±‚
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not trade_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šè‚¡ç¥¨ä»£ç (ts_code)ã€äº¤æ˜“æ—¥æœŸ(trade_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå¿…é¡»åŒæ—¶æä¾›start_dateå’Œend_date
        if (start_date and not end_date) or (end_date and not start_date):
            return "å¦‚æœä½¿ç”¨æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œè¯·åŒæ—¶æä¾›start_dateå’Œend_date"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if trade_date:
                params['trade_date'] = trade_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'ts_code': ts_code or '',
                'trade_date': trade_date or '',
                'start_date': start_date or '',
                'end_date': end_date or ''
            }
            df = cache_manager.get_dataframe('block_trade', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('block_trade', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.block_trade(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('block_trade', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šblock_trade\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°è¦æ±‚\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚ï¼š600436.SHï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤block_tradeæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿ"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°è¦æ±‚\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦æ­£ç¡®"
            
            if df is None or df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¤§å®—äº¤æ˜“æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰äº¤æ˜“æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'trade_date' in df.columns:
                df = df.sort_values('trade_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_block_trade_data(df, ts_code or "", trade_date or start_date or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    def format_announcement_signals_data(df: pd.DataFrame, ts_code_list: str = "", date_filter: str = "") -> str:
        """
        æ ¼å¼åŒ–å…¬å‘Šä¿¡å·æ•°æ®è¾“å‡º
        
        å‚æ•°:
            df: å…¬å‘Šä¿¡å·æ•°æ®DataFrame
            ts_code_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
            date_filter: æ—¥æœŸç­›é€‰æ¡ä»¶ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        
        è¿”å›:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if df.empty:
            return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å…³é”®å…¬å‘Šä¿¡å·"
        
        result = []
        result.append("ğŸ“¢ ä¸Šå¸‚å…¬å¸å…¬å‘Šä¿¡å·æ‰«æ")
        result.append("=" * 180)
        result.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_count = len(df)
        bear_count = len(df[df['signal'] == 'åˆ©ç©ºè­¦æŠ¥ (Bear)'])
        bull_count = len(df[df['signal'] == 'åˆ©å¥½å‚¬åŒ– (Bull)'])
        event_count = len(df[df['signal'] == 'é‡å¤§äº‹é¡¹ (Event)'])
        
        result.append(f"ğŸ“Š æ‰«æç»“æœç»Ÿè®¡ï¼š")
        result.append(f"  - æ€»ä¿¡å·æ•°: {total_count} æ¡")
        result.append(f"  - ğŸ”´ åˆ©ç©ºè­¦æŠ¥: {bear_count} æ¡")
        result.append(f"  - ğŸŸ¢ åˆ©å¥½å‚¬åŒ–: {bull_count} æ¡")
        result.append(f"  - ğŸŸ¡ é‡å¤§äº‹é¡¹: {event_count} æ¡")
        result.append("")
        
        if date_filter:
            result.append(f"æŸ¥è¯¢æ—¥æœŸ: {date_filter}")
        if ts_code_list:
            result.append(f"è‚¡ç¥¨ä»£ç : {ts_code_list}")
        result.append("")
        
        # æŒ‰ä¿¡å·ç±»å‹åˆ†ç»„æ˜¾ç¤º
        signal_groups = {
            'åˆ©ç©ºè­¦æŠ¥ (Bear)': 'ğŸ”´ åˆ©ç©ºè­¦æŠ¥ (Bear) - é¿é›·ä¼˜å…ˆ',
            'åˆ©å¥½å‚¬åŒ– (Bull)': 'ğŸŸ¢ åˆ©å¥½å‚¬åŒ– (Bull)',
            'é‡å¤§äº‹é¡¹ (Event)': 'ğŸŸ¡ é‡å¤§äº‹é¡¹ (Event)'
        }
        
        for signal_type, header in signal_groups.items():
            signal_df = df[df['signal'] == signal_type]
            if signal_df.empty:
                continue
            
            result.append(header)
            result.append("-" * 180)
            result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è‚¡ç¥¨ä»£ç ':<12} {'è‚¡ç¥¨åç§°':<20} {'ä¿¡å·ç±»å‹':<20} {'å…¬å‘Šæ ‡é¢˜':<80}")
            result.append("-" * 180)
            
            # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'ann_date' in signal_df.columns:
                signal_df = signal_df.sort_values('ann_date', ascending=False)
            
            display_count = min(100, len(signal_df))
            for _, row in signal_df.head(display_count).iterrows():
                ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
                ts_code = str(row.get('ts_code', '-'))[:10]
                name = str(row.get('name', '-'))[:18]
                signal = str(row.get('signal', '-'))[:18]
                title = str(row.get('title', '-'))[:78]
                
                result.append(f"{ann_date:<12} {ts_code:<12} {name:<20} {signal:<20} {title:<80}")
            
            if len(signal_df) > display_count:
                result.append(f"  ... è¿˜æœ‰ {len(signal_df) - display_count} æ¡è®°å½•æœªæ˜¾ç¤º")
            
            result.append("")
        
        # æ˜¾ç¤ºURLä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'url' in df.columns and df['url'].notna().any():
            result.append("ğŸ“ è¯´æ˜ï¼š")
            result.append("  - éƒ¨åˆ†å…¬å‘ŠåŒ…å«PDFä¸‹è½½é“¾æ¥ï¼ˆurlå­—æ®µï¼‰ï¼Œå¯é€šè¿‡Tushareæ¥å£è·å–å®Œæ•´å…¬å‘Šå†…å®¹")
            result.append("")
        
        result.append("ğŸ“ å…³é”®è¯è¯´æ˜ï¼š")
        result.append("  - åˆ©å¥½å…³é”®è¯ï¼šä¸­æ ‡ã€åˆåŒã€ç­¾ç½²ã€æ”¶è´­ã€å¢æŒã€å›è´­ã€è·å¾—ã€é€šè¿‡ã€é¢„å¢ã€æ‰­äºç­‰")
        result.append("  - åˆ©ç©ºå…³é”®è¯ï¼šç«‹æ¡ˆã€è°ƒæŸ¥ã€è­¦ç¤ºã€ç›‘ç®¡å‡½ã€é—®è¯¢ã€è¯‰è®¼ã€å†»ç»“ã€å‡æŒã€ç»ˆæ­¢ã€äºæŸç­‰")
        result.append("  - é‡å¤§äº‹é¡¹å…³é”®è¯ï¼šé‡ç»„ã€å¤ç‰Œã€å®šå¢ã€æ¿€åŠ±ã€è°ƒç ”ã€è‚¡ä¸œå¤§ä¼šç­‰")
        result.append("")
        result.append("âš ï¸ æ³¨æ„ï¼š")
        result.append("  - æœ¬å·¥å…·åŸºäºå…³é”®è¯åŒ¹é…ï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")
        result.append("  - å»ºè®®ç»“åˆå…¬å‘Šå…¨æ–‡å†…å®¹è¿›è¡Œç»¼åˆåˆ¤æ–­")
        result.append("  - æ•°æ®æ¥æºï¼šTushare anns_dæ¥å£")
        result.append("  - æƒé™è¦æ±‚ï¼šæœ¬æ¥å£ä¸ºå•ç‹¬æƒé™ï¼Œè¯·å‚è€ƒTushareæƒé™è¯´æ˜")
        result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§2000æ¡æ•°æ®ï¼Œå¯ä»¥æŒ‰æ—¥æœŸå¾ªç¯è·å–å…¨é‡")
        
        return "\n".join(result)
    
    @mcp.tool()
    def scan_announcement_signals(
        ts_code_list: str = "",
        check_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        æ‰«æä¸Šå¸‚å…¬å¸å…¬å‘Šæ ‡é¢˜ï¼Œæ•æ‰ã€é‡å¤§åˆ©å¥½ã€‘æˆ–ã€é‡å¤§åˆ©ç©ºã€‘ä¿¡å·
        
        å‚æ•°:
            ts_code_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆå¤šä¸ªä»£ç ç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š000001.SZ,600000.SHï¼Œå¯é€‰ã€‚è‹¥ä¸ºç©ºåˆ™æ‰«æå…¨å¸‚åœºï¼‰
            check_date: å…¬å‘Šæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20230621ï¼Œå¯é€‰ï¼Œé»˜è®¤å½“å¤©ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        è¿”å›:
            åŒ…å«å…³é”®å…¬å‘Šä¿¡å·çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare anns_dæ¥å£
            - æ ¹æ®å…¬å‘Šæ ‡é¢˜å…³é”®è¯è‡ªåŠ¨åˆ†ç±»ä¸ºï¼šåˆ©å¥½å‚¬åŒ–ã€åˆ©ç©ºè­¦æŠ¥ã€é‡å¤§äº‹é¡¹
            - æ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç åˆ—è¡¨å’Œæ—¥æœŸç­›é€‰
            - æƒé™è¦æ±‚ï¼šæœ¬æ¥å£ä¸ºå•ç‹¬æƒé™ï¼Œè¯·å‚è€ƒTushareæƒé™è¯´æ˜
            - é™é‡ï¼šå•æ¬¡æœ€å¤§2000æ¡æ•°æ®ï¼Œå¯ä»¥æŒ‰æ—¥æœŸå¾ªç¯è·å–å…¨é‡
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        try:
            pro = ts.pro_api()
            
            # è§£æè‚¡ç¥¨ä»£ç åˆ—è¡¨
            ts_code_filter = None
            if ts_code_list:
                ts_code_filter = [code.strip() for code in ts_code_list.split(',') if code.strip()]
            
            # æ„å»ºAPIæŸ¥è¯¢å‚æ•°
            api_params = {}
            
            # æ—¥æœŸå‚æ•°å¤„ç†
            if check_date:
                # å•æ—¥æŸ¥è¯¢ä½¿ç”¨ ann_date
                api_params['ann_date'] = check_date
                date_info = check_date
            elif start_date and end_date:
                # æ—¥æœŸèŒƒå›´æŸ¥è¯¢ä½¿ç”¨ start_date å’Œ end_dateï¼ˆAPIåŸç”Ÿæ”¯æŒï¼‰
                api_params['start_date'] = start_date
                api_params['end_date'] = end_date
                date_info = f"{start_date} è‡³ {end_date}"
            else:
                # é»˜è®¤ä½¿ç”¨å½“å¤©
                api_params['ann_date'] = datetime.now().strftime('%Y%m%d')
                date_info = api_params['ann_date']
            
            # è·å–å…¬å‘Šæ•°æ®
            all_results = []
            last_error = None  # è®°å½•æœ€åä¸€ä¸ªé”™è¯¯
            
            try:
                if ts_code_filter:
                    # æœ‰è‚¡ç¥¨ä»£ç è¿‡æ»¤æ—¶ï¼Œé€ä¸ªè‚¡ç¥¨æŸ¥è¯¢ï¼ˆAPIåŸç”Ÿæ”¯æŒts_codeå‚æ•°ï¼‰
                    for ts_code in ts_code_filter:
                        try:
                            df = pro.anns_d(ts_code=ts_code, **api_params)
                            if df is not None and not df.empty:
                                all_results.append(df)
                        except Exception as e:
                            # è®°å½•é”™è¯¯ä¿¡æ¯ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                            last_error = str(e)
                            continue
                    
                    if all_results:
                        df = pd.concat(all_results, ignore_index=True)
                    else:
                        df = pd.DataFrame()
                        # å¦‚æœæ‰€æœ‰æŸ¥è¯¢éƒ½å¤±è´¥ä¸”æœ‰æƒé™é”™è¯¯ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                        if last_error and ('æ²¡æœ‰æ¥å£è®¿é—®æƒé™' in last_error or 'æƒé™' in last_error):
                            return f"APIè°ƒç”¨å¤±è´¥ï¼š{last_error}\n\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·æ˜¯å¦æœ‰anns_dæ¥å£æƒé™ï¼ˆæœ¬æ¥å£ä¸ºå•ç‹¬æƒé™ï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤anns_dæ¥å£æƒé™\n- è®¿é—® https://tushare.pro/document/1?doc_id=108 æŸ¥çœ‹æƒé™è¯´æ˜"
                else:
                    # å…¨å¸‚åœºæŸ¥è¯¢
                    df = pro.anns_d(**api_params)
                    
            except Exception as api_error:
                error_msg = str(api_error)
                if 'æ²¡æœ‰æ¥å£è®¿é—®æƒé™' in error_msg or 'æƒé™' in error_msg:
                    return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·æ˜¯å¦æœ‰anns_dæ¥å£æƒé™ï¼ˆæœ¬æ¥å£ä¸ºå•ç‹¬æƒé™ï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤anns_dæ¥å£æƒé™\n- è®¿é—® https://tushare.pro/document/1?doc_id=108 æŸ¥çœ‹æƒé™è¯´æ˜"
                else:
                    return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·æ˜¯å¦æœ‰anns_dæ¥å£æƒé™ï¼ˆæœ¬æ¥å£ä¸ºå•ç‹¬æƒé™ï¼‰\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸"
            
            if df is None or df.empty:
                stock_info = f"ï¼ˆè‚¡ç¥¨ï¼š{ts_code_list}ï¼‰" if ts_code_list else ""
                return f"æœªæ‰¾åˆ° {date_info} {stock_info}çš„å…¬å‘Šæ•°æ®"
            
            # --- æ ¸å¿ƒé€»è¾‘ï¼šå…³é”®è¯å­—å…¸ ---
            
            # 1. è¿›æ”»å…³é”®è¯ (åˆ©å¥½)
            keywords_bull = ['ä¸­æ ‡', 'åˆåŒ', 'ç­¾ç½²', 'æ”¶è´­', 'å¢æŒ', 'å›è´­', 'è·å¾—', 'é€šè¿‡', 'é¢„å¢', 'æ‰­äº', 
                           'ç›ˆåˆ©', 'å¢é•¿', 'çªç ´', 'åˆ›æ–°', 'åˆä½œ', 'æŠ•èµ„', 'å»ºè®¾', 'æŠ•äº§', 'ä¸Šå¸‚', 'è·æ‰¹']
            
            # 2. é˜²å®ˆå…³é”®è¯ (åˆ©ç©º)
            keywords_bear = ['ç«‹æ¡ˆ', 'è°ƒæŸ¥', 'è­¦ç¤º', 'ç›‘ç®¡å‡½', 'é—®è¯¢', 'è¯‰è®¼', 'å†»ç»“', 'å‡æŒ', 'ç»ˆæ­¢', 'äºæŸ', 
                           'ä¸‹ä¿®', 'é£é™©', 'è¿è§„', 'å¤„ç½š', 'é€€å¸‚', 'ST', 'åœç‰Œ', 'ç ´äº§', 'æ¸…ç®—', 'è¿çº¦']
            
            # 3. ä¸­æ€§/é‡è¦å…³é”®è¯ (å…³æ³¨)
            keywords_neutral = ['é‡ç»„', 'å¤ç‰Œ', 'å®šå¢', 'æ¿€åŠ±', 'è°ƒç ”', 'è‚¡ä¸œå¤§ä¼š', 'è‘£äº‹ä¼š', 'å˜æ›´', 'è½¬è®©', 
                              'è´¨æŠ¼', 'è§£æŠ¼', 'åˆ†çº¢', 'é…è‚¡', 'å¯è½¬å€º']
            
            results = []
            
            for index, row in df.iterrows():
                title = str(row.get('title', ''))
                if not title:
                    continue
                
                signal_type = None
                
                # åŒ¹é…é€»è¾‘ï¼šä¼˜å…ˆåŒ¹é…åˆ©ç©ºï¼ˆé¿é›·ç¬¬ä¸€ï¼‰
                if any(k in title for k in keywords_bear):
                    signal_type = "åˆ©ç©ºè­¦æŠ¥ (Bear)"
                elif any(k in title for k in keywords_bull):
                    # ç®€å•æ’é™¤æ³•ï¼šæ¯”å¦‚ "ç»ˆæ­¢æ”¶è´­" è™½ç„¶æœ‰æ”¶è´­ï¼Œä½†æ˜¯åˆ©ç©º
                    if 'ç»ˆæ­¢' not in title and 'å–æ¶ˆ' not in title and 'å¤±è´¥' not in title:
                        signal_type = "åˆ©å¥½å‚¬åŒ– (Bull)"
                elif any(k in title for k in keywords_neutral):
                    signal_type = "é‡å¤§äº‹é¡¹ (Event)"
                
                if signal_type:
                    results.append({
                        'ts_code': row.get('ts_code', '-'),
                        'name': row.get('name', '-'),
                        'ann_date': row.get('ann_date', '-'),
                        'title': title,
                        'signal': signal_type,
                        'url': row.get('url', '-')
                    })
            
            if not results:
                stock_info = f"ï¼ˆè‚¡ç¥¨ï¼š{ts_code_list}ï¼‰" if ts_code_list else ""
                return f"æœªå‘ç° {date_info} {stock_info}çš„å…³é”®ä¿¡å·å…¬å‘Š\n\nè¯´æ˜ï¼šå…±æ‰«æ {len(df)} æ¡å…¬å‘Šï¼ŒæœªåŒ¹é…åˆ°åˆ©å¥½/åˆ©ç©º/é‡å¤§äº‹é¡¹å…³é”®è¯"
            
            # è½¬æ¢ä¸ºDataFrame
            res_df = pd.DataFrame(results)
            
            # ä¼˜å…ˆå±•ç¤ºåˆ©ç©ºï¼Œå› ä¸ºé¿é›·ç¬¬ä¸€
            signal_order = {'åˆ©ç©ºè­¦æŠ¥ (Bear)': 1, 'åˆ©å¥½å‚¬åŒ– (Bull)': 2, 'é‡å¤§äº‹é¡¹ (Event)': 3}
            res_df['signal_order'] = res_df['signal'].map(signal_order)
            res_df = res_df.sort_values(['signal_order', 'ann_date'], ascending=[True, False])
            res_df = res_df.drop('signal_order', axis=1)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_announcement_signals_data(res_df, ts_code_list or "", check_date or start_date or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æ‰«æå¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_limit_list(
        trade_date: str = "",
        ts_code: str = "",
        limit_type: str = "",
        exchange: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–Aè‚¡æ¯æ—¥æ¶¨è·Œåœã€ç‚¸æ¿æ•°æ®æƒ…å†µ
        
        å‚æ•°:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20220615ï¼Œå¯é€‰ï¼‰
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001.SZï¼Œå¯é€‰ï¼‰
            limit_type: æ¶¨è·Œåœç±»å‹ï¼ˆUæ¶¨åœã€Dè·Œåœã€Zç‚¸æ¿ï¼Œå¯é€‰ï¼‰
            exchange: äº¤æ˜“æ‰€ï¼ˆSHä¸Šäº¤æ‰€ã€SZæ·±äº¤æ‰€ã€BJåŒ—äº¤æ‰€ï¼Œå¯é€‰ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼Œå¯é€‰ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼Œå¯é€‰ï¼‰
        
        è¿”å›:
            åŒ…å«æ¶¨è·Œåœæ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare limit_list_dæ¥å£
            - æ•°æ®å†å²ï¼š2020å¹´è‡³ä»Šï¼ˆä¸æä¾›STè‚¡ç¥¨çš„ç»Ÿè®¡ï¼‰
            - æ˜¾ç¤ºæ”¶ç›˜ä»·ã€æ¶¨è·Œå¹…ã€æˆäº¤é¢ã€å°å•é‡‘é¢ã€é¦–æ¬¡/æœ€åå°æ¿æ—¶é—´ã€ç‚¸æ¿æ¬¡æ•°ã€è¿æ¿æ•°ç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†ï¼ˆæ¯åˆ†é’Ÿ200æ¬¡ï¼Œæ¯å¤©æ€»é‡1ä¸‡æ¬¡ï¼‰ï¼Œ8000ç§¯åˆ†ä»¥ä¸Šï¼ˆæ¯åˆ†é’Ÿ500æ¬¡ï¼Œæ¯å¤©æ€»é‡ä¸é™åˆ¶ï¼‰
            - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è·å–2500æ¡æ•°æ®ï¼Œå¯é€šè¿‡æ—¥æœŸæˆ–è‚¡ç¥¨å¾ªç¯æå–
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not trade_date and not ts_code and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šäº¤æ˜“æ—¥æœŸ(trade_date)ã€è‚¡ç¥¨ä»£ç (ts_code)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå¿…é¡»åŒæ—¶æä¾›start_dateå’Œend_date
        if (start_date and not end_date) or (end_date and not start_date):
            return "å¦‚æœä½¿ç”¨æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œè¯·åŒæ—¶æä¾›start_dateå’Œend_date"
        
        # éªŒè¯limit_typeå‚æ•°
        if limit_type and limit_type.upper() not in ['U', 'D', 'Z']:
            return "limit_typeå‚æ•°å€¼é”™è¯¯ï¼Œå¯é€‰å€¼ï¼šUï¼ˆæ¶¨åœï¼‰ã€Dï¼ˆè·Œåœï¼‰ã€Zï¼ˆç‚¸æ¿ï¼‰"
        
        # éªŒè¯exchangeå‚æ•°
        if exchange and exchange.upper() not in ['SH', 'SZ', 'BJ']:
            return "exchangeå‚æ•°å€¼é”™è¯¯ï¼Œå¯é€‰å€¼ï¼šSHï¼ˆä¸Šäº¤æ‰€ï¼‰ã€SZï¼ˆæ·±äº¤æ‰€ï¼‰ã€BJï¼ˆåŒ—äº¤æ‰€ï¼‰"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if trade_date:
                params['trade_date'] = trade_date
            if ts_code:
                params['ts_code'] = ts_code
            if limit_type:
                params['limit_type'] = limit_type.upper()
            if exchange:
                params['exchange'] = exchange.upper()
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'trade_date': trade_date or '',
                'ts_code': ts_code or '',
                'limit_type': limit_type.upper() if limit_type else '',
                'exchange': exchange.upper() if exchange else '',
                'start_date': start_date or '',
                'end_date': end_date or ''
            }
            df = cache_manager.get_dataframe('limit_list_d', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('limit_list_d', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.limit_list_d(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('limit_list_d', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šlimit_list_d\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°5000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤limit_list_dæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿï¼ˆéœ€è¦5000ç§¯åˆ†ï¼‰"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°5000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥"
            
            if df is None or df.empty:
                param_info = []
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if ts_code:
                    param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                if limit_type:
                    limit_type_map = {'U': 'æ¶¨åœ', 'D': 'è·Œåœ', 'Z': 'ç‚¸æ¿'}
                    param_info.append(f"ç±»å‹: {limit_type_map.get(limit_type.upper(), limit_type)}")
                if exchange:
                    exchange_map = {'SH': 'ä¸Šäº¤æ‰€', 'SZ': 'æ·±äº¤æ‰€', 'BJ': 'åŒ—äº¤æ‰€'}
                    param_info.append(f"äº¤æ˜“æ‰€: {exchange_map.get(exchange.upper(), exchange)}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¶¨è·Œåœæ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}\n\næç¤ºï¼š\n- è¯·ç¡®è®¤è¯¥æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n- è¯¥æ—¥æœŸæ˜¯å¦æœ‰è‚¡ç¥¨æ¶¨è·Œåœæˆ–ç‚¸æ¿\n- æ³¨æ„ï¼šæœ¬æ¥å£ä¸æä¾›STè‚¡ç¥¨çš„ç»Ÿè®¡"
            
            # æŒ‰äº¤æ˜“æ—¥æœŸå’Œè‚¡ç¥¨ä»£ç æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'trade_date' in df.columns:
                df = df.sort_values('trade_date', ascending=False)
            if 'ts_code' in df.columns:
                df = df.sort_values(['trade_date', 'ts_code'], ascending=[False, True])
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_limit_list_data(df, trade_date or start_date or "", ts_code or "", limit_type or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_limit_cpt_list(
        trade_date: str = "",
        ts_code: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–æ¯å¤©æ¶¨åœè‚¡ç¥¨æœ€å¤šæœ€å¼ºçš„æ¦‚å¿µæ¿å—
        
        å‚æ•°:
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241127ï¼Œå¯é€‰ï¼‰
            ts_code: æ¿å—ä»£ç ï¼ˆå¯é€‰ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼Œå¯é€‰ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼Œå¯é€‰ï¼‰
        
        è¿”å›:
            åŒ…å«æœ€å¼ºæ¿å—ç»Ÿè®¡æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šTushare limit_cpt_listæ¥å£
            - åŠŸèƒ½ï¼šè·å–æ¯å¤©æ¶¨åœè‚¡ç¥¨æœ€å¤šæœ€å¼ºçš„æ¦‚å¿µæ¿å—ï¼Œå¯ä»¥åˆ†æå¼ºåŠ¿æ¿å—çš„è½®åŠ¨ï¼Œåˆ¤æ–­èµ„é‡‘åŠ¨å‘
            - æ˜¾ç¤ºæ¿å—ä»£ç ã€æ¿å—åç§°ã€äº¤æ˜“æ—¥æœŸã€ä¸Šæ¦œå¤©æ•°ã€è¿æ¿é«˜åº¦ã€è¿æ¿å®¶æ•°ã€æ¶¨åœå®¶æ•°ã€æ¶¨è·Œå¹…ã€æ¿å—çƒ­ç‚¹æ’åç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼š8000ç§¯åˆ†ä»¥ä¸Šæ¯åˆ†é’Ÿ500æ¬¡ï¼Œæ¯å¤©æ€»é‡ä¸é™åˆ¶
            - é™é‡ï¼šå•æ¬¡æœ€å¤§2000è¡Œæ•°æ®ï¼Œå¯æ ¹æ®è‚¡ç¥¨ä»£ç æˆ–æ—¥æœŸå¾ªç¯æå–å…¨éƒ¨
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not trade_date and not ts_code and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šäº¤æ˜“æ—¥æœŸ(trade_date)ã€æ¿å—ä»£ç (ts_code)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå¿…é¡»åŒæ—¶æä¾›start_dateå’Œend_date
        if (start_date and not end_date) or (end_date and not start_date):
            return "å¦‚æœä½¿ç”¨æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œè¯·åŒæ—¶æä¾›start_dateå’Œend_date"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if trade_date:
                params['trade_date'] = trade_date
            if ts_code:
                params['ts_code'] = ts_code
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'trade_date': trade_date or '',
                'ts_code': ts_code or '',
                'start_date': start_date or '',
                'end_date': end_date or ''
            }
            df = cache_manager.get_dataframe('limit_cpt_list', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('limit_cpt_list', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.limit_cpt_list(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('limit_cpt_list', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šlimit_cpt_list\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°8000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤limit_cpt_listæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥Tushareè´¦æˆ·ç§¯åˆ†æ˜¯å¦è¶³å¤Ÿï¼ˆéœ€è¦8000ç§¯åˆ†ä»¥ä¸Šï¼‰"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·ç§¯åˆ†æ˜¯å¦è¾¾åˆ°8000åˆ†ä»¥ä¸Š\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥"
            
            if df is None or df.empty:
                param_info = []
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if ts_code:
                    param_info.append(f"æ¿å—ä»£ç : {ts_code}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æœ€å¼ºæ¿å—ç»Ÿè®¡æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}\n\næç¤ºï¼š\n- è¯·ç¡®è®¤è¯¥æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n- è¯¥æ—¥æœŸæ˜¯å¦æœ‰æ¶¨åœè‚¡ç¥¨å’Œæ¦‚å¿µæ¿å—æ•°æ®"
            
            # æŒ‰æ¿å—çƒ­ç‚¹æ’åæ’åºï¼ˆå‡åºï¼Œæ’åè¶Šå°è¶Šé å‰ï¼‰
            if 'rank' in df.columns:
                # å°†rankè½¬æ¢ä¸ºæ•°å­—è¿›è¡Œæ’åº
                df['rank_num'] = df['rank'].astype(str).str.extract(r'(\d+)').astype(float)
                df = df.sort_values('rank_num', ascending=True, na_position='last')
                df = df.drop('rank_num', axis=1)
            elif 'trade_date' in df.columns:
                df = df.sort_values('trade_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_limit_cpt_list_data(df, trade_date or start_date or "", ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_stock_auction(
        ts_code: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–å½“æ—¥ä¸ªè‚¡å’ŒETFçš„é›†åˆç«ä»·æˆäº¤æƒ…å†µ
        
        å‚æ•°:
            ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š000001.SZï¼Œå¯é€‰ï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250218ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        æ³¨æ„:
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - æ•°æ®è¯´æ˜ï¼šè·å–å½“æ—¥ä¸ªè‚¡å’ŒETFçš„é›†åˆç«ä»·æˆäº¤æƒ…å†µï¼Œæ¯å¤©9ç‚¹25~29åˆ†ä¹‹é—´å¯ä»¥è·å–å½“æ—¥çš„é›†åˆç«ä»·æˆäº¤æ•°æ®
            - æƒé™è¦æ±‚ï¼šæœ¬æ¥å£æ˜¯å•ç‹¬å¼€æƒé™çš„æ•°æ®ï¼Œå·²ç»å¼€é€šäº†è‚¡ç¥¨åˆ†é’Ÿæƒé™çš„ç”¨æˆ·å¯è‡ªåŠ¨è·å¾—æœ¬æ¥å£æƒé™
            - é™é‡ï¼šå•æ¬¡æœ€å¤§è¿”å›8000è¡Œæ•°æ®ï¼Œå¯æ ¹æ®æ—¥æœŸæˆ–ä»£ç å¾ªç¯è·å–å†å²
        
        è¿”å›:
            åŒ…å«é›†åˆç«ä»·æˆäº¤æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not trade_date and not ts_code and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šäº¤æ˜“æ—¥æœŸ(trade_date)ã€è‚¡ç¥¨ä»£ç (ts_code)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        # å¦‚æœæä¾›äº†æ—¥æœŸèŒƒå›´ï¼Œå¿…é¡»åŒæ—¶æä¾›start_dateå’Œend_date
        if (start_date and not end_date) or (end_date and not start_date):
            return "å¦‚æœä½¿ç”¨æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œè¯·åŒæ—¶æä¾›start_dateå’Œend_date"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if trade_date:
                params['trade_date'] = trade_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'ts_code': ts_code or '',
                'trade_date': trade_date or '',
                'start_date': start_date or '',
                'end_date': end_date or ''
            }
            df = cache_manager.get_dataframe('stk_auction', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('stk_auction', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                try:
                    df = pro.stk_auction(**params)
                    
                    # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                    if not df.empty:
                        cache_manager.set('stk_auction', df, **cache_params)
                except Exception as api_error:
                    error_msg = str(api_error)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¥å£åé”™è¯¯æˆ–æƒé™é—®é¢˜
                    if 'æ¥å£å' in error_msg or 'api_name' in error_msg.lower() or 'è¯·æŒ‡å®šæ­£ç¡®çš„æ¥å£å' in error_msg:
                        return f"APIæ¥å£è°ƒç”¨å¤±è´¥ï¼š{error_msg}\n\nå·²ä½¿ç”¨æ¥å£ï¼šstk_auction\n\nå¯èƒ½çš„åŸå› ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·æ˜¯å¦å¼€é€šäº†è‚¡ç¥¨åˆ†é’Ÿæƒé™ï¼ˆå·²å¼€é€šçš„ç”¨æˆ·å¯è‡ªåŠ¨è·å¾—æœ¬æ¥å£æƒé™ï¼‰\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n5. æŸ¥è¯¢æ—¶é—´æ˜¯å¦åœ¨9ç‚¹25~29åˆ†ä¹‹é—´ï¼ˆå½“æ—¥æ•°æ®ï¼‰\n\nå»ºè®®ï¼š\n- è¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤stk_auctionæ¥å£æ˜¯å¦å¯ç”¨\n- æ£€æŸ¥æ˜¯å¦å·²å¼€é€šè‚¡ç¥¨åˆ†é’Ÿæƒé™"
                    else:
                        return f"APIè°ƒç”¨å¤±è´¥ï¼š{error_msg}\nè¯·æ£€æŸ¥ï¼š\n1. Tushare tokenæ˜¯å¦æœ‰æ•ˆ\n2. è´¦æˆ·æ˜¯å¦å¼€é€šäº†è‚¡ç¥¨åˆ†é’Ÿæƒé™\n3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n4. æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥"
            
            if df is None or df.empty:
                param_info = []
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if ts_code:
                    param_info.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
                if start_date and end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}")
                
                param_str = "ã€".join(param_info) if param_info else "æŒ‡å®šæ¡ä»¶"
                return f"æœªæ‰¾åˆ°ç¬¦åˆ{param_str}çš„é›†åˆç«ä»·æ•°æ®\n\næç¤ºï¼š\n- å½“æ—¥æ•°æ®éœ€è¦åœ¨9ç‚¹25~29åˆ†ä¹‹é—´æŸ¥è¯¢\n- è¯·ç¡®è®¤æŸ¥è¯¢æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n- è¯·ç¡®è®¤è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®"
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_stock_auction_data(df, ts_code or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"


def format_holder_number_data(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–è‚¡ä¸œæˆ·æ•°æ•°æ®
    
    å‚æ•°:
        df: è‚¡ä¸œæˆ·æ•°æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„è‚¡ä¸œæˆ·æ•°æ•°æ®"
    
    result = []
    result.append(f"ğŸ“Š {ts_code} è‚¡ä¸œæˆ·æ•°å˜åŒ–")
    result.append("-" * 100)
    result.append("")
    
    # è¡¨å¤´
    result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'æˆªæ­¢æ—¥æœŸ':<12} {'è‚¡ä¸œæˆ·æ•°':<12} {'å˜åŒ–':<12} {'å˜åŒ–ç‡':<12}")
    result.append("-" * 100)
    
    # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    if 'ann_date' in df.columns:
        df = df.sort_values('ann_date', ascending=False)
    elif 'end_date' in df.columns:
        df = df.sort_values('end_date', ascending=False)
    
    # è®¡ç®—å˜åŒ–
    df = df.copy()
    if 'holder_num' in df.columns:
        df['holder_num'] = pd.to_numeric(df['holder_num'], errors='coerce')
        # è®¡ç®—å˜åŒ–ï¼ˆä¸ä¸Šä¸€æ¡è®°å½•æ¯”è¾ƒï¼‰
        df['change'] = df['holder_num'].diff().fillna(0)
        df['change_pct'] = (df['change'] / df['holder_num'].shift(1) * 100).fillna(0)
    
    for _, row in df.iterrows():
        # å…¬å‘Šæ—¥æœŸ
        ann_date = format_date(str(row['ann_date'])) if 'ann_date' in row and pd.notna(row['ann_date']) else "-"
        
        # æˆªæ­¢æ—¥æœŸ
        end_date = format_date(str(row['end_date'])) if 'end_date' in row and pd.notna(row['end_date']) else "-"
        
        # è‚¡ä¸œæˆ·æ•°
        holder_num = f"{int(row['holder_num']):,}" if 'holder_num' in row and pd.notna(row['holder_num']) else "-"
        
        # å˜åŒ–
        change = "-"
        if 'change' in row and pd.notna(row['change']):
            change_val = row['change']
            if change_val > 0:
                change = f"+{int(change_val):,}"
            elif change_val < 0:
                change = f"{int(change_val):,}"
            else:
                change = "0"
        
        # å˜åŒ–ç‡
        change_pct = "-"
        if 'change_pct' in row and pd.notna(row['change_pct']):
            change_pct_val = row['change_pct']
            if change_pct_val > 0:
                change_pct = f"+{change_pct_val:.2f}%"
            elif change_pct_val < 0:
                change_pct = f"{change_pct_val:.2f}%"
            else:
                change_pct = "0.00%"
        
        result.append(f"{ann_date:<12} {end_date:<12} {holder_num:<12} {change:<12} {change_pct:<12}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    result.append("")
    result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    
    if 'holder_num' in df.columns and len(df) > 1:
        # æœ€æ–°è‚¡ä¸œæˆ·æ•°
        latest_num = df['holder_num'].iloc[0]
        oldest_num = df['holder_num'].iloc[-1]
        result.append(f"  - æœ€æ–°è‚¡ä¸œæˆ·æ•°: {int(latest_num):,} æˆ·")
        result.append(f"  - æœ€æ—©è‚¡ä¸œæˆ·æ•°: {int(oldest_num):,} æˆ·")
        
        # æ€»å˜åŒ–
        total_change = latest_num - oldest_num
        if total_change > 0:
            result.append(f"  - æ€»å˜åŒ–: +{int(total_change):,} æˆ·ï¼ˆæŒè‚¡åˆ†æ•£ï¼‰")
        elif total_change < 0:
            result.append(f"  - æ€»å˜åŒ–: {int(total_change):,} æˆ·ï¼ˆæŒè‚¡é›†ä¸­ï¼‰")
        else:
            result.append(f"  - æ€»å˜åŒ–: 0 æˆ·")
        
        # å˜åŒ–ç‡
        if oldest_num > 0:
            total_change_pct = (total_change / oldest_num) * 100
            result.append(f"  - å˜åŒ–ç‡: {total_change_pct:+.2f}%")
    
    # æ•°æ®ç‚¹æ•°é‡
    result.append(f"  - æ•°æ®ç‚¹æ•°é‡: {len(df)} ä¸ª")
    
    return "\n".join(result)

def format_holder_trade_data(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–è‚¡ä¸œå¢å‡æŒæ•°æ®
    
    å‚æ•°:
        df: å¢å‡æŒæ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„å¢å‡æŒæ•°æ®"
    
    result = []
    result.append(f"ğŸ“Š {ts_code} è‚¡ä¸œå¢å‡æŒè®°å½•")
    result.append("-" * 120)
    result.append("")
    
    # è¡¨å¤´
    result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è‚¡ä¸œåç§°':<25} {'ç±»å‹':<8} {'å˜åŠ¨æ•°é‡(è‚¡)':<18} {'å æµé€šæ¯”ä¾‹(%)':<15} {'å¹³å‡ä»·æ ¼':<12} {'å˜åŠ¨åæŒè‚¡(è‚¡)':<18}")
    result.append("-" * 120)
    
    # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    if 'ann_date' in df.columns:
        df = df.sort_values('ann_date', ascending=False)
    
    for _, row in df.iterrows():
        # å…¬å‘Šæ—¥æœŸ
        ann_date = format_date(str(row['ann_date'])) if 'ann_date' in row and pd.notna(row['ann_date']) else "-"
        
        # è‚¡ä¸œåç§°
        holder_name = str(row['holder_name'])[:23] if 'holder_name' in row and pd.notna(row['holder_name']) else "-"
        
        # äº¤æ˜“ç±»å‹
        in_de = row.get('in_de', '-')
        if in_de == 'IN':
            trade_type = "å¢æŒ"
        elif in_de == 'DE':
            trade_type = "å‡æŒ"
        else:
            trade_type = str(in_de)
        
        # å˜åŠ¨æ•°é‡
        change_vol = f"{int(row['change_vol']):,}" if 'change_vol' in row and pd.notna(row['change_vol']) else "-"
        
        # å æµé€šæ¯”ä¾‹
        change_ratio = f"{row['change_ratio']:.2f}%" if 'change_ratio' in row and pd.notna(row['change_ratio']) else "-"
        
        # å¹³å‡ä»·æ ¼
        avg_price = f"{row['avg_price']:.2f}" if 'avg_price' in row and pd.notna(row['avg_price']) else "-"
        
        # å˜åŠ¨åæŒè‚¡
        after_share = f"{int(row['after_share']):,}" if 'after_share' in row and pd.notna(row['after_share']) else "-"
        
        result.append(f"{ann_date:<12} {holder_name:<25} {trade_type:<8} {change_vol:<18} {change_ratio:<15} {avg_price:<12} {after_share:<18}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    result.append("")
    result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    
    # å¢æŒ/å‡æŒç»Ÿè®¡
    if 'in_de' in df.columns:
        increase_count = len(df[df['in_de'] == 'IN'])
        decrease_count = len(df[df['in_de'] == 'DE'])
        result.append(f"  - å¢æŒè®°å½•: {increase_count} æ¡")
        result.append(f"  - å‡æŒè®°å½•: {decrease_count} æ¡")
    
    # è‚¡ä¸œç±»å‹ç»Ÿè®¡
    if 'holder_type' in df.columns:
        holder_type_map = {"C": "å…¬å¸", "P": "ä¸ªäºº", "G": "é«˜ç®¡"}
        for htype, count in df['holder_type'].value_counts().items():
            type_name = holder_type_map.get(htype, htype)
            result.append(f"  - {type_name}è‚¡ä¸œ: {count} æ¡")
    
    # æ€»å˜åŠ¨æ•°é‡
    if 'change_vol' in df.columns:
        total_change = df['change_vol'].sum()
        if total_change > 0:
            result.append(f"  - å‡€å¢æŒ: {int(total_change):,} è‚¡")
        elif total_change < 0:
            result.append(f"  - å‡€å‡æŒ: {int(abs(total_change)):,} è‚¡")
        else:
            result.append(f"  - å‡€å˜åŠ¨: 0 è‚¡")
    
    return "\n".join(result)

def format_stock_daily_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–è‚¡ç¥¨æ—¥çº¿è¡Œæƒ…æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ—¥çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨æˆ–å¤šä¸ªè‚¡ç¥¨
    if ts_code:
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            stock_df = df[df['ts_code'] == code]
            if not stock_df.empty:
                result.append(format_single_stock_daily(stock_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # æŒ‰æ—¥æœŸæŸ¥è¯¢ï¼Œæ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨
        # æŒ‰æ—¥æœŸåˆ†ç»„
        dates = df['trade_date'].unique()
        for date in sorted(dates, reverse=True)[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
            date_df = df[df['trade_date'] == date]
            if not date_df.empty:
                result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                result.append("=" * 80)
                result.append(f"{'è‚¡ç¥¨ä»£ç ':<15} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œé¢':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
                result.append("-" * 80)
                for _, row in date_df.iterrows():
                    close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
                    change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
                    pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
                    vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
                    amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
                    result.append(f"{row['ts_code']:<15} {close:<10} {change:<10} {pct_chg:<10} {vol:<15} {amount:<15}")
                result.append("")
    
    return "\n".join(result)

def format_single_stock_daily(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªè‚¡ç¥¨çš„æ—¥çº¿è¡Œæƒ…æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªè‚¡ç¥¨çš„æ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„æ—¥çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append(f"ğŸ“ˆ {ts_code} æ—¥çº¿è¡Œæƒ…")
    result.append("=" * 80)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š20æ¡ï¼‰
    display_count = min(20, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'å¼€ç›˜':<10} {'æœ€é«˜':<10} {'æœ€ä½':<10} {'æ”¶ç›˜':<10} {'æ¶¨è·Œé¢':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
    result.append("-" * 80)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(row['trade_date'])
        open_price = f"{row['open']:.2f}" if pd.notna(row['open']) else "-"
        high = f"{row['high']:.2f}" if pd.notna(row['high']) else "-"
        low = f"{row['low']:.2f}" if pd.notna(row['low']) else "-"
        close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
        change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
        pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
        vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
        amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
        
        result.append(f"{trade_date:<12} {open_price:<10} {high:<10} {low:<10} {close:<10} {change:<10} {pct_chg:<10} {vol:<15} {amount:<15}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 80)
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(latest['trade_date'])}")
        result.append(f"å¼€ç›˜ä»·: {latest['open']:.2f}" if pd.notna(latest['open']) else "å¼€ç›˜ä»·: -")
        result.append(f"æœ€é«˜ä»·: {latest['high']:.2f}" if pd.notna(latest['high']) else "æœ€é«˜ä»·: -")
        result.append(f"æœ€ä½ä»·: {latest['low']:.2f}" if pd.notna(latest['low']) else "æœ€ä½ä»·: -")
        result.append(f"æ”¶ç›˜ä»·: {latest['close']:.2f}" if pd.notna(latest['close']) else "æ”¶ç›˜ä»·: -")
        result.append(f"æ˜¨æ”¶ä»·: {latest['pre_close']:.2f}" if pd.notna(latest.get('pre_close')) else "æ˜¨æ”¶ä»·: -")
        if pd.notna(latest.get('change')):
            result.append(f"æ¶¨è·Œé¢: {latest['change']:+.2f}")
        if pd.notna(latest.get('pct_chg')):
            result.append(f"æ¶¨è·Œå¹…: {latest['pct_chg']:+.2f}%")
        if pd.notna(latest.get('vol')):
            result.append(f"æˆäº¤é‡: {latest['vol']:.0f} æ‰‹")
        if pd.notna(latest.get('amount')):
            result.append(f"æˆäº¤é¢: {latest['amount']:.0f} åƒå…ƒ")
    
    return "\n".join(result)

def format_stock_weekly_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–è‚¡ç¥¨å‘¨çº¿è¡Œæƒ…æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: å‘¨çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å‘¨çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨æˆ–å¤šä¸ªè‚¡ç¥¨
    if ts_code:
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            stock_df = df[df['ts_code'] == code]
            if not stock_df.empty:
                result.append(format_single_stock_weekly(stock_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # æŒ‰æ—¥æœŸæŸ¥è¯¢ï¼Œæ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨
        # æŒ‰æ—¥æœŸåˆ†ç»„
        dates = df['trade_date'].unique()
        for date in sorted(dates, reverse=True)[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10å‘¨
            date_df = df[df['trade_date'] == date]
            if not date_df.empty:
                result.append(f"ğŸ“… äº¤æ˜“å‘¨ï¼ˆæœ€åäº¤æ˜“æ—¥ï¼‰: {format_date(date)}")
                result.append("=" * 100)
                result.append(f"{'è‚¡ç¥¨ä»£ç ':<15} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œé¢':<10} {'æ¶¨è·Œå¹…':<10} {'æ³¢åŠ¨èŒƒå›´':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
                result.append("-" * 100)
                for _, row in date_df.iterrows():
                    close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
                    change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
                    pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
                    # è®¡ç®—æ³¢åŠ¨èŒƒå›´ï¼ˆæœ€é«˜ä»· - æœ€ä½ä»·ï¼‰
                    if pd.notna(row.get('high')) and pd.notna(row.get('low')):
                        swing_range = f"{row['high'] - row['low']:.2f}"
                    else:
                        swing_range = "-"
                    vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
                    amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
                    result.append(f"{row['ts_code']:<15} {close:<10} {change:<10} {pct_chg:<10} {swing_range:<10} {vol:<15} {amount:<15}")
                result.append("")
    
    return "\n".join(result)

def format_single_stock_weekly(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªè‚¡ç¥¨çš„å‘¨çº¿è¡Œæƒ…æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªè‚¡ç¥¨çš„å‘¨çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„å‘¨çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append(f"ğŸ“ˆ {ts_code} å‘¨çº¿è¡Œæƒ…")
    result.append("=" * 80)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š20å‘¨ï¼‰
    display_count = min(20, len(df))
    result.append(f"æœ€è¿‘ {display_count} å‘¨æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'äº¤æ˜“å‘¨':<12} {'å¼€ç›˜':<10} {'æœ€é«˜':<10} {'æœ€ä½':<10} {'æ”¶ç›˜':<10} {'æ¶¨è·Œé¢':<10} {'æ¶¨è·Œå¹…':<10} {'æ³¢åŠ¨èŒƒå›´':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
    result.append("-" * 100)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(row['trade_date'])
        open_price = f"{row['open']:.2f}" if pd.notna(row['open']) else "-"
        high = f"{row['high']:.2f}" if pd.notna(row['high']) else "-"
        low = f"{row['low']:.2f}" if pd.notna(row['low']) else "-"
        close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
        change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
        pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
        # è®¡ç®—æ³¢åŠ¨èŒƒå›´ï¼ˆæœ€é«˜ä»· - æœ€ä½ä»·ï¼‰
        if pd.notna(row['high']) and pd.notna(row['low']):
            swing_range = f"{row['high'] - row['low']:.2f}"
        else:
            swing_range = "-"
        vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
        amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
        
        result.append(f"{trade_date:<12} {open_price:<10} {high:<10} {low:<10} {close:<10} {change:<10} {pct_chg:<10} {swing_range:<10} {vol:<15} {amount:<15}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°å‘¨æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 80)
        result.append(f"äº¤æ˜“å‘¨ï¼ˆæœ€åäº¤æ˜“æ—¥ï¼‰: {format_date(latest['trade_date'])}")
        result.append(f"å‘¨å¼€ç›˜ä»·: {latest['open']:.2f}" if pd.notna(latest['open']) else "å‘¨å¼€ç›˜ä»·: -")
        result.append(f"å‘¨æœ€é«˜ä»·: {latest['high']:.2f}" if pd.notna(latest['high']) else "å‘¨æœ€é«˜ä»·: -")
        result.append(f"å‘¨æœ€ä½ä»·: {latest['low']:.2f}" if pd.notna(latest['low']) else "å‘¨æœ€ä½ä»·: -")
        result.append(f"å‘¨æ”¶ç›˜ä»·: {latest['close']:.2f}" if pd.notna(latest['close']) else "å‘¨æ”¶ç›˜ä»·: -")
        result.append(f"ä¸Šå‘¨æ”¶ç›˜ä»·: {latest['pre_close']:.2f}" if pd.notna(latest.get('pre_close')) else "ä¸Šå‘¨æ”¶ç›˜ä»·: -")
        if pd.notna(latest.get('change')):
            result.append(f"æ¶¨è·Œé¢: {latest['change']:+.2f} (æ”¶ç›˜ä»· - ä¸Šå‘¨æ”¶ç›˜ä»·)")
        if pd.notna(latest.get('pct_chg')):
            result.append(f"æ¶¨è·Œå¹…: {latest['pct_chg']:+.2f}%")
        # æ·»åŠ æ³¢åŠ¨èŒƒå›´
        if pd.notna(latest.get('high')) and pd.notna(latest.get('low')):
            swing_range = latest['high'] - latest['low']
            result.append(f"æ³¢åŠ¨èŒƒå›´: {swing_range:.2f} (æœ€é«˜ä»· - æœ€ä½ä»·)")
        if pd.notna(latest.get('vol')):
            result.append(f"å‘¨æˆäº¤é‡: {latest['vol']:.0f} æ‰‹")
        if pd.notna(latest.get('amount')):
            result.append(f"å‘¨æˆäº¤é¢: {latest['amount']:.0f} åƒå…ƒ")
    
    return "\n".join(result)

def format_index_daily_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–Aè‚¡æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: æŒ‡æ•°ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æŒ‡æ•°æ—¥çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªæŒ‡æ•°æˆ–å¤šä¸ªæŒ‡æ•°
    if ts_code:
        # æŒ‰æŒ‡æ•°ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            index_df = df[df['ts_code'] == code]
            if not index_df.empty:
                result.append(format_single_index_daily(index_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # æŒ‰æ—¥æœŸæŸ¥è¯¢ï¼Œæ˜¾ç¤ºæ‰€æœ‰æŒ‡æ•°
        # æŒ‰æ—¥æœŸåˆ†ç»„
        dates = df['trade_date'].unique()
        for date in sorted(dates, reverse=True)[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
            date_df = df[df['trade_date'] == date]
            if not date_df.empty:
                result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                result.append("=" * 80)
                result.append(f"{'æŒ‡æ•°ä»£ç ':<15} {'æ”¶ç›˜ç‚¹ä½':<12} {'æ¶¨è·Œç‚¹ä½':<12} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
                result.append("-" * 80)
                for _, row in date_df.iterrows():
                    close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
                    change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
                    pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
                    vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
                    amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
                    result.append(f"{row['ts_code']:<15} {close:<12} {change:<12} {pct_chg:<10} {vol:<15} {amount:<15}")
                result.append("")
    
    return "\n".join(result)

def format_single_index_daily(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªæŒ‡æ•°çš„æ—¥çº¿è¡Œæƒ…æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªæŒ‡æ•°çš„æ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: æŒ‡æ•°ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„æ—¥çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append(f"ğŸ“ˆ {ts_code} æ—¥çº¿è¡Œæƒ…")
    result.append("=" * 80)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š20æ¡ï¼‰
    display_count = min(20, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'å¼€ç›˜':<12} {'æœ€é«˜':<12} {'æœ€ä½':<12} {'æ”¶ç›˜':<12} {'æ¶¨è·Œç‚¹ä½':<12} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
    result.append("-" * 100)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(row['trade_date'])
        open_price = f"{row['open']:.2f}" if pd.notna(row['open']) else "-"
        high = f"{row['high']:.2f}" if pd.notna(row['high']) else "-"
        low = f"{row['low']:.2f}" if pd.notna(row['low']) else "-"
        close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
        change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
        pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
        vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
        amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
        
        result.append(f"{trade_date:<12} {open_price:<12} {high:<12} {low:<12} {close:<12} {change:<12} {pct_chg:<10} {vol:<15} {amount:<15}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 80)
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(latest['trade_date'])}")
        result.append(f"å¼€ç›˜ç‚¹ä½: {latest['open']:.2f}" if pd.notna(latest['open']) else "å¼€ç›˜ç‚¹ä½: -")
        result.append(f"æœ€é«˜ç‚¹ä½: {latest['high']:.2f}" if pd.notna(latest['high']) else "æœ€é«˜ç‚¹ä½: -")
        result.append(f"æœ€ä½ç‚¹ä½: {latest['low']:.2f}" if pd.notna(latest['low']) else "æœ€ä½ç‚¹ä½: -")
        result.append(f"æ”¶ç›˜ç‚¹ä½: {latest['close']:.2f}" if pd.notna(latest['close']) else "æ”¶ç›˜ç‚¹ä½: -")
        result.append(f"æ˜¨æ”¶ç‚¹ä½: {latest['pre_close']:.2f}" if pd.notna(latest.get('pre_close')) else "æ˜¨æ”¶ç‚¹ä½: -")
        if pd.notna(latest.get('change')):
            result.append(f"æ¶¨è·Œç‚¹ä½: {latest['change']:+.2f}")
        if pd.notna(latest.get('pct_chg')):
            result.append(f"æ¶¨è·Œå¹…: {latest['pct_chg']:+.2f}%")
        if pd.notna(latest.get('vol')):
            result.append(f"æˆäº¤é‡: {latest['vol']:.0f} æ‰‹")
        if pd.notna(latest.get('amount')):
            result.append(f"æˆäº¤é¢: {latest['amount']:.0f} åƒå…ƒ")
    
    return "\n".join(result)

def format_etf_daily_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–ETFæ—¥çº¿è¡Œæƒ…æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: ETFæ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: ETFä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ETFæ—¥çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªETFæˆ–å¤šä¸ªETF
    if ts_code:
        # æŒ‰ETFä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            etf_df = df[df['ts_code'] == code]
            if not etf_df.empty:
                result.append(format_single_etf_daily(etf_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # æŒ‰æ—¥æœŸæŸ¥è¯¢ï¼Œæ˜¾ç¤ºæ‰€æœ‰ETF
        # æŒ‰æ—¥æœŸåˆ†ç»„
        dates = df['trade_date'].unique()
        for date in sorted(dates, reverse=True)[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
            date_df = df[df['trade_date'] == date]
            if not date_df.empty:
                result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                result.append("=" * 80)
                result.append(f"{'ETFä»£ç ':<15} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œé¢':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
                result.append("-" * 80)
                for _, row in date_df.iterrows():
                    close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
                    change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
                    pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
                    vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
                    amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
                    result.append(f"{row['ts_code']:<15} {close:<10} {change:<10} {pct_chg:<10} {vol:<15} {amount:<15}")
                result.append("")
    
    return "\n".join(result)

def format_single_etf_daily(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªETFçš„æ—¥çº¿è¡Œæƒ…æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªETFçš„æ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: ETFä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„æ—¥çº¿è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append(f"ğŸ“ˆ {ts_code} ETFæ—¥çº¿è¡Œæƒ…")
    result.append("=" * 80)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š20æ¡ï¼‰
    display_count = min(20, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'å¼€ç›˜':<10} {'æœ€é«˜':<10} {'æœ€ä½':<10} {'æ”¶ç›˜':<10} {'æ¶¨è·Œé¢':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é‡(æ‰‹)':<15} {'æˆäº¤é¢(åƒå…ƒ)':<15}")
    result.append("-" * 100)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(row['trade_date'])
        open_price = f"{row['open']:.2f}" if pd.notna(row['open']) else "-"
        high = f"{row['high']:.2f}" if pd.notna(row['high']) else "-"
        low = f"{row['low']:.2f}" if pd.notna(row['low']) else "-"
        close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
        change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
        pct_chg = f"{row['pct_chg']:+.2f}%" if pd.notna(row['pct_chg']) else "-"
        vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
        amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
        
        result.append(f"{trade_date:<12} {open_price:<10} {high:<10} {low:<10} {close:<10} {change:<10} {pct_chg:<10} {vol:<15} {amount:<15}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 80)
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(latest['trade_date'])}")
        result.append(f"å¼€ç›˜ä»·: {latest['open']:.2f}" if pd.notna(latest['open']) else "å¼€ç›˜ä»·: -")
        result.append(f"æœ€é«˜ä»·: {latest['high']:.2f}" if pd.notna(latest['high']) else "æœ€é«˜ä»·: -")
        result.append(f"æœ€ä½ä»·: {latest['low']:.2f}" if pd.notna(latest['low']) else "æœ€ä½ä»·: -")
        result.append(f"æ”¶ç›˜ä»·: {latest['close']:.2f}" if pd.notna(latest['close']) else "æ”¶ç›˜ä»·: -")
        result.append(f"æ˜¨æ”¶ä»·: {latest['pre_close']:.2f}" if pd.notna(latest.get('pre_close')) else "æ˜¨æ”¶ä»·: -")
        if pd.notna(latest.get('change')):
            result.append(f"æ¶¨è·Œé¢: {latest['change']:+.2f}")
        if pd.notna(latest.get('pct_chg')):
            result.append(f"æ¶¨è·Œå¹…: {latest['pct_chg']:+.2f}%")
        if pd.notna(latest.get('vol')):
            result.append(f"æˆäº¤é‡: {latest['vol']:.0f} æ‰‹")
        if pd.notna(latest.get('amount')):
            result.append(f"æˆäº¤é¢: {latest['amount']:.0f} åƒå…ƒ")
    
    return "\n".join(result)

def format_stock_survey_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–æœºæ„è°ƒç ”æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æœºæ„è°ƒç ”æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æœºæ„è°ƒç ”æ•°æ®"
    
    # æŒ‰è°ƒç ”æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('surv_date', ascending=False)
    
    result = []
    result.append("ğŸ“Š ä¸Šå¸‚å…¬å¸æœºæ„è°ƒç ”è®°å½•")
    result.append("=" * 140)
    result.append("")
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨æˆ–å¤šä¸ªè‚¡ç¥¨
    if ts_code:
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            stock_df = df[df['ts_code'] == code]
            if not stock_df.empty:
                result.append(format_single_stock_survey(stock_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # æŒ‰æ—¥æœŸæŸ¥è¯¢ï¼Œæ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨
        # æŒ‰æ—¥æœŸåˆ†ç»„
        dates = df['surv_date'].unique()
        for date in sorted(dates, reverse=True)[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªè°ƒç ”æ—¥æœŸ
            date_df = df[df['surv_date'] == date]
            if not date_df.empty:
                result.append(f"ğŸ“… è°ƒç ”æ—¥æœŸ: {format_date(date)}")
                result.append("=" * 140)
                # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
                stocks = date_df['ts_code'].unique()
                for stock in stocks[:10]:  # æœ€å¤šæ˜¾ç¤º10åªè‚¡ç¥¨
                    stock_df = date_df[date_df['ts_code'] == stock]
                    stock_name = stock_df.iloc[0]['name'] if pd.notna(stock_df.iloc[0].get('name')) else stock
                    result.append(f"è‚¡ç¥¨: {stock} ({stock_name}) - å…± {len(stock_df)} æ¡è°ƒç ”è®°å½•")
                    result.append("-" * 140)
                    result.append(f"{'æœºæ„å‚ä¸äººå‘˜':<20} {'æ¥å¾…å…¬å¸':<30} {'æ¥å¾…æ–¹å¼':<15} {'æ¥å¾…åœ°ç‚¹':<20} {'ä¸Šå¸‚å…¬å¸æ¥å¾…äººå‘˜':<20}")
                    result.append("-" * 140)
                    for _, row in stock_df.head(5).iterrows():  # æ¯åªè‚¡ç¥¨æœ€å¤šæ˜¾ç¤º5æ¡
                        fund_visitors = str(row['fund_visitors'])[:18] if pd.notna(row.get('fund_visitors')) else "-"
                        rece_org = str(row['rece_org'])[:28] if pd.notna(row.get('rece_org')) else "-"
                        rece_mode = str(row['rece_mode'])[:13] if pd.notna(row.get('rece_mode')) else "-"
                        rece_place = str(row['rece_place'])[:18] if pd.notna(row.get('rece_place')) else "-"
                        comp_rece = str(row['comp_rece'])[:18] if pd.notna(row.get('comp_rece')) else "-"
                        result.append(f"{fund_visitors:<20} {rece_org:<30} {rece_mode:<15} {rece_place:<20} {comp_rece:<20}")
                    if len(stock_df) > 5:
                        result.append(f"ï¼ˆå…± {len(stock_df)} æ¡è®°å½•ï¼Œä»…æ˜¾ç¤ºå‰ 5 æ¡ï¼‰")
                    result.append("")
                if len(stocks) > 10:
                    result.append(f"ï¼ˆå…± {len(stocks)} åªè‚¡ç¥¨ï¼Œä»…æ˜¾ç¤ºå‰ 10 åªï¼‰")
                result.append("")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºäºä¸Šå¸‚å…¬å¸æŠ«éœ²çš„æœºæ„è°ƒç ”è®°å½•")
    result.append("  - æœºæ„è°ƒç ”å¯ä»¥åæ˜ å¸‚åœºå¯¹å…¬å¸çš„å…³æ³¨åº¦")
    result.append("  - è°ƒç ”é¢‘ç‡å’Œå‚ä¸æœºæ„æ•°é‡å¯ä»¥ä½œä¸ºæŠ•èµ„å‚è€ƒæŒ‡æ ‡")
    
    return "\n".join(result)


def format_single_stock_survey(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªè‚¡ç¥¨çš„æœºæ„è°ƒç ”æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªè‚¡ç¥¨çš„æœºæ„è°ƒç ”æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„æœºæ„è°ƒç ”æ•°æ®"
    
    # æŒ‰è°ƒç ”æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('surv_date', ascending=False)
    
    stock_name = df.iloc[0]['name'] if pd.notna(df.iloc[0].get('name')) else ts_code
    result = []
    result.append(f"ğŸ“ˆ {ts_code} ({stock_name}) æœºæ„è°ƒç ”è®°å½•")
    result.append("=" * 140)
    result.append("")
    
    # ç»Ÿè®¡ä¿¡æ¯
    unique_dates = df['surv_date'].nunique()
    total_records = len(df)
    result.append(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    result.append(f"  - è°ƒç ”æ—¥æœŸæ•°: {unique_dates} ä¸ª")
    result.append(f"  - è°ƒç ”è®°å½•æ•°: {total_records} æ¡")
    
    # ç»Ÿè®¡å‚ä¸æœºæ„
    if 'rece_org' in df.columns:
        unique_orgs = df['rece_org'].nunique()
        result.append(f"  - å‚ä¸æœºæ„æ•°: {unique_orgs} å®¶")
    
    # ç»Ÿè®¡å‚ä¸äººå‘˜
    if 'fund_visitors' in df.columns:
        unique_visitors = df['fund_visitors'].nunique()
        result.append(f"  - å‚ä¸äººå‘˜æ•°: {unique_visitors} äºº")
    
    result.append("")
    
    # æŒ‰è°ƒç ”æ—¥æœŸåˆ†ç»„æ˜¾ç¤º
    dates = df['surv_date'].unique()
    display_dates = sorted(dates, reverse=True)[:10]  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªè°ƒç ”æ—¥æœŸ
    
    for date in display_dates:
        date_df = df[df['surv_date'] == date]
        if not date_df.empty:
            result.append(f"ğŸ“… è°ƒç ”æ—¥æœŸ: {format_date(date)} (å…± {len(date_df)} æ¡è®°å½•)")
            result.append("-" * 140)
            result.append(f"{'æœºæ„å‚ä¸äººå‘˜':<20} {'æ¥å¾…å…¬å¸':<30} {'æ¥å¾…æ–¹å¼':<15} {'æ¥å¾…åœ°ç‚¹':<20} {'ä¸Šå¸‚å…¬å¸æ¥å¾…äººå‘˜':<20}")
            result.append("-" * 140)
            
            for _, row in date_df.iterrows():
                fund_visitors = str(row['fund_visitors'])[:18] if pd.notna(row.get('fund_visitors')) else "-"
                rece_org = str(row['rece_org'])[:28] if pd.notna(row.get('rece_org')) else "-"
                rece_mode = str(row['rece_mode'])[:13] if pd.notna(row.get('rece_mode')) else "-"
                rece_place = str(row['rece_place'])[:18] if pd.notna(row.get('rece_place')) else "-"
                comp_rece = str(row['comp_rece'])[:18] if pd.notna(row.get('comp_rece')) else "-"
                result.append(f"{fund_visitors:<20} {rece_org:<30} {rece_mode:<15} {rece_place:<20} {comp_rece:<20}")
            
            result.append("")
    
    if len(dates) > 10:
        result.append(f"ï¼ˆå…± {len(dates)} ä¸ªè°ƒç ”æ—¥æœŸï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ 10 ä¸ªï¼‰")
    
    return "\n".join(result)


def format_cyq_perf_data(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–æ¯æ—¥ç­¹ç åŠèƒœç‡æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ¯æ—¥ç­¹ç åŠèƒœç‡æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„æ¯æ—¥ç­¹ç åŠèƒœç‡æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append(f"ğŸ“Š {ts_code} æ¯æ—¥ç­¹ç åŠèƒœç‡æ•°æ®")
    result.append("=" * 140)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š30æ¡ï¼‰
    display_count = min(30, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'5åˆ†ä½æˆæœ¬':<12} {'50åˆ†ä½æˆæœ¬':<12} {'95åˆ†ä½æˆæœ¬':<12} {'åŠ æƒå¹³å‡æˆæœ¬':<14} {'èƒœç‡(%)':<10} {'ç­¹ç é›†ä¸­åº¦':<12}")
    result.append("-" * 140)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(row['trade_date'])
        cost_5pct = f"{row['cost_5pct']:.2f}" if pd.notna(row['cost_5pct']) else "-"
        cost_50pct = f"{row['cost_50pct']:.2f}" if pd.notna(row['cost_50pct']) else "-"
        cost_95pct = f"{row['cost_95pct']:.2f}" if pd.notna(row['cost_95pct']) else "-"
        weight_avg = f"{row['weight_avg']:.2f}" if pd.notna(row['weight_avg']) else "-"
        winner_rate = f"{row['winner_rate']:.2f}" if pd.notna(row['winner_rate']) else "-"
        
        # ç­¹ç é›†ä¸­åº¦
        concentration = "-"
        if 'concentration' in row and pd.notna(row['concentration']):
            concentration = f"{row['concentration']:.4f}"
        
        result.append(f"{trade_date:<12} {cost_5pct:<12} {cost_50pct:<12} {cost_95pct:<12} {weight_avg:<14} {winner_rate:<10} {concentration:<12}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 140)
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(latest['trade_date'])}")
        result.append(f"å†å²æœ€ä½ä»·: {latest['his_low']:.2f}" if pd.notna(latest['his_low']) else "å†å²æœ€ä½ä»·: -")
        result.append(f"å†å²æœ€é«˜ä»·: {latest['his_high']:.2f}" if pd.notna(latest['his_high']) else "å†å²æœ€é«˜ä»·: -")
        result.append(f"5åˆ†ä½æˆæœ¬: {latest['cost_5pct']:.2f}" if pd.notna(latest['cost_5pct']) else "5åˆ†ä½æˆæœ¬: -")
        result.append(f"15åˆ†ä½æˆæœ¬: {latest['cost_15pct']:.2f}" if pd.notna(latest.get('cost_15pct')) else "15åˆ†ä½æˆæœ¬: -")
        result.append(f"50åˆ†ä½æˆæœ¬: {latest['cost_50pct']:.2f}" if pd.notna(latest['cost_50pct']) else "50åˆ†ä½æˆæœ¬: -")
        result.append(f"85åˆ†ä½æˆæœ¬: {latest['cost_85pct']:.2f}" if pd.notna(latest.get('cost_85pct')) else "85åˆ†ä½æˆæœ¬: -")
        result.append(f"95åˆ†ä½æˆæœ¬: {latest['cost_95pct']:.2f}" if pd.notna(latest['cost_95pct']) else "95åˆ†ä½æˆæœ¬: -")
        result.append(f"åŠ æƒå¹³å‡æˆæœ¬: {latest['weight_avg']:.2f}" if pd.notna(latest['weight_avg']) else "åŠ æƒå¹³å‡æˆæœ¬: -")
        result.append(f"èƒœç‡: {latest['winner_rate']:.2f}%" if pd.notna(latest['winner_rate']) else "èƒœç‡: -")
        
        # ç­¹ç é›†ä¸­åº¦
        if 'concentration' in latest and pd.notna(latest['concentration']):
            concentration = latest['concentration']
            result.append(f"ç­¹ç é›†ä¸­åº¦: {concentration:.4f}")
            # è§£é‡Šé›†ä¸­åº¦å«ä¹‰
            if concentration < 0.1:
                result.append("  â†’ ç­¹ç é«˜åº¦é›†ä¸­ï¼ˆé›†ä¸­åº¦ < 0.1ï¼‰")
            elif concentration < 0.2:
                result.append("  â†’ ç­¹ç è¾ƒä¸ºé›†ä¸­ï¼ˆé›†ä¸­åº¦ 0.1-0.2ï¼‰")
            elif concentration < 0.3:
                result.append("  â†’ ç­¹ç ä¸­ç­‰é›†ä¸­ï¼ˆé›†ä¸­åº¦ 0.2-0.3ï¼‰")
            else:
                result.append("  â†’ ç­¹ç è¾ƒä¸ºåˆ†æ•£ï¼ˆé›†ä¸­åº¦ > 0.3ï¼‰")
        
        # è®¡ç®—æˆæœ¬åŒºé—´
        if pd.notna(latest.get('cost_5pct')) and pd.notna(latest.get('cost_95pct')):
            cost_range = latest['cost_95pct'] - latest['cost_5pct']
            result.append(f"æˆæœ¬åŒºé—´: {cost_range:.2f} (95åˆ†ä½ - 5åˆ†ä½)")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¯å¤©17~18ç‚¹å·¦å³æ›´æ–°ï¼Œæ•°æ®ä»2018å¹´å¼€å§‹")
    result.append("  - ç­¹ç é›†ä¸­åº¦è®¡ç®—å…¬å¼ï¼šé›†ä¸­åº¦ = (cost_95pct - cost_5pct) / (cost_95pct + cost_5pct)")
    result.append("  - é›†ä¸­åº¦è¶Šå°ï¼Œè¯´æ˜ç­¹ç è¶Šé›†ä¸­ï¼›é›†ä¸­åº¦è¶Šå¤§ï¼Œè¯´æ˜ç­¹ç è¶Šåˆ†æ•£")
    result.append("  - èƒœç‡ï¼šå½“å‰ä»·æ ¼é«˜äºæŒä»“æˆæœ¬çš„æ¯”ä¾‹")
    
    return "\n".join(result)


def format_moneyflow_dc_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–èµ„é‡‘æµå‘æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: èµ„é‡‘æµå‘æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„èµ„é‡‘æµå‘æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨æˆ–å¤šä¸ªè‚¡ç¥¨
    if ts_code:
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            stock_df = df[df['ts_code'] == code]
            if not stock_df.empty:
                result.append(format_single_moneyflow_dc(stock_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # å¦‚æœæœ‰å¤šä¸ªäº¤æ˜“æ—¥æœŸï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„æ˜¾ç¤º
        if 'trade_date' in df.columns and len(df['trade_date'].unique()) > 1:
            dates = sorted(df['trade_date'].unique(), reverse=True)
            for date in dates[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                date_df = df[df['trade_date'] == date]
                if not date_df.empty:
                    result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                    result.append("=" * 160)
                    result.append(f"{'è‚¡ç¥¨ä»£ç ':<15} {'è‚¡ç¥¨åç§°':<15} {'æ¶¨è·Œå¹…':<10} {'æœ€æ–°ä»·':<10} {'ä¸»åŠ›å‡€æµå…¥(ä¸‡)':<18} {'ä¸»åŠ›å‡€æµå…¥å æ¯”':<16} {'è¶…å¤§å•å‡€æµå…¥(ä¸‡)':<18} {'è¶…å¤§å•å æ¯”':<14} {'å¤§å•å‡€æµå…¥(ä¸‡)':<16} {'å¤§å•å æ¯”':<12} {'ä¸­å•å‡€æµå…¥(ä¸‡)':<16} {'ä¸­å•å æ¯”':<12} {'å°å•å‡€æµå…¥(ä¸‡)':<16} {'å°å•å æ¯”':<12}")
                    result.append("-" * 160)
                    
                    # æŒ‰ä¸»åŠ›å‡€æµå…¥é¢æ’åºï¼ˆé™åºï¼‰
                    if 'net_amount' in date_df.columns:
                        date_df = date_df.sort_values('net_amount', ascending=False)
                    
                    for _, row in date_df.iterrows():
                        code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
                        name = str(row['name'])[:12] if 'name' in row and pd.notna(row['name']) else "-"
                        pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
                        close = f"{row['close']:.2f}" if 'close' in row and pd.notna(row['close']) else "-"
                        net_amount = f"{row['net_amount']:.2f}" if 'net_amount' in row and pd.notna(row['net_amount']) else "-"
                        net_amount_rate = f"{row['net_amount_rate']:+.2f}%" if 'net_amount_rate' in row and pd.notna(row['net_amount_rate']) else "-"
                        buy_elg_amount = f"{row['buy_elg_amount']:.2f}" if 'buy_elg_amount' in row and pd.notna(row['buy_elg_amount']) else "-"
                        buy_elg_amount_rate = f"{row['buy_elg_amount_rate']:+.2f}%" if 'buy_elg_amount_rate' in row and pd.notna(row['buy_elg_amount_rate']) else "-"
                        buy_lg_amount = f"{row['buy_lg_amount']:.2f}" if 'buy_lg_amount' in row and pd.notna(row['buy_lg_amount']) else "-"
                        buy_lg_amount_rate = f"{row['buy_lg_amount_rate']:+.2f}%" if 'buy_lg_amount_rate' in row and pd.notna(row['buy_lg_amount_rate']) else "-"
                        buy_md_amount = f"{row['buy_md_amount']:.2f}" if 'buy_md_amount' in row and pd.notna(row['buy_md_amount']) else "-"
                        buy_md_amount_rate = f"{row['buy_md_amount_rate']:+.2f}%" if 'buy_md_amount_rate' in row and pd.notna(row['buy_md_amount_rate']) else "-"
                        buy_sm_amount = f"{row['buy_sm_amount']:.2f}" if 'buy_sm_amount' in row and pd.notna(row['buy_sm_amount']) else "-"
                        buy_sm_amount_rate = f"{row['buy_sm_amount_rate']:+.2f}%" if 'buy_sm_amount_rate' in row and pd.notna(row['buy_sm_amount_rate']) else "-"
                        
                        result.append(f"{code:<15} {name:<15} {pct_change:<10} {close:<10} {net_amount:<18} {net_amount_rate:<16} {buy_elg_amount:<18} {buy_elg_amount_rate:<14} {buy_lg_amount:<16} {buy_lg_amount_rate:<12} {buy_md_amount:<16} {buy_md_amount_rate:<12} {buy_sm_amount:<16} {buy_sm_amount_rate:<12}")
                    result.append("")
        else:
            # å•ä¸ªæ—¥æœŸæˆ–å•ä¸ªè‚¡ç¥¨ï¼Œä½¿ç”¨è¯¦ç»†æ ¼å¼
            if ts_code and len(df['ts_code'].unique()) == 1:
                result.append(format_single_moneyflow_dc(df, df['ts_code'].iloc[0]))
            else:
                # æ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨
                result.append("ğŸ“Š èµ„é‡‘æµå‘æ•°æ®")
                result.append("=" * 160)
                result.append(f"{'è‚¡ç¥¨ä»£ç ':<15} {'è‚¡ç¥¨åç§°':<15} {'æ¶¨è·Œå¹…':<10} {'æœ€æ–°ä»·':<10} {'ä¸»åŠ›å‡€æµå…¥(ä¸‡)':<18} {'ä¸»åŠ›å‡€æµå…¥å æ¯”':<16} {'è¶…å¤§å•å‡€æµå…¥(ä¸‡)':<18} {'è¶…å¤§å•å æ¯”':<14} {'å¤§å•å‡€æµå…¥(ä¸‡)':<16} {'å¤§å•å æ¯”':<12} {'ä¸­å•å‡€æµå…¥(ä¸‡)':<16} {'ä¸­å•å æ¯”':<12} {'å°å•å‡€æµå…¥(ä¸‡)':<16} {'å°å•å æ¯”':<12}")
                result.append("-" * 160)
                
                for _, row in df.iterrows():
                    code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
                    name = str(row['name'])[:12] if 'name' in row and pd.notna(row['name']) else "-"
                    pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
                    close = f"{row['close']:.2f}" if 'close' in row and pd.notna(row['close']) else "-"
                    net_amount = f"{row['net_amount']:.2f}" if 'net_amount' in row and pd.notna(row['net_amount']) else "-"
                    net_amount_rate = f"{row['net_amount_rate']:+.2f}%" if 'net_amount_rate' in row and pd.notna(row['net_amount_rate']) else "-"
                    buy_elg_amount = f"{row['buy_elg_amount']:.2f}" if 'buy_elg_amount' in row and pd.notna(row['buy_elg_amount']) else "-"
                    buy_elg_amount_rate = f"{row['buy_elg_amount_rate']:+.2f}%" if 'buy_elg_amount_rate' in row and pd.notna(row['buy_elg_amount_rate']) else "-"
                    buy_lg_amount = f"{row['buy_lg_amount']:.2f}" if 'buy_lg_amount' in row and pd.notna(row['buy_lg_amount']) else "-"
                    buy_lg_amount_rate = f"{row['buy_lg_amount_rate']:+.2f}%" if 'buy_lg_amount_rate' in row and pd.notna(row['buy_lg_amount_rate']) else "-"
                    buy_md_amount = f"{row['buy_md_amount']:.2f}" if 'buy_md_amount' in row and pd.notna(row['buy_md_amount']) else "-"
                    buy_md_amount_rate = f"{row['buy_md_amount_rate']:+.2f}%" if 'buy_md_amount_rate' in row and pd.notna(row['buy_md_amount_rate']) else "-"
                    buy_sm_amount = f"{row['buy_sm_amount']:.2f}" if 'buy_sm_amount' in row and pd.notna(row['buy_sm_amount']) else "-"
                    buy_sm_amount_rate = f"{row['buy_sm_amount_rate']:+.2f}%" if 'buy_sm_amount_rate' in row and pd.notna(row['buy_sm_amount_rate']) else "-"
                    
                    result.append(f"{code:<15} {name:<15} {pct_change:<10} {close:<10} {net_amount:<18} {net_amount_rate:<16} {buy_elg_amount:<18} {buy_elg_amount_rate:<14} {buy_lg_amount:<16} {buy_lg_amount_rate:<12} {buy_md_amount:<16} {buy_md_amount_rate:<12} {buy_sm_amount:<16} {buy_sm_amount_rate:<12}")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œï¼Œæ¯æ—¥ç›˜åæ›´æ–°ï¼Œæ•°æ®å¼€å§‹äº20230911")
    result.append("  - ä¸»åŠ›å‡€æµå…¥ = è¶…å¤§å•å‡€æµå…¥ + å¤§å•å‡€æµå…¥")
    result.append("  - æ­£æ•°è¡¨ç¤ºå‡€æµå…¥ï¼Œè´Ÿæ•°è¡¨ç¤ºå‡€æµå‡º")
    result.append("  - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§è·å–6000æ¡æ•°æ®")
    
    return "\n".join(result)


def format_single_moneyflow_dc(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªè‚¡ç¥¨çš„èµ„é‡‘æµå‘æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªè‚¡ç¥¨çš„èµ„é‡‘æµå‘æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„èµ„é‡‘æµå‘æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    stock_name = str(df.iloc[0]['name']) if 'name' in df.columns and pd.notna(df.iloc[0]['name']) else ts_code
    result.append(f"ğŸ’° {ts_code} {stock_name} èµ„é‡‘æµå‘æ•°æ®")
    result.append("=" * 160)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š30æ¡ï¼‰
    display_count = min(30, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'æ¶¨è·Œå¹…':<10} {'æœ€æ–°ä»·':<10} {'ä¸»åŠ›å‡€æµå…¥(ä¸‡)':<18} {'ä¸»åŠ›å‡€æµå…¥å æ¯”':<16} {'è¶…å¤§å•å‡€æµå…¥(ä¸‡)':<18} {'è¶…å¤§å•å æ¯”':<14} {'å¤§å•å‡€æµå…¥(ä¸‡)':<16} {'å¤§å•å æ¯”':<12} {'ä¸­å•å‡€æµå…¥(ä¸‡)':<16} {'ä¸­å•å æ¯”':<12} {'å°å•å‡€æµå…¥(ä¸‡)':<16} {'å°å•å æ¯”':<12}")
    result.append("-" * 160)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(str(row['trade_date']))
        pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
        close = f"{row['close']:.2f}" if 'close' in row and pd.notna(row['close']) else "-"
        net_amount = f"{row['net_amount']:.2f}" if 'net_amount' in row and pd.notna(row['net_amount']) else "-"
        net_amount_rate = f"{row['net_amount_rate']:+.2f}%" if 'net_amount_rate' in row and pd.notna(row['net_amount_rate']) else "-"
        buy_elg_amount = f"{row['buy_elg_amount']:.2f}" if 'buy_elg_amount' in row and pd.notna(row['buy_elg_amount']) else "-"
        buy_elg_amount_rate = f"{row['buy_elg_amount_rate']:+.2f}%" if 'buy_elg_amount_rate' in row and pd.notna(row['buy_elg_amount_rate']) else "-"
        buy_lg_amount = f"{row['buy_lg_amount']:.2f}" if 'buy_lg_amount' in row and pd.notna(row['buy_lg_amount']) else "-"
        buy_lg_amount_rate = f"{row['buy_lg_amount_rate']:+.2f}%" if 'buy_lg_amount_rate' in row and pd.notna(row['buy_lg_amount_rate']) else "-"
        buy_md_amount = f"{row['buy_md_amount']:.2f}" if 'buy_md_amount' in row and pd.notna(row['buy_md_amount']) else "-"
        buy_md_amount_rate = f"{row['buy_md_amount_rate']:+.2f}%" if 'buy_md_amount_rate' in row and pd.notna(row['buy_md_amount_rate']) else "-"
        buy_sm_amount = f"{row['buy_sm_amount']:.2f}" if 'buy_sm_amount' in row and pd.notna(row['buy_sm_amount']) else "-"
        buy_sm_amount_rate = f"{row['buy_sm_amount_rate']:+.2f}%" if 'buy_sm_amount_rate' in row and pd.notna(row['buy_sm_amount_rate']) else "-"
        
        result.append(f"{trade_date:<12} {pct_change:<10} {close:<10} {net_amount:<18} {net_amount_rate:<16} {buy_elg_amount:<18} {buy_elg_amount_rate:<14} {buy_lg_amount:<16} {buy_lg_amount_rate:<12} {buy_md_amount:<16} {buy_md_amount_rate:<12} {buy_sm_amount:<16} {buy_sm_amount_rate:<12}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 160)
        trade_date_str = str(latest.get('trade_date', '-'))
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(trade_date_str)}")
        result.append(f"è‚¡ç¥¨åç§°: {latest.get('name', '-')}")
        result.append(f"æ¶¨è·Œå¹…: {latest.get('pct_change', 0):+.2f}%" if pd.notna(latest.get('pct_change')) else "æ¶¨è·Œå¹…: -")
        result.append(f"æœ€æ–°ä»·: {latest.get('close', 0):.2f}" if pd.notna(latest.get('close')) else "æœ€æ–°ä»·: -")
        result.append("")
        result.append("èµ„é‡‘æµå‘ï¼š")
        result.append(f"  ä¸»åŠ›å‡€æµå…¥: {latest.get('net_amount', 0):.2f} ä¸‡å…ƒ ({latest.get('net_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('net_amount')) else "  ä¸»åŠ›å‡€æµå…¥: -")
        result.append(f"  è¶…å¤§å•å‡€æµå…¥: {latest.get('buy_elg_amount', 0):.2f} ä¸‡å…ƒ ({latest.get('buy_elg_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_elg_amount')) else "  è¶…å¤§å•å‡€æµå…¥: -")
        result.append(f"  å¤§å•å‡€æµå…¥: {latest.get('buy_lg_amount', 0):.2f} ä¸‡å…ƒ ({latest.get('buy_lg_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_lg_amount')) else "  å¤§å•å‡€æµå…¥: -")
        result.append(f"  ä¸­å•å‡€æµå…¥: {latest.get('buy_md_amount', 0):.2f} ä¸‡å…ƒ ({latest.get('buy_md_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_md_amount')) else "  ä¸­å•å‡€æµå…¥: -")
        result.append(f"  å°å•å‡€æµå…¥: {latest.get('buy_sm_amount', 0):.2f} ä¸‡å…ƒ ({latest.get('buy_sm_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_sm_amount')) else "  å°å•å‡€æµå…¥: -")
    
    return "\n".join(result)


def format_daily_basic_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–æ¯æ—¥æŒ‡æ ‡æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ¯æ—¥æŒ‡æ ‡æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¯æ—¥æŒ‡æ ‡æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append("ğŸ“Š æ¯æ—¥æŒ‡æ ‡æ•°æ®")
    result.append("=" * 160)
    result.append("")
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨æˆ–å¤šä¸ªè‚¡ç¥¨
    if ts_code:
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            stock_df = df[df['ts_code'] == code]
            if not stock_df.empty:
                result.append(format_single_stock_daily_basic(stock_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # æŒ‰æ—¥æœŸæŸ¥è¯¢ï¼Œæ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨
        # æŒ‰æ—¥æœŸåˆ†ç»„
        dates = df['trade_date'].unique()
        for date in sorted(dates, reverse=True)[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
            date_df = df[df['trade_date'] == date]
            if not date_df.empty:
                result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                result.append("=" * 160)
                result.append(f"{'è‚¡ç¥¨ä»£ç ':<15} {'æ”¶ç›˜ä»·':<10} {'æ¢æ‰‹ç‡(%)':<12} {'é‡æ¯”':<10} {'PE':<10} {'PB':<10} {'PS':<10} {'æ€»å¸‚å€¼(ä¸‡)':<15} {'æµé€šå¸‚å€¼(ä¸‡)':<15}")
                result.append("-" * 160)
                
                for _, row in date_df.head(20).iterrows():  # æœ€å¤šæ˜¾ç¤º20åªè‚¡ç¥¨
                    code = row['ts_code']
                    close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
                    turnover_rate = f"{row['turnover_rate']:.2f}" if pd.notna(row['turnover_rate']) else "-"
                    volume_ratio = f"{row['volume_ratio']:.2f}" if pd.notna(row['volume_ratio']) else "-"
                    pe = f"{row['pe']:.2f}" if pd.notna(row['pe']) else "-"
                    pb = f"{row['pb']:.2f}" if pd.notna(row['pb']) else "-"
                    ps = f"{row['ps']:.2f}" if pd.notna(row['ps']) else "-"
                    total_mv = format_large_number(row['total_mv']) if pd.notna(row['total_mv']) else "-"
                    circ_mv = format_large_number(row['circ_mv']) if pd.notna(row['circ_mv']) else "-"
                    
                    result.append(f"{code:<15} {close:<10} {turnover_rate:<12} {volume_ratio:<10} {pe:<10} {pb:<10} {ps:<10} {total_mv:<15} {circ_mv:<15}")
                
                if len(date_df) > 20:
                    result.append(f"ï¼ˆå…± {len(date_df)} åªè‚¡ç¥¨ï¼Œä»…æ˜¾ç¤ºå‰ 20 åªï¼‰")
                result.append("")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - PEï¼šå¸‚ç›ˆç‡ï¼ˆæ€»å¸‚å€¼/å‡€åˆ©æ¶¦ï¼‰ï¼ŒäºæŸçš„PEä¸ºç©º")
    result.append("  - PBï¼šå¸‚å‡€ç‡ï¼ˆæ€»å¸‚å€¼/å‡€èµ„äº§ï¼‰")
    result.append("  - PSï¼šå¸‚é”€ç‡")
    result.append("  - æ¢æ‰‹ç‡ï¼šåæ˜ è‚¡ç¥¨æµåŠ¨æ€§ï¼Œæ¢æ‰‹ç‡è¶Šé«˜ï¼ŒæµåŠ¨æ€§è¶Šå¥½")
    result.append("  - é‡æ¯”ï¼šå½“æ—¥æˆäº¤é‡ä¸å‰5æ—¥å¹³å‡æˆäº¤é‡çš„æ¯”å€¼ï¼Œåæ˜ æˆäº¤æ´»è·ƒåº¦")
    
    return "\n".join(result)


def format_single_stock_daily_basic(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªè‚¡ç¥¨çš„æ¯æ—¥æŒ‡æ ‡æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªè‚¡ç¥¨çš„æ¯æ—¥æŒ‡æ ‡æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„æ¯æ—¥æŒ‡æ ‡æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append(f"ğŸ“ˆ {ts_code} æ¯æ—¥æŒ‡æ ‡æ•°æ®")
    result.append("=" * 160)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š30æ¡ï¼‰
    display_count = min(30, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'æ”¶ç›˜ä»·':<10} {'æ¢æ‰‹ç‡(%)':<12} {'æ¢æ‰‹ç‡(è‡ªç”±)':<15} {'é‡æ¯”':<10} {'PE':<10} {'PE(TTM)':<12} {'PB':<10} {'PS':<10} {'PS(TTM)':<12} {'è‚¡æ¯ç‡(%)':<12} {'æ€»å¸‚å€¼(ä¸‡)':<15} {'æµé€šå¸‚å€¼(ä¸‡)':<15}")
    result.append("-" * 160)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(row['trade_date'])
        close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
        turnover_rate = f"{row['turnover_rate']:.2f}" if pd.notna(row['turnover_rate']) else "-"
        turnover_rate_f = f"{row['turnover_rate_f']:.2f}" if pd.notna(row['turnover_rate_f']) else "-"
        volume_ratio = f"{row['volume_ratio']:.2f}" if pd.notna(row['volume_ratio']) else "-"
        pe = f"{row['pe']:.2f}" if pd.notna(row['pe']) else "-"
        pe_ttm = f"{row['pe_ttm']:.2f}" if pd.notna(row['pe_ttm']) else "-"
        pb = f"{row['pb']:.2f}" if pd.notna(row['pb']) else "-"
        ps = f"{row['ps']:.2f}" if pd.notna(row['ps']) else "-"
        ps_ttm = f"{row['ps_ttm']:.2f}" if pd.notna(row['ps_ttm']) else "-"
        dv_ratio = f"{row['dv_ratio']:.2f}" if pd.notna(row['dv_ratio']) else "-"
        total_mv = format_large_number(row['total_mv']) if pd.notna(row['total_mv']) else "-"
        circ_mv = format_large_number(row['circ_mv']) if pd.notna(row['circ_mv']) else "-"
        
        result.append(f"{trade_date:<12} {close:<10} {turnover_rate:<12} {turnover_rate_f:<15} {volume_ratio:<10} {pe:<10} {pe_ttm:<12} {pb:<10} {ps:<10} {ps_ttm:<12} {dv_ratio:<12} {total_mv:<15} {circ_mv:<15}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 160)
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(latest['trade_date'])}")
        result.append(f"æ”¶ç›˜ä»·: {latest['close']:.2f}" if pd.notna(latest['close']) else "æ”¶ç›˜ä»·: -")
        result.append("")
        result.append("ä¼°å€¼æŒ‡æ ‡ï¼š")
        result.append(f"  å¸‚ç›ˆç‡(PE): {latest['pe']:.2f}" if pd.notna(latest['pe']) else "  å¸‚ç›ˆç‡(PE): -")
        result.append(f"  å¸‚ç›ˆç‡(TTM): {latest['pe_ttm']:.2f}" if pd.notna(latest['pe_ttm']) else "  å¸‚ç›ˆç‡(TTM): -")
        result.append(f"  å¸‚å‡€ç‡(PB): {latest['pb']:.2f}" if pd.notna(latest['pb']) else "  å¸‚å‡€ç‡(PB): -")
        result.append(f"  å¸‚é”€ç‡(PS): {latest['ps']:.2f}" if pd.notna(latest['ps']) else "  å¸‚é”€ç‡(PS): -")
        result.append(f"  å¸‚é”€ç‡(TTM): {latest['ps_ttm']:.2f}" if pd.notna(latest['ps_ttm']) else "  å¸‚é”€ç‡(TTM): -")
        result.append(f"  è‚¡æ¯ç‡: {latest['dv_ratio']:.2f}%" if pd.notna(latest['dv_ratio']) else "  è‚¡æ¯ç‡: -")
        result.append("")
        result.append("äº¤æ˜“æŒ‡æ ‡ï¼š")
        result.append(f"  æ¢æ‰‹ç‡: {latest['turnover_rate']:.2f}%" if pd.notna(latest['turnover_rate']) else "  æ¢æ‰‹ç‡: -")
        result.append(f"  æ¢æ‰‹ç‡(è‡ªç”±æµé€š): {latest['turnover_rate_f']:.2f}%" if pd.notna(latest['turnover_rate_f']) else "  æ¢æ‰‹ç‡(è‡ªç”±æµé€š): -")
        result.append(f"  é‡æ¯”: {latest['volume_ratio']:.2f}" if pd.notna(latest['volume_ratio']) else "  é‡æ¯”: -")
        result.append("")
        result.append("è‚¡æœ¬ä¸å¸‚å€¼ï¼š")
        result.append(f"  æ€»è‚¡æœ¬: {format_large_number(latest['total_share'])} ä¸‡è‚¡" if pd.notna(latest['total_share']) else "  æ€»è‚¡æœ¬: -")
        result.append(f"  æµé€šè‚¡æœ¬: {format_large_number(latest['float_share'])} ä¸‡è‚¡" if pd.notna(latest['float_share']) else "  æµé€šè‚¡æœ¬: -")
        result.append(f"  è‡ªç”±æµé€šè‚¡æœ¬: {format_large_number(latest['free_share'])} ä¸‡è‚¡" if pd.notna(latest['free_share']) else "  è‡ªç”±æµé€šè‚¡æœ¬: -")
        result.append(f"  æ€»å¸‚å€¼: {format_large_number(latest['total_mv'])} ä¸‡å…ƒ" if pd.notna(latest['total_mv']) else "  æ€»å¸‚å€¼: -")
        result.append(f"  æµé€šå¸‚å€¼: {format_large_number(latest['circ_mv'])} ä¸‡å…ƒ" if pd.notna(latest['circ_mv']) else "  æµé€šå¸‚å€¼: -")
    
    return "\n".join(result)


def format_large_number(num: float) -> str:
    """
    æ ¼å¼åŒ–å¤§æ•°å­—ï¼ˆæ·»åŠ åƒåˆ†ä½åˆ†éš”ç¬¦ï¼‰
    
    å‚æ•°:
        num: æ•°å­—
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if pd.isna(num):
        return "-"
    
    # è½¬æ¢ä¸ºæ•´æ•°ï¼ˆå»æ‰å°æ•°éƒ¨åˆ†ï¼‰
    num_int = int(num)
    
    # æ·»åŠ åƒåˆ†ä½åˆ†éš”ç¬¦
    return f"{num_int:,}"


def format_top_list_data(df: pd.DataFrame, trade_date: str, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–é¾™è™æ¦œæ¯æ—¥äº¤æ˜“æ˜ç»†æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: é¾™è™æ¦œæ•°æ®DataFrame
        trade_date: äº¤æ˜“æ—¥æœŸ
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é¾™è™æ¦œæ•°æ®"
    
    result = []
    result.append("ğŸ‰ é¾™è™æ¦œæ¯æ—¥äº¤æ˜“æ˜ç»†")
    result.append("=" * 180)
    result.append("")
    result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(trade_date)}")
    if ts_code:
        result.append(f"ğŸ“Š è‚¡ç¥¨ä»£ç : {ts_code}")
    result.append("")
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨
    if ts_code and 'ts_code' in df.columns:
        stock_df = df[df['ts_code'] == ts_code]
        if not stock_df.empty:
            result.append(format_single_stock_top_list(stock_df, ts_code))
            return "\n".join(result)
    
    # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
    if 'ts_code' in df.columns:
        # æŒ‰å‡€ä¹°å…¥é¢æ’åºï¼ˆé™åºï¼‰
        if 'net_amount' in df.columns:
            df = df.sort_values('net_amount', ascending=False, na_position='last')
        
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡é¾™è™æ¦œè®°å½•ï¼Œæ¶‰åŠ {len(df['ts_code'].unique())} åªè‚¡ç¥¨")
        result.append("")
        result.append(f"{'è‚¡ç¥¨ä»£ç ':<15} {'è‚¡ç¥¨åç§°':<15} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œå¹…':<10} {'æ¢æ‰‹ç‡':<10} {'æ€»æˆäº¤é¢(å…ƒ)':<18} {'é¾™è™æ¦œä¹°å…¥(å…ƒ)':<18} {'é¾™è™æ¦œå–å‡º(å…ƒ)':<18} {'å‡€ä¹°å…¥(å…ƒ)':<18} {'å‡€ä¹°å æ¯”':<12} {'ä¸Šæ¦œç†ç”±':<30}")
        result.append("-" * 180)
        
        display_count = min(50, len(df))
        for _, row in df.head(display_count).iterrows():
            code = str(row.get('ts_code', '-'))[:13]
            name = str(row.get('name', '-'))[:13]
            close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
            pct_change = f"{row.get('pct_change', 0):+.2f}%" if pd.notna(row.get('pct_change')) else "-"
            turnover_rate = f"{row.get('turnover_rate', 0):.2f}%" if pd.notna(row.get('turnover_rate')) else "-"
            amount = format_large_number(row.get('amount', 0)) if pd.notna(row.get('amount')) else "-"
            l_buy = format_large_number(row.get('l_buy', 0)) if pd.notna(row.get('l_buy')) else "-"
            l_sell = format_large_number(row.get('l_sell', 0)) if pd.notna(row.get('l_sell')) else "-"
            net_amount = format_large_number(row.get('net_amount', 0)) if pd.notna(row.get('net_amount')) else "-"
            net_rate = f"{row.get('net_rate', 0):+.2f}%" if pd.notna(row.get('net_rate')) else "-"
            reason = str(row.get('reason', '-'))[:28]
            
            result.append(f"{code:<15} {name:<15} {close:<10} {pct_change:<10} {turnover_rate:<10} {amount:<18} {l_buy:<18} {l_sell:<18} {net_amount:<18} {net_rate:<12} {reason:<30}")
        
        if len(df) > display_count:
            result.append("")
            result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    else:
        # å¦‚æœæ²¡æœ‰ts_codeå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡é¾™è™æ¦œè®°å½•")
        result.append("")
        result.append(f"{'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œå¹…':<10} {'æ¢æ‰‹ç‡':<10} {'æ€»æˆäº¤é¢(å…ƒ)':<18} {'é¾™è™æ¦œä¹°å…¥(å…ƒ)':<18} {'é¾™è™æ¦œå–å‡º(å…ƒ)':<18} {'å‡€ä¹°å…¥(å…ƒ)':<18} {'å‡€ä¹°å æ¯”':<12} {'ä¸Šæ¦œç†ç”±':<30}")
        result.append("-" * 180)
        
        display_count = min(50, len(df))
        for _, row in df.head(display_count).iterrows():
            close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
            pct_change = f"{row.get('pct_change', 0):+.2f}%" if pd.notna(row.get('pct_change')) else "-"
            turnover_rate = f"{row.get('turnover_rate', 0):.2f}%" if pd.notna(row.get('turnover_rate')) else "-"
            amount = format_large_number(row.get('amount', 0)) if pd.notna(row.get('amount')) else "-"
            l_buy = format_large_number(row.get('l_buy', 0)) if pd.notna(row.get('l_buy')) else "-"
            l_sell = format_large_number(row.get('l_sell', 0)) if pd.notna(row.get('l_sell')) else "-"
            net_amount = format_large_number(row.get('net_amount', 0)) if pd.notna(row.get('net_amount')) else "-"
            net_rate = f"{row.get('net_rate', 0):+.2f}%" if pd.notna(row.get('net_rate')) else "-"
            reason = str(row.get('reason', '-'))[:28]
            
            result.append(f"{close:<10} {pct_change:<10} {turnover_rate:<10} {amount:<18} {l_buy:<18} {l_sell:<18} {net_amount:<18} {net_rate:<12} {reason:<30}")
        
        if len(df) > display_count:
            result.append("")
            result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        result.append(f"ä¸Šæ¦œè‚¡ç¥¨æ•°é‡: {len(df['ts_code'].unique()) if 'ts_code' in df.columns else len(df)}")
        
        if 'net_amount' in df.columns:
            total_net = df['net_amount'].sum()
            result.append(f"æ€»å‡€ä¹°å…¥é¢: {format_large_number(total_net)} å…ƒ")
        
        if 'amount' in df.columns:
            total_amount = df['amount'].sum()
            result.append(f"æ€»æˆäº¤é¢: {format_large_number(total_amount)} å…ƒ")
        
        if 'l_amount' in df.columns:
            total_l_amount = df['l_amount'].sum()
            result.append(f"é¾™è™æ¦œæ€»æˆäº¤é¢: {format_large_number(total_l_amount)} å…ƒ")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare top_listæ¥å£")
    result.append("  - æ•°æ®å†å²ï¼š2005å¹´è‡³ä»Š")
    result.append("  - é¾™è™æ¦œå‡€ä¹°å…¥é¢ = é¾™è™æ¦œä¹°å…¥é¢ - é¾™è™æ¦œå–å‡ºé¢")
    result.append("  - å‡€ä¹°å æ¯” = é¾™è™æ¦œå‡€ä¹°å…¥é¢ / æ€»æˆäº¤é¢")
    result.append("  - ä¸Šæ¦œç†ç”±åŒ…æ‹¬ï¼šæ—¥æ¶¨å¹…/è·Œå¹…åç¦»å€¼è¾¾åˆ°7%ã€æ—¥æ¢æ‰‹ç‡è¾¾åˆ°20%ã€è¿ç»­ä¸‰ä¸ªäº¤æ˜“æ—¥å†…æ¶¨å¹…åç¦»å€¼ç´¯è®¡è¾¾åˆ°20%ç­‰")
    result.append("  - æƒé™è¦æ±‚ï¼š2000ç§¯åˆ†")
    result.append("  - é™é‡ï¼šå•æ¬¡è¯·æ±‚è¿”å›æœ€å¤§10000è¡Œæ•°æ®")
    
    return "\n".join(result)


def format_single_stock_top_list(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªè‚¡ç¥¨çš„é¾™è™æ¦œæ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªè‚¡ç¥¨çš„é¾™è™æ¦œæ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„é¾™è™æ¦œæ•°æ®"
    
    result = []
    result.append(f"ğŸ‰ {ts_code} é¾™è™æ¦œæ•°æ®")
    result.append("=" * 180)
    result.append("")
    
    # æ˜¾ç¤ºæ‰€æœ‰è®°å½•
    result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
    result.append("")
    result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'è‚¡ç¥¨åç§°':<15} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œå¹…':<10} {'æ¢æ‰‹ç‡':<10} {'æ€»æˆäº¤é¢(å…ƒ)':<18} {'é¾™è™æ¦œä¹°å…¥(å…ƒ)':<18} {'é¾™è™æ¦œå–å‡º(å…ƒ)':<18} {'å‡€ä¹°å…¥(å…ƒ)':<18} {'å‡€ä¹°å æ¯”':<12} {'æˆäº¤å æ¯”':<12} {'ä¸Šæ¦œç†ç”±':<30}")
    result.append("-" * 180)
    
    for _, row in df.iterrows():
        trade_date = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
        name = str(row.get('name', '-'))[:13]
        close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
        pct_change = f"{row.get('pct_change', 0):+.2f}%" if pd.notna(row.get('pct_change')) else "-"
        turnover_rate = f"{row.get('turnover_rate', 0):.2f}%" if pd.notna(row.get('turnover_rate')) else "-"
        amount = format_large_number(row.get('amount', 0)) if pd.notna(row.get('amount')) else "-"
        l_buy = format_large_number(row.get('l_buy', 0)) if pd.notna(row.get('l_buy')) else "-"
        l_sell = format_large_number(row.get('l_sell', 0)) if pd.notna(row.get('l_sell')) else "-"
        net_amount = format_large_number(row.get('net_amount', 0)) if pd.notna(row.get('net_amount')) else "-"
        net_rate = f"{row.get('net_rate', 0):+.2f}%" if pd.notna(row.get('net_rate')) else "-"
        amount_rate = f"{row.get('amount_rate', 0):.2f}%" if pd.notna(row.get('amount_rate')) else "-"
        reason = str(row.get('reason', '-'))[:28]
        
        result.append(f"{trade_date:<12} {name:<15} {close:<10} {pct_change:<10} {turnover_rate:<10} {amount:<18} {l_buy:<18} {l_sell:<18} {net_amount:<18} {net_rate:<12} {amount_rate:<12} {reason:<30}")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 180)
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(str(latest.get('trade_date', '-')))}")
        result.append(f"è‚¡ç¥¨ä»£ç : {ts_code}")
        result.append(f"è‚¡ç¥¨åç§°: {latest.get('name', '-')}")
        result.append(f"æ”¶ç›˜ä»·: {latest.get('close', 0):.2f}" if pd.notna(latest.get('close')) else "æ”¶ç›˜ä»·: -")
        result.append(f"æ¶¨è·Œå¹…: {latest.get('pct_change', 0):+.2f}%" if pd.notna(latest.get('pct_change')) else "æ¶¨è·Œå¹…: -")
        result.append(f"æ¢æ‰‹ç‡: {latest.get('turnover_rate', 0):.2f}%" if pd.notna(latest.get('turnover_rate')) else "æ¢æ‰‹ç‡: -")
        result.append(f"æ€»æˆäº¤é¢: {format_large_number(latest.get('amount', 0))} å…ƒ" if pd.notna(latest.get('amount')) else "æ€»æˆäº¤é¢: -")
        result.append(f"é¾™è™æ¦œä¹°å…¥é¢: {format_large_number(latest.get('l_buy', 0))} å…ƒ" if pd.notna(latest.get('l_buy')) else "é¾™è™æ¦œä¹°å…¥é¢: -")
        result.append(f"é¾™è™æ¦œå–å‡ºé¢: {format_large_number(latest.get('l_sell', 0))} å…ƒ" if pd.notna(latest.get('l_sell')) else "é¾™è™æ¦œå–å‡ºé¢: -")
        result.append(f"é¾™è™æ¦œå‡€ä¹°å…¥é¢: {format_large_number(latest.get('net_amount', 0))} å…ƒ" if pd.notna(latest.get('net_amount')) else "é¾™è™æ¦œå‡€ä¹°å…¥é¢: -")
        result.append(f"å‡€ä¹°å æ¯”: {latest.get('net_rate', 0):+.2f}%" if pd.notna(latest.get('net_rate')) else "å‡€ä¹°å æ¯”: -")
        result.append(f"æˆäº¤å æ¯”: {latest.get('amount_rate', 0):.2f}%" if pd.notna(latest.get('amount_rate')) else "æˆäº¤å æ¯”: -")
        result.append(f"ä¸Šæ¦œç†ç”±: {latest.get('reason', '-')}")
    
    return "\n".join(result)


def format_top_inst_data(df: pd.DataFrame, trade_date: str, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–é¾™è™æ¦œæœºæ„æˆäº¤æ˜ç»†æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: é¾™è™æ¦œæœºæ„æ˜ç»†æ•°æ®DataFrame
        trade_date: äº¤æ˜“æ—¥æœŸ
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é¾™è™æ¦œæœºæ„æ˜ç»†æ•°æ®"
    
    result = []
    result.append("ğŸ¢ é¾™è™æ¦œæœºæ„æˆäº¤æ˜ç»†")
    result.append("=" * 180)
    result.append("")
    result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(trade_date)}")
    if ts_code:
        result.append(f"ğŸ“Š è‚¡ç¥¨ä»£ç : {ts_code}")
    result.append("")
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨
    if ts_code and 'ts_code' in df.columns:
        stock_df = df[df['ts_code'] == ts_code]
        if not stock_df.empty:
            result.append(format_single_stock_top_inst(stock_df, ts_code))
            return "\n".join(result)
    
    # æŒ‰è‚¡ç¥¨ä»£ç å’Œä¹°å–ç±»å‹åˆ†ç»„æ˜¾ç¤º
    if 'ts_code' in df.columns:
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„
        codes = sorted(df['ts_code'].unique())
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æœºæ„æ˜ç»†è®°å½•ï¼Œæ¶‰åŠ {len(codes)} åªè‚¡ç¥¨")
        result.append("")
        
        for code in codes[:20]:  # æœ€å¤šæ˜¾ç¤ºå‰20åªè‚¡ç¥¨
            code_df = df[df['ts_code'] == code]
            if not code_df.empty:
                # è·å–è‚¡ç¥¨åç§°ï¼ˆå¦‚æœæœ‰ï¼‰
                stock_name = ""
                if 'name' in code_df.columns and not code_df['name'].isna().all():
                    stock_name = code_df['name'].iloc[0]
                
                result.append(f"ğŸ“ˆ {code} {stock_name} ({len(code_df)} æ¡è®°å½•)")
                result.append("-" * 180)
                
                # åˆ†åˆ«æ˜¾ç¤ºä¹°å…¥å’Œå–å‡º
                buy_df = code_df[code_df['side'] == 0] if 'side' in code_df.columns else pd.DataFrame()
                sell_df = code_df[code_df['side'] == 1] if 'side' in code_df.columns else pd.DataFrame()
                
                if not buy_df.empty:
                    result.append("ğŸ’° ä¹°å…¥é‡‘é¢æœ€å¤§çš„å‰5åï¼š")
                    result.append(f"{'è¥ä¸šéƒ¨åç§°':<30} {'ä¹°å…¥é¢(å…ƒ)':<18} {'ä¹°å…¥å æ¯”':<12} {'å–å‡ºé¢(å…ƒ)':<18} {'å–å‡ºå æ¯”':<12} {'å‡€æˆäº¤é¢(å…ƒ)':<18} {'ä¸Šæ¦œç†ç”±':<30}")
                    result.append("-" * 180)
                    
                    # æŒ‰ä¹°å…¥é¢æ’åºï¼ˆé™åºï¼‰
                    if 'buy' in buy_df.columns:
                        buy_df = buy_df.sort_values('buy', ascending=False, na_position='last')
                    
                    for _, row in buy_df.head(10).iterrows():  # æœ€å¤šæ˜¾ç¤º10æ¡
                        exalter = str(row.get('exalter', '-'))[:28]
                        buy = format_large_number(row.get('buy', 0)) if pd.notna(row.get('buy')) else "-"
                        buy_rate = f"{row.get('buy_rate', 0):.2f}%" if pd.notna(row.get('buy_rate')) else "-"
                        sell = format_large_number(row.get('sell', 0)) if pd.notna(row.get('sell')) else "-"
                        sell_rate = f"{row.get('sell_rate', 0):.2f}%" if pd.notna(row.get('sell_rate')) else "-"
                        net_buy = format_large_number(row.get('net_buy', 0)) if pd.notna(row.get('net_buy')) else "-"
                        reason = str(row.get('reason', '-'))[:28]
                        
                        result.append(f"{exalter:<30} {buy:<18} {buy_rate:<12} {sell:<18} {sell_rate:<12} {net_buy:<18} {reason:<30}")
                    result.append("")
                
                if not sell_df.empty:
                    result.append("ğŸ’¸ å–å‡ºé‡‘é¢æœ€å¤§çš„å‰5åï¼š")
                    result.append(f"{'è¥ä¸šéƒ¨åç§°':<30} {'ä¹°å…¥é¢(å…ƒ)':<18} {'ä¹°å…¥å æ¯”':<12} {'å–å‡ºé¢(å…ƒ)':<18} {'å–å‡ºå æ¯”':<12} {'å‡€æˆäº¤é¢(å…ƒ)':<18} {'ä¸Šæ¦œç†ç”±':<30}")
                    result.append("-" * 180)
                    
                    # æŒ‰å–å‡ºé¢æ’åºï¼ˆé™åºï¼‰
                    if 'sell' in sell_df.columns:
                        sell_df = sell_df.sort_values('sell', ascending=False, na_position='last')
                    
                    for _, row in sell_df.head(10).iterrows():  # æœ€å¤šæ˜¾ç¤º10æ¡
                        exalter = str(row.get('exalter', '-'))[:28]
                        buy = format_large_number(row.get('buy', 0)) if pd.notna(row.get('buy')) else "-"
                        buy_rate = f"{row.get('buy_rate', 0):.2f}%" if pd.notna(row.get('buy_rate')) else "-"
                        sell = format_large_number(row.get('sell', 0)) if pd.notna(row.get('sell')) else "-"
                        sell_rate = f"{row.get('sell_rate', 0):.2f}%" if pd.notna(row.get('sell_rate')) else "-"
                        net_buy = format_large_number(row.get('net_buy', 0)) if pd.notna(row.get('net_buy')) else "-"
                        reason = str(row.get('reason', '-'))[:28]
                        
                        result.append(f"{exalter:<30} {buy:<18} {buy_rate:<12} {sell:<18} {sell_rate:<12} {net_buy:<18} {reason:<30}")
                    result.append("")
                
                result.append("")
        
        if len(codes) > 20:
            result.append(f"  ... è¿˜æœ‰ {len(codes) - 20} åªè‚¡ç¥¨æœªæ˜¾ç¤º")
    else:
        # å¦‚æœæ²¡æœ‰ts_codeå­—æ®µï¼ŒæŒ‰ä¹°å–ç±»å‹åˆ†ç»„æ˜¾ç¤º
        if 'side' in df.columns:
            result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æœºæ„æ˜ç»†è®°å½•")
            result.append("")
            
            # ä¹°å…¥è®°å½•
            buy_df = df[df['side'] == 0]
            if not buy_df.empty:
                result.append("ğŸ’° ä¹°å…¥é‡‘é¢æœ€å¤§çš„å‰5åï¼š")
                result.append(f"{'è¥ä¸šéƒ¨åç§°':<30} {'ä¹°å…¥é¢(å…ƒ)':<18} {'ä¹°å…¥å æ¯”':<12} {'å–å‡ºé¢(å…ƒ)':<18} {'å–å‡ºå æ¯”':<12} {'å‡€æˆäº¤é¢(å…ƒ)':<18} {'ä¸Šæ¦œç†ç”±':<30}")
                result.append("-" * 180)
                
                # æŒ‰ä¹°å…¥é¢æ’åºï¼ˆé™åºï¼‰
                if 'buy' in buy_df.columns:
                    buy_df = buy_df.sort_values('buy', ascending=False, na_position='last')
                
                for _, row in buy_df.head(50).iterrows():
                    exalter = str(row.get('exalter', '-'))[:28]
                    buy = format_large_number(row.get('buy', 0)) if pd.notna(row.get('buy')) else "-"
                    buy_rate = f"{row.get('buy_rate', 0):.2f}%" if pd.notna(row.get('buy_rate')) else "-"
                    sell = format_large_number(row.get('sell', 0)) if pd.notna(row.get('sell')) else "-"
                    sell_rate = f"{row.get('sell_rate', 0):.2f}%" if pd.notna(row.get('sell_rate')) else "-"
                    net_buy = format_large_number(row.get('net_buy', 0)) if pd.notna(row.get('net_buy')) else "-"
                    reason = str(row.get('reason', '-'))[:28]
                    
                    result.append(f"{exalter:<30} {buy:<18} {buy_rate:<12} {sell:<18} {sell_rate:<12} {net_buy:<18} {reason:<30}")
                result.append("")
            
            # å–å‡ºè®°å½•
            sell_df = df[df['side'] == 1]
            if not sell_df.empty:
                result.append("ğŸ’¸ å–å‡ºé‡‘é¢æœ€å¤§çš„å‰5åï¼š")
                result.append(f"{'è¥ä¸šéƒ¨åç§°':<30} {'ä¹°å…¥é¢(å…ƒ)':<18} {'ä¹°å…¥å æ¯”':<12} {'å–å‡ºé¢(å…ƒ)':<18} {'å–å‡ºå æ¯”':<12} {'å‡€æˆäº¤é¢(å…ƒ)':<18} {'ä¸Šæ¦œç†ç”±':<30}")
                result.append("-" * 180)
                
                # æŒ‰å–å‡ºé¢æ’åºï¼ˆé™åºï¼‰
                if 'sell' in sell_df.columns:
                    sell_df = sell_df.sort_values('sell', ascending=False, na_position='last')
                
                for _, row in sell_df.head(50).iterrows():
                    exalter = str(row.get('exalter', '-'))[:28]
                    buy = format_large_number(row.get('buy', 0)) if pd.notna(row.get('buy')) else "-"
                    buy_rate = f"{row.get('buy_rate', 0):.2f}%" if pd.notna(row.get('buy_rate')) else "-"
                    sell = format_large_number(row.get('sell', 0)) if pd.notna(row.get('sell')) else "-"
                    sell_rate = f"{row.get('sell_rate', 0):.2f}%" if pd.notna(row.get('sell_rate')) else "-"
                    net_buy = format_large_number(row.get('net_buy', 0)) if pd.notna(row.get('net_buy')) else "-"
                    reason = str(row.get('reason', '-'))[:28]
                    
                    result.append(f"{exalter:<30} {buy:<18} {buy_rate:<12} {sell:<18} {sell_rate:<12} {net_buy:<18} {reason:<30}")
                result.append("")
        else:
            # æ²¡æœ‰sideå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
            result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æœºæ„æ˜ç»†è®°å½•")
            result.append("")
            result.append(f"{'è¥ä¸šéƒ¨åç§°':<30} {'ä¹°å…¥é¢(å…ƒ)':<18} {'ä¹°å…¥å æ¯”':<12} {'å–å‡ºé¢(å…ƒ)':<18} {'å–å‡ºå æ¯”':<12} {'å‡€æˆäº¤é¢(å…ƒ)':<18} {'ä¸Šæ¦œç†ç”±':<30}")
            result.append("-" * 180)
            
            display_count = min(100, len(df))
            for _, row in df.head(display_count).iterrows():
                exalter = str(row.get('exalter', '-'))[:28]
                buy = format_large_number(row.get('buy', 0)) if pd.notna(row.get('buy')) else "-"
                buy_rate = f"{row.get('buy_rate', 0):.2f}%" if pd.notna(row.get('buy_rate')) else "-"
                sell = format_large_number(row.get('sell', 0)) if pd.notna(row.get('sell')) else "-"
                sell_rate = f"{row.get('sell_rate', 0):.2f}%" if pd.notna(row.get('sell_rate')) else "-"
                net_buy = format_large_number(row.get('net_buy', 0)) if pd.notna(row.get('net_buy')) else "-"
                reason = str(row.get('reason', '-'))[:28]
                
                result.append(f"{exalter:<30} {buy:<18} {buy_rate:<12} {sell:<18} {sell_rate:<12} {net_buy:<18} {reason:<30}")
            
            if len(df) > display_count:
                result.append("")
                result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        
        if 'ts_code' in df.columns:
            result.append(f"ä¸Šæ¦œè‚¡ç¥¨æ•°é‡: {len(df['ts_code'].unique())}")
        
        if 'exalter' in df.columns:
            result.append(f"æ¶‰åŠè¥ä¸šéƒ¨æ•°é‡: {len(df['exalter'].unique())}")
        
        if 'buy' in df.columns:
            total_buy = df['buy'].sum()
            result.append(f"æ€»ä¹°å…¥é¢: {format_large_number(total_buy)} å…ƒ")
        
        if 'sell' in df.columns:
            total_sell = df['sell'].sum()
            result.append(f"æ€»å–å‡ºé¢: {format_large_number(total_sell)} å…ƒ")
        
        if 'net_buy' in df.columns:
            total_net = df['net_buy'].sum()
            result.append(f"æ€»å‡€æˆäº¤é¢: {format_large_number(total_net)} å…ƒ")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare top_instæ¥å£")
    result.append("  - ä¹°å–ç±»å‹ï¼š0=ä¹°å…¥é‡‘é¢æœ€å¤§çš„å‰5åï¼Œ1=å–å‡ºé‡‘é¢æœ€å¤§çš„å‰5å")
    result.append("  - å‡€æˆäº¤é¢ = ä¹°å…¥é¢ - å–å‡ºé¢")
    result.append("  - ä¹°å…¥å æ¯” = ä¹°å…¥é¢ / æ€»æˆäº¤é¢")
    result.append("  - å–å‡ºå æ¯” = å–å‡ºé¢ / æ€»æˆäº¤é¢")
    result.append("  - ä¸Šæ¦œç†ç”±åŒ…æ‹¬ï¼šæ¶¨å¹…åç¦»å€¼è¾¾7%ã€è¿ç»­ä¸‰ä¸ªäº¤æ˜“æ—¥å†…æ¶¨å¹…åç¦»å€¼ç´¯è®¡è¾¾20%ç­‰")
    result.append("  - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†")
    result.append("  - é™é‡ï¼šå•æ¬¡è¯·æ±‚æœ€å¤§è¿”å›10000è¡Œæ•°æ®")
    
    return "\n".join(result)


def format_single_stock_top_inst(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªè‚¡ç¥¨çš„é¾™è™æ¦œæœºæ„æ˜ç»†æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªè‚¡ç¥¨çš„é¾™è™æ¦œæœºæ„æ˜ç»†æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„é¾™è™æ¦œæœºæ„æ˜ç»†æ•°æ®"
    
    result = []
    result.append(f"ğŸ¢ {ts_code} é¾™è™æ¦œæœºæ„æ˜ç»†")
    result.append("=" * 180)
    result.append("")
    
    # è·å–è‚¡ç¥¨åç§°ï¼ˆå¦‚æœæœ‰ï¼‰
    stock_name = ""
    if 'name' in df.columns and not df['name'].isna().all():
        stock_name = df['name'].iloc[0]
        result.append(f"è‚¡ç¥¨åç§°: {stock_name}")
    
    result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
    result.append("")
    
    # åˆ†åˆ«æ˜¾ç¤ºä¹°å…¥å’Œå–å‡º
    buy_df = df[df['side'] == 0] if 'side' in df.columns else pd.DataFrame()
    sell_df = df[df['side'] == 1] if 'side' in df.columns else pd.DataFrame()
    
    if not buy_df.empty:
        result.append("ğŸ’° ä¹°å…¥é‡‘é¢æœ€å¤§çš„å‰5åï¼š")
        result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'è¥ä¸šéƒ¨åç§°':<30} {'ä¹°å…¥é¢(å…ƒ)':<18} {'ä¹°å…¥å æ¯”':<12} {'å–å‡ºé¢(å…ƒ)':<18} {'å–å‡ºå æ¯”':<12} {'å‡€æˆäº¤é¢(å…ƒ)':<18} {'ä¸Šæ¦œç†ç”±':<30}")
        result.append("-" * 180)
        
        # æŒ‰ä¹°å…¥é¢æ’åºï¼ˆé™åºï¼‰
        if 'buy' in buy_df.columns:
            buy_df = buy_df.sort_values('buy', ascending=False, na_position='last')
        
        for _, row in buy_df.iterrows():
            trade_date = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
            exalter = str(row.get('exalter', '-'))[:28]
            buy = format_large_number(row.get('buy', 0)) if pd.notna(row.get('buy')) else "-"
            buy_rate = f"{row.get('buy_rate', 0):.2f}%" if pd.notna(row.get('buy_rate')) else "-"
            sell = format_large_number(row.get('sell', 0)) if pd.notna(row.get('sell')) else "-"
            sell_rate = f"{row.get('sell_rate', 0):.2f}%" if pd.notna(row.get('sell_rate')) else "-"
            net_buy = format_large_number(row.get('net_buy', 0)) if pd.notna(row.get('net_buy')) else "-"
            reason = str(row.get('reason', '-'))[:28]
            
            result.append(f"{trade_date:<12} {exalter:<30} {buy:<18} {buy_rate:<12} {sell:<18} {sell_rate:<12} {net_buy:<18} {reason:<30}")
        result.append("")
    
    if not sell_df.empty:
        result.append("ğŸ’¸ å–å‡ºé‡‘é¢æœ€å¤§çš„å‰5åï¼š")
        result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'è¥ä¸šéƒ¨åç§°':<30} {'ä¹°å…¥é¢(å…ƒ)':<18} {'ä¹°å…¥å æ¯”':<12} {'å–å‡ºé¢(å…ƒ)':<18} {'å–å‡ºå æ¯”':<12} {'å‡€æˆäº¤é¢(å…ƒ)':<18} {'ä¸Šæ¦œç†ç”±':<30}")
        result.append("-" * 180)
        
        # æŒ‰å–å‡ºé¢æ’åºï¼ˆé™åºï¼‰
        if 'sell' in sell_df.columns:
            sell_df = sell_df.sort_values('sell', ascending=False, na_position='last')
        
        for _, row in sell_df.iterrows():
            trade_date = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
            exalter = str(row.get('exalter', '-'))[:28]
            buy = format_large_number(row.get('buy', 0)) if pd.notna(row.get('buy')) else "-"
            buy_rate = f"{row.get('buy_rate', 0):.2f}%" if pd.notna(row.get('buy_rate')) else "-"
            sell = format_large_number(row.get('sell', 0)) if pd.notna(row.get('sell')) else "-"
            sell_rate = f"{row.get('sell_rate', 0):.2f}%" if pd.notna(row.get('sell_rate')) else "-"
            net_buy = format_large_number(row.get('net_buy', 0)) if pd.notna(row.get('net_buy')) else "-"
            reason = str(row.get('reason', '-'))[:28]
            
            result.append(f"{trade_date:<12} {exalter:<30} {buy:<18} {buy_rate:<12} {sell:<18} {sell_rate:<12} {net_buy:<18} {reason:<30}")
        result.append("")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        
        if 'exalter' in df.columns:
            result.append(f"æ¶‰åŠè¥ä¸šéƒ¨æ•°é‡: {len(df['exalter'].unique())}")
        
        if 'buy' in df.columns:
            total_buy = df['buy'].sum()
            result.append(f"æ€»ä¹°å…¥é¢: {format_large_number(total_buy)} å…ƒ")
        
        if 'sell' in df.columns:
            total_sell = df['sell'].sum()
            result.append(f"æ€»å–å‡ºé¢: {format_large_number(total_sell)} å…ƒ")
        
        if 'net_buy' in df.columns:
            total_net = df['net_buy'].sum()
            result.append(f"æ€»å‡€æˆäº¤é¢: {format_large_number(total_net)} å…ƒ")
    
    return "\n".join(result)


def format_stock_min_data(df: pd.DataFrame, ts_code: str = "", freq: str = "1MIN", date_str: str = "") -> str:
    """
    æ ¼å¼åŒ–Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: Aè‚¡åˆ†é’Ÿè¡Œæƒ…æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        freq: åˆ†é’Ÿé¢‘åº¦ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        date_str: å›æ”¾æ—¥æœŸï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„Aè‚¡åˆ†é’Ÿè¡Œæƒ…æ•°æ®"
    
    result = []
    result.append("ğŸ“ˆ Aè‚¡å®æ—¶åˆ†é’Ÿè¡Œæƒ…æ•°æ®")
    result.append("=" * 180)
    result.append("")
    
    # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    if 'time' in df.columns:
        df = df.sort_values('time', ascending=False)
    
    # å¦‚æœæœ‰å¤šä¸ªè‚¡ç¥¨ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
    if 'ts_code' in df.columns and len(df['ts_code'].unique()) > 1:
        codes = sorted(df['ts_code'].unique())
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•ï¼Œæ¶‰åŠ {len(codes)} åªè‚¡ç¥¨")
        result.append(f"åˆ†é’Ÿé¢‘åº¦: {freq}")
        if date_str:
            result.append(f"å›æ”¾æ—¥æœŸ: {date_str}")
        result.append("")
        
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        for code in codes:
            code_df = df[df['ts_code'] == code]
            if not code_df.empty:
                result.append(f"ğŸ“Š {code} åˆ†é’Ÿè¡Œæƒ…æ•°æ®")
                result.append("-" * 180)
                result.append(f"{'äº¤æ˜“æ—¶é—´':<20} {'å¼€ç›˜':<12} {'æœ€é«˜':<12} {'æœ€ä½':<12} {'æ”¶ç›˜':<12} {'æˆäº¤é‡(è‚¡)':<18} {'æˆäº¤é¢(å…ƒ)':<18}")
                result.append("-" * 180)
                
                # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                if 'time' in code_df.columns:
                    code_df = code_df.sort_values('time', ascending=False)
                
                display_count = min(100, len(code_df))
                for _, row in code_df.head(display_count).iterrows():
                    time_str = str(row.get('time', '-'))[:18]
                    open_price = f"{row.get('open', 0):.2f}" if pd.notna(row.get('open')) else "-"
                    high = f"{row.get('high', 0):.2f}" if pd.notna(row.get('high')) else "-"
                    low = f"{row.get('low', 0):.2f}" if pd.notna(row.get('low')) else "-"
                    close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
                    vol = f"{row.get('vol', 0):,.0f}" if pd.notna(row.get('vol')) else "-"
                    amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
                    
                    result.append(f"{time_str:<20} {open_price:<12} {high:<12} {low:<12} {close:<12} {vol:<18} {amount:<18}")
                
                if len(code_df) > display_count:
                    result.append(f"  ... è¿˜æœ‰ {len(code_df) - display_count} æ¡è®°å½•æœªæ˜¾ç¤º")
                result.append("")
        
        if len(codes) > 10:
            result.append(f"  ... è¿˜æœ‰ {len(codes) - 10} åªè‚¡ç¥¨æœªæ˜¾ç¤º")
    else:
        # å•ä¸ªè‚¡ç¥¨æˆ–æ²¡æœ‰ts_codeå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
        if 'ts_code' in df.columns and not df.empty:
            code = df.iloc[0].get('ts_code', ts_code or '-')
            result.append(f"ğŸ“Š {code} åˆ†é’Ÿè¡Œæƒ…æ•°æ®")
        else:
            result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
        result.append("")
        result.append(f"åˆ†é’Ÿé¢‘åº¦: {freq}")
        if date_str:
            result.append(f"å›æ”¾æ—¥æœŸ: {date_str}")
        result.append("")
        result.append(f"{'äº¤æ˜“æ—¶é—´':<20} {'å¼€ç›˜':<12} {'æœ€é«˜':<12} {'æœ€ä½':<12} {'æ”¶ç›˜':<12} {'æˆäº¤é‡(è‚¡)':<18} {'æˆäº¤é¢(å…ƒ)':<18}")
        result.append("-" * 180)
        
        display_count = min(200, len(df))
        for _, row in df.head(display_count).iterrows():
            time_str = str(row.get('time', '-'))[:18]
            open_price = f"{row.get('open', 0):.2f}" if pd.notna(row.get('open')) else "-"
            high = f"{row.get('high', 0):.2f}" if pd.notna(row.get('high')) else "-"
            low = f"{row.get('low', 0):.2f}" if pd.notna(row.get('low')) else "-"
            close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
            vol = f"{row.get('vol', 0):,.0f}" if pd.notna(row.get('vol')) else "-"
            amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
            
            result.append(f"{time_str:<20} {open_price:<12} {high:<12} {low:<12} {close:<12} {vol:<18} {amount:<18}")
        
        if len(df) > display_count:
            result.append("")
            result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 180)
        if 'ts_code' in latest:
            result.append(f"è‚¡ç¥¨ä»£ç : {latest.get('ts_code', '-')}")
        if 'time' in latest:
            result.append(f"äº¤æ˜“æ—¶é—´: {latest.get('time', '-')}")
        if 'open' in latest and pd.notna(latest.get('open')):
            result.append(f"å¼€ç›˜: {latest.get('open', 0):.2f}")
        if 'high' in latest and pd.notna(latest.get('high')):
            result.append(f"æœ€é«˜: {latest.get('high', 0):.2f}")
        if 'low' in latest and pd.notna(latest.get('low')):
            result.append(f"æœ€ä½: {latest.get('low', 0):.2f}")
        if 'close' in latest and pd.notna(latest.get('close')):
            result.append(f"æ”¶ç›˜: {latest.get('close', 0):.2f}")
        if 'vol' in latest and pd.notna(latest.get('vol')):
            result.append(f"æˆäº¤é‡: {latest.get('vol', 0):,.0f} è‚¡")
        if 'amount' in latest and pd.notna(latest.get('amount')):
            result.append(f"æˆäº¤é¢: {latest.get('amount', 0):,.2f} å…ƒ")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    if date_str:
        result.append("  - æ•°æ®æ¥æºï¼šTushare rt_min_dailyæ¥å£ï¼ˆå†å²å›æ”¾ï¼‰")
        result.append("  - æä¾›å½“æ—¥å¼€ç›˜ä»¥æ¥çš„æ‰€æœ‰å†å²åˆ†é’Ÿæ•°æ®")
    else:
        result.append("  - æ•°æ®æ¥æºï¼šTushare rt_minæ¥å£ï¼ˆå®æ—¶ï¼‰")
        result.append("  - è·å–å…¨Aè‚¡ç¥¨å®æ—¶åˆ†é’Ÿæ•°æ®")
    result.append("  - æ”¯æŒ1min/5min/15min/30min/60minè¡Œæƒ…")
    result.append("  - æƒé™è¦æ±‚ï¼šæ­£å¼æƒé™è¯·å‚é˜…æƒé™è¯´æ˜")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§1000è¡Œæ•°æ®ï¼Œæ”¯æŒå¤šä¸ªè‚¡ç¥¨åŒæ—¶æå–")
    result.append("  - æ³¨æ„ï¼šrt_min_dailyæ¥å£ä»…æ”¯æŒå•ä¸ªè‚¡ç¥¨æå–ï¼Œä¸èƒ½åŒæ—¶æå–å¤šä¸ª")
    
    return "\n".join(result)


def format_stock_rt_k_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–æ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: å®æ—¶æ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç æˆ–é€šé…ç¬¦ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æ•°æ®"
    
    result = []
    result.append("ğŸ“ˆ æ²ªæ·±äº¬å®æ—¶æ—¥çº¿è¡Œæƒ…æ•°æ®")
    result.append("=" * 180)
    result.append("")
    
    # æŒ‰æˆäº¤é‡æ’åºï¼ˆé™åºï¼‰ï¼Œæ˜¾ç¤ºæœ€æ´»è·ƒçš„è‚¡ç¥¨
    if 'vol' in df.columns:
        df = df.sort_values('vol', ascending=False, na_position='last')
    
    result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
    if ts_code:
        result.append(f"æŸ¥è¯¢æ¡ä»¶: {ts_code}")
    result.append("")
    
    # æ˜¾ç¤ºä¸»è¦è¡Œæƒ…æ•°æ®
    result.append(f"{'è‚¡ç¥¨ä»£ç ':<12} {'è‚¡ç¥¨åç§°':<20} {'æ˜¨æ”¶':<10} {'å¼€ç›˜':<10} {'æœ€é«˜':<10} {'æœ€ä½':<10} {'æœ€æ–°ä»·':<10} {'æˆäº¤é‡(è‚¡)':<18} {'æˆäº¤é¢(å…ƒ)':<18} {'æˆäº¤ç¬”æ•°':<12}")
    result.append("-" * 180)
    
    display_count = min(200, len(df))
    for _, row in df.head(display_count).iterrows():
        code = str(row.get('ts_code', '-'))[:10]
        name = str(row.get('name', '-'))[:18]
        pre_close = f"{row.get('pre_close', 0):.2f}" if pd.notna(row.get('pre_close')) else "-"
        open_price = f"{row.get('open', 0):.2f}" if pd.notna(row.get('open')) else "-"
        high = f"{row.get('high', 0):.2f}" if pd.notna(row.get('high')) else "-"
        low = f"{row.get('low', 0):.2f}" if pd.notna(row.get('low')) else "-"
        close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
        vol = f"{row.get('vol', 0):,.0f}" if pd.notna(row.get('vol')) else "-"
        amount = f"{row.get('amount', 0):,.0f}" if pd.notna(row.get('amount')) else "-"
        num = f"{row.get('num', 0):,.0f}" if pd.notna(row.get('num')) else "-"
        
        result.append(f"{code:<12} {name:<20} {pre_close:<10} {open_price:<10} {high:<10} {low:<10} {close:<10} {vol:<18} {amount:<18} {num:<12}")
    
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼ŒæŒ‰æˆäº¤é‡é™åºæ’åˆ—ï¼‰")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        
        if 'vol' in df.columns:
            total_vol = df['vol'].sum()
            result.append(f"æ€»æˆäº¤é‡: {total_vol:,.0f} è‚¡")
        
        if 'amount' in df.columns:
            total_amount = df['amount'].sum()
            result.append(f"æ€»æˆäº¤é¢: {total_amount:,.0f} å…ƒ")
        
        if 'num' in df.columns:
            total_num = df['num'].sum()
            result.append(f"æ€»æˆäº¤ç¬”æ•°: {total_num:,.0f} ç¬”")
        
        # è®¡ç®—æ¶¨è·Œæƒ…å†µ
        if 'close' in df.columns and 'pre_close' in df.columns:
            up_count = 0
            down_count = 0
            flat_count = 0
            for _, row in df.iterrows():
                if pd.notna(row.get('close')) and pd.notna(row.get('pre_close')):
                    if row.get('close') > row.get('pre_close'):
                        up_count += 1
                    elif row.get('close') < row.get('pre_close'):
                        down_count += 1
                    else:
                        flat_count += 1
            
            if up_count + down_count + flat_count > 0:
                result.append(f"ä¸Šæ¶¨: {up_count} åªï¼Œä¸‹è·Œ: {down_count} åªï¼Œå¹³ç›˜: {flat_count} åª")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦ï¼ˆå‰5åªæœ€æ´»è·ƒçš„è‚¡ç¥¨ï¼‰
    if not df.empty and len(df) > 0:
        result.append("")
        result.append("ğŸ“Š æœ€æ´»è·ƒè‚¡ç¥¨è¯¦æƒ…ï¼ˆå‰5åªï¼‰ï¼š")
        result.append("-" * 180)
        
        for idx, (_, row) in enumerate(df.head(5).iterrows()):
            code = str(row.get('ts_code', '-'))
            name = str(row.get('name', '-'))
            result.append(f"\n{idx + 1}. {code} ({name})")
            
            if pd.notna(row.get('pre_close')):
                result.append(f"   æ˜¨æ”¶: {row.get('pre_close', 0):.2f}")
            if pd.notna(row.get('open')):
                result.append(f"   å¼€ç›˜: {row.get('open', 0):.2f}")
            if pd.notna(row.get('high')):
                result.append(f"   æœ€é«˜: {row.get('high', 0):.2f}")
            if pd.notna(row.get('low')):
                result.append(f"   æœ€ä½: {row.get('low', 0):.2f}")
            if pd.notna(row.get('close')):
                result.append(f"   æœ€æ–°ä»·: {row.get('close', 0):.2f}")
                if pd.notna(row.get('pre_close')):
                    change = row.get('close', 0) - row.get('pre_close', 0)
                    change_pct = (change / row.get('pre_close', 1)) * 100 if row.get('pre_close', 0) != 0 else 0
                    result.append(f"   æ¶¨è·Œ: {change:+.2f} ({change_pct:+.2f}%)")
            if pd.notna(row.get('vol')):
                result.append(f"   æˆäº¤é‡: {row.get('vol', 0):,.0f} è‚¡")
            if pd.notna(row.get('amount')):
                result.append(f"   æˆäº¤é¢: {row.get('amount', 0):,.0f} å…ƒ")
            if pd.notna(row.get('num')):
                result.append(f"   æˆäº¤ç¬”æ•°: {row.get('num', 0):,.0f} ç¬”")
            
            # æ˜¾ç¤ºå§”æ‰˜ä¹°å–ç›˜ä¿¡æ¯
            if pd.notna(row.get('ask_price1')) and pd.notna(row.get('ask_volume1')):
                result.append(f"   å–ä¸€: {row.get('ask_price1', 0):.2f} ({row.get('ask_volume1', 0):,.0f} è‚¡)")
            if pd.notna(row.get('bid_price1')) and pd.notna(row.get('bid_volume1')):
                result.append(f"   ä¹°ä¸€: {row.get('bid_price1', 0):.2f} ({row.get('bid_volume1', 0):,.0f} è‚¡)")
            
            if pd.notna(row.get('trade_time')):
                result.append(f"   äº¤æ˜“æ—¶é—´: {row.get('trade_time', '-')}")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare rt_kæ¥å£")
    result.append("  - è·å–å®æ—¶æ—¥kçº¿è¡Œæƒ…ï¼Œæ”¯æŒæŒ‰è‚¡ç¥¨ä»£ç åŠè‚¡ç¥¨ä»£ç é€šé…ç¬¦ä¸€æ¬¡æ€§æå–")
    result.append("  - æ”¯æŒé€šé…ç¬¦æ–¹å¼ï¼š6*.SHï¼ˆæ‰€æœ‰6å¼€å¤´çš„æ²ªå¸‚è‚¡ç¥¨ï¼‰ã€301*.SZï¼ˆæ‰€æœ‰301å¼€å¤´çš„æ·±å¸‚è‚¡ç¥¨ï¼‰ç­‰")
    result.append("  - æƒé™è¦æ±‚ï¼šæœ¬æ¥å£æ˜¯å•ç‹¬å¼€æƒé™çš„æ•°æ®ï¼Œå•ç‹¬ç”³è¯·æƒé™è¯·å‚è€ƒæƒé™åˆ—è¡¨")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯æå–6000æ¡æ•°æ®ï¼Œç­‰åŒäºä¸€æ¬¡æå–å…¨å¸‚åœº")
    result.append("  - æ³¨æ„ï¼šä¸å»ºè®®ä¸€æ¬¡æå–å…¨å¸‚åœºï¼Œå¯åˆ†æ‰¹æå–æ€§èƒ½æ›´å¥½")
    
    return "\n".join(result)


def format_share_float_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–é™å”®è‚¡è§£ç¦æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: é™å”®è‚¡è§£ç¦æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é™å”®è‚¡è§£ç¦æ•°æ®"
    
    result = []
    result.append("ğŸ”“ é™å”®è‚¡è§£ç¦æ•°æ®")
    result.append("=" * 180)
    result.append("")
    
    # æŒ‰è§£ç¦æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    if 'float_date' in df.columns:
        df = df.sort_values('float_date', ascending=False)
    elif 'ann_date' in df.columns:
        df = df.sort_values('ann_date', ascending=False)
    
    # å¦‚æœæœ‰å¤šä¸ªè‚¡ç¥¨ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
    if 'ts_code' in df.columns and len(df['ts_code'].unique()) > 1:
        codes = sorted(df['ts_code'].unique())
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•ï¼Œæ¶‰åŠ {len(codes)} åªè‚¡ç¥¨")
        result.append("")
        
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        for code in codes:
            code_df = df[df['ts_code'] == code]
            if not code_df.empty:
                result.append(f"ğŸ“Š {code} é™å”®è‚¡è§£ç¦æ•°æ®")
                result.append("-" * 180)
                
                # æŒ‰è§£ç¦æ—¥æœŸåˆ†ç»„
                if 'float_date' in code_df.columns and len(code_df['float_date'].unique()) > 1:
                    dates = sorted(code_df['float_date'].unique(), reverse=True)
                    for date in dates[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªè§£ç¦æ—¥æœŸ
                        date_df = code_df[code_df['float_date'] == date]
                        if not date_df.empty:
                            result.append(f"ğŸ“… è§£ç¦æ—¥æœŸ: {format_date(str(date))}")
                            result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è‚¡ä¸œåç§°':<25} {'æµé€šè‚¡ä»½(è‚¡)':<20} {'å æ€»è‚¡æœ¬æ¯”ç‡(%)':<18} {'è‚¡ä»½ç±»å‹':<20}")
                            result.append("-" * 180)
                            
                            for _, row in date_df.iterrows():
                                ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
                                holder_name = str(row.get('holder_name', '-'))[:23]
                                float_share = f"{row.get('float_share', 0):,.0f}" if pd.notna(row.get('float_share')) else "-"
                                float_ratio = f"{row.get('float_ratio', 0):.4f}%" if pd.notna(row.get('float_ratio')) else "-"
                                share_type = str(row.get('share_type', '-'))[:18]
                                
                                result.append(f"{ann_date:<12} {holder_name:<25} {float_share:<20} {float_ratio:<18} {share_type:<20}")
                            
                            result.append("")
                else:
                    # å•ä¸ªè§£ç¦æ—¥æœŸï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
                    result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è§£ç¦æ—¥æœŸ':<12} {'è‚¡ä¸œåç§°':<25} {'æµé€šè‚¡ä»½(è‚¡)':<20} {'å æ€»è‚¡æœ¬æ¯”ç‡(%)':<18} {'è‚¡ä»½ç±»å‹':<20}")
                    result.append("-" * 180)
                    
                    for _, row in code_df.iterrows():
                        ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
                        float_date = format_date(str(row.get('float_date', '-'))) if pd.notna(row.get('float_date')) else "-"
                        holder_name = str(row.get('holder_name', '-'))[:23]
                        float_share = f"{row.get('float_share', 0):,.0f}" if pd.notna(row.get('float_share')) else "-"
                        float_ratio = f"{row.get('float_ratio', 0):.4f}%" if pd.notna(row.get('float_ratio')) else "-"
                        share_type = str(row.get('share_type', '-'))[:18]
                        
                        result.append(f"{ann_date:<12} {float_date:<12} {holder_name:<25} {float_share:<20} {float_ratio:<18} {share_type:<20}")
                    
                    result.append("")
        
        if len(codes) > 20:
            result.append(f"  ... è¿˜æœ‰ {len(codes) - 20} åªè‚¡ç¥¨æœªæ˜¾ç¤º")
    else:
        # å•ä¸ªè‚¡ç¥¨æˆ–æ²¡æœ‰ts_codeå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
        if 'ts_code' in df.columns and not df.empty:
            code = df.iloc[0].get('ts_code', ts_code or '-')
            result.append(f"ğŸ“Š {code} é™å”®è‚¡è§£ç¦æ•°æ®")
        else:
            result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
        result.append("")
        
        # æŒ‰è§£ç¦æ—¥æœŸåˆ†ç»„
        if 'float_date' in df.columns and len(df['float_date'].unique()) > 1:
            dates = sorted(df['float_date'].unique(), reverse=True)
            for date in dates[:20]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘20ä¸ªè§£ç¦æ—¥æœŸ
                date_df = df[df['float_date'] == date]
                if not date_df.empty:
                    result.append(f"ğŸ“… è§£ç¦æ—¥æœŸ: {format_date(str(date))}")
                    result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è‚¡ä¸œåç§°':<25} {'æµé€šè‚¡ä»½(è‚¡)':<20} {'å æ€»è‚¡æœ¬æ¯”ç‡(%)':<18} {'è‚¡ä»½ç±»å‹':<20}")
                    result.append("-" * 180)
                    
                    for _, row in date_df.iterrows():
                        ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
                        holder_name = str(row.get('holder_name', '-'))[:23]
                        float_share = f"{row.get('float_share', 0):,.0f}" if pd.notna(row.get('float_share')) else "-"
                        float_ratio = f"{row.get('float_ratio', 0):.4f}%" if pd.notna(row.get('float_ratio')) else "-"
                        share_type = str(row.get('share_type', '-'))[:18]
                        
                        result.append(f"{ann_date:<12} {holder_name:<25} {float_share:<20} {float_ratio:<18} {share_type:<20}")
                    
                    result.append("")
        else:
            # å•ä¸ªè§£ç¦æ—¥æœŸï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
            result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è§£ç¦æ—¥æœŸ':<12} {'è‚¡ä¸œåç§°':<25} {'æµé€šè‚¡ä»½(è‚¡)':<20} {'å æ€»è‚¡æœ¬æ¯”ç‡(%)':<18} {'è‚¡ä»½ç±»å‹':<20}")
            result.append("-" * 180)
            
            display_count = min(200, len(df))
            for _, row in df.head(display_count).iterrows():
                ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
                float_date = format_date(str(row.get('float_date', '-'))) if pd.notna(row.get('float_date')) else "-"
                holder_name = str(row.get('holder_name', '-'))[:23]
                float_share = f"{row.get('float_share', 0):,.0f}" if pd.notna(row.get('float_share')) else "-"
                float_ratio = f"{row.get('float_ratio', 0):.4f}%" if pd.notna(row.get('float_ratio')) else "-"
                share_type = str(row.get('share_type', '-'))[:18]
                
                result.append(f"{ann_date:<12} {float_date:<12} {holder_name:<25} {float_share:<20} {float_ratio:<18} {share_type:<20}")
            
            if len(df) > display_count:
                result.append("")
                result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        
        if 'ts_code' in df.columns:
            result.append(f"æ¶‰åŠè‚¡ç¥¨æ•°é‡: {len(df['ts_code'].unique())} åª")
        
        if 'float_date' in df.columns:
            result.append(f"æ¶‰åŠè§£ç¦æ—¥æœŸ: {len(df['float_date'].unique())} ä¸ª")
        
        if 'holder_name' in df.columns:
            result.append(f"æ¶‰åŠè‚¡ä¸œæ•°é‡: {len(df['holder_name'].unique())} ä¸ª")
        
        if 'float_share' in df.columns:
            total_float_share = df['float_share'].sum()
            result.append(f"æ€»è§£ç¦è‚¡ä»½: {total_float_share:,.0f} è‚¡")
        
        if 'float_ratio' in df.columns:
            avg_float_ratio = df['float_ratio'].mean()
            result.append(f"å¹³å‡å æ€»è‚¡æœ¬æ¯”ç‡: {avg_float_ratio:.4f}%")
        
        # æŒ‰è‚¡ä»½ç±»å‹ç»Ÿè®¡
        if 'share_type' in df.columns:
            share_types = df['share_type'].value_counts()
            result.append("")
            result.append("è‚¡ä»½ç±»å‹åˆ†å¸ƒï¼š")
            for share_type, count in share_types.items():
                result.append(f"  {share_type}: {count} æ¡")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare share_floatæ¥å£")
    result.append("  - æ˜¾ç¤ºé™å”®è‚¡è§£ç¦æ•°æ®ï¼ŒåŒ…æ‹¬è§£ç¦æ—¥æœŸã€æµé€šè‚¡ä»½ã€è‚¡ä¸œåç§°ã€è‚¡ä»½ç±»å‹ç­‰ä¿¡æ¯")
    result.append("  - æƒé™è¦æ±‚ï¼š2000ç§¯åˆ†")
    
    return "\n".join(result)


def format_repurchase_data(df: pd.DataFrame, date_filter: str = "") -> str:
    """
    æ ¼å¼åŒ–è‚¡ç¥¨å›è´­æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: è‚¡ç¥¨å›è´­æ•°æ®DataFrame
        date_filter: æ—¥æœŸç­›é€‰æ¡ä»¶ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨å›è´­æ•°æ®"
    
    result = []
    result.append("ğŸ’° è‚¡ç¥¨å›è´­æ•°æ®")
    result.append("=" * 180)
    result.append("")
    
    # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    if 'ann_date' in df.columns:
        df = df.sort_values('ann_date', ascending=False)
    
    result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
    if date_filter:
        result.append(f"æŸ¥è¯¢æ¡ä»¶: {date_filter}")
    result.append("")
    
    # å¦‚æœæœ‰å¤šä¸ªè‚¡ç¥¨ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
    if 'ts_code' in df.columns and len(df['ts_code'].unique()) > 1:
        codes = sorted(df['ts_code'].unique())
        result.append(f"æ¶‰åŠ {len(codes)} åªè‚¡ç¥¨")
        result.append("")
        
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        for code in codes[:50]:  # æœ€å¤šæ˜¾ç¤ºå‰50åªè‚¡ç¥¨
            code_df = df[df['ts_code'] == code]
            if not code_df.empty:
                result.append(f"ğŸ“Š {code} è‚¡ç¥¨å›è´­æ•°æ®")
                result.append("-" * 180)
                result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'æˆªæ­¢æ—¥æœŸ':<12} {'è¿›åº¦':<15} {'è¿‡æœŸæ—¥æœŸ':<12} {'å›è´­æ•°é‡(è‚¡)':<18} {'å›è´­é‡‘é¢(å…ƒ)':<18} {'æœ€é«˜ä»·':<10} {'æœ€ä½ä»·':<10}")
                result.append("-" * 180)
                
                # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                if 'ann_date' in code_df.columns:
                    code_df = code_df.sort_values('ann_date', ascending=False)
                
                for _, row in code_df.iterrows():
                    ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
                    end_date = format_date(str(row.get('end_date', '-'))) if pd.notna(row.get('end_date')) else "-"
                    proc = str(row.get('proc', '-'))[:13]
                    exp_date = format_date(str(row.get('exp_date', '-'))) if pd.notna(row.get('exp_date')) else "-"
                    vol = f"{row.get('vol', 0):,.0f}" if pd.notna(row.get('vol')) else "-"
                    amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
                    high_limit = f"{row.get('high_limit', 0):.2f}" if pd.notna(row.get('high_limit')) else "-"
                    low_limit = f"{row.get('low_limit', 0):.2f}" if pd.notna(row.get('low_limit')) else "-"
                    
                    result.append(f"{ann_date:<12} {end_date:<12} {proc:<15} {exp_date:<12} {vol:<18} {amount:<18} {high_limit:<10} {low_limit:<10}")
                
                result.append("")
        
        if len(codes) > 50:
            result.append(f"  ... è¿˜æœ‰ {len(codes) - 50} åªè‚¡ç¥¨æœªæ˜¾ç¤º")
    else:
        # å•ä¸ªè‚¡ç¥¨æˆ–æ²¡æœ‰ts_codeå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
        if 'ts_code' in df.columns and not df.empty:
            code = df.iloc[0].get('ts_code', '-')
            result.append(f"ğŸ“Š {code} è‚¡ç¥¨å›è´­æ•°æ®")
        else:
            result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
        result.append("")
        result.append(f"{'è‚¡ç¥¨ä»£ç ':<12} {'å…¬å‘Šæ—¥æœŸ':<12} {'æˆªæ­¢æ—¥æœŸ':<12} {'è¿›åº¦':<15} {'è¿‡æœŸæ—¥æœŸ':<12} {'å›è´­æ•°é‡(è‚¡)':<18} {'å›è´­é‡‘é¢(å…ƒ)':<18} {'æœ€é«˜ä»·':<10} {'æœ€ä½ä»·':<10}")
        result.append("-" * 180)
        
        display_count = min(200, len(df))
        for _, row in df.head(display_count).iterrows():
            code = str(row.get('ts_code', '-'))[:10]
            ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
            end_date = format_date(str(row.get('end_date', '-'))) if pd.notna(row.get('end_date')) else "-"
            proc = str(row.get('proc', '-'))[:13]
            exp_date = format_date(str(row.get('exp_date', '-'))) if pd.notna(row.get('exp_date')) else "-"
            vol = f"{row.get('vol', 0):,.0f}" if pd.notna(row.get('vol')) else "-"
            amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
            high_limit = f"{row.get('high_limit', 0):.2f}" if pd.notna(row.get('high_limit')) else "-"
            low_limit = f"{row.get('low_limit', 0):.2f}" if pd.notna(row.get('low_limit')) else "-"
            
            result.append(f"{code:<12} {ann_date:<12} {end_date:<12} {proc:<15} {exp_date:<12} {vol:<18} {amount:<18} {high_limit:<10} {low_limit:<10}")
        
        if len(df) > display_count:
            result.append("")
            result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        
        if 'ts_code' in df.columns:
            result.append(f"æ¶‰åŠè‚¡ç¥¨æ•°é‡: {len(df['ts_code'].unique())} åª")
        
        if 'ann_date' in df.columns:
            result.append(f"æ¶‰åŠå…¬å‘Šæ—¥æœŸ: {len(df['ann_date'].unique())} ä¸ª")
        
        # æŒ‰è¿›åº¦ç»Ÿè®¡
        if 'proc' in df.columns:
            proc_counts = df['proc'].value_counts()
            result.append("")
            result.append("å›è´­è¿›åº¦åˆ†å¸ƒï¼š")
            for proc, count in proc_counts.items():
                result.append(f"  {proc}: {count} æ¡")
        
        # è®¡ç®—æ€»å›è´­æ•°é‡å’Œé‡‘é¢
        if 'vol' in df.columns:
            total_vol = df['vol'].sum()
            if total_vol > 0:
                result.append("")
                result.append(f"æ€»å›è´­æ•°é‡: {total_vol:,.0f} è‚¡")
        
        if 'amount' in df.columns:
            total_amount = df['amount'].sum()
            if total_amount > 0:
                result.append(f"æ€»å›è´­é‡‘é¢: {total_amount:,.2f} å…ƒ")
        
        # è®¡ç®—å¹³å‡å›è´­ä»·æ ¼
        if 'vol' in df.columns and 'amount' in df.columns:
            valid_data = df[(df['vol'] > 0) & (df['amount'] > 0)]
            if not valid_data.empty:
                avg_price = (valid_data['amount'].sum() / valid_data['vol'].sum())
                result.append(f"å¹³å‡å›è´­ä»·æ ¼: {avg_price:.2f} å…ƒ/è‚¡")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare repurchaseæ¥å£")
    result.append("  - æ˜¾ç¤ºä¸Šå¸‚å…¬å¸å›è´­è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…æ‹¬å…¬å‘Šæ—¥æœŸã€æˆªæ­¢æ—¥æœŸã€è¿›åº¦ã€è¿‡æœŸæ—¥æœŸã€å›è´­æ•°é‡ã€å›è´­é‡‘é¢ã€å›è´­ä»·æ ¼åŒºé—´ç­‰ä¿¡æ¯")
    result.append("  - æƒé™è¦æ±‚ï¼š600ç§¯åˆ†")
    result.append("  - æ³¨æ„ï¼šå¦‚æœéƒ½ä¸å¡«å‚æ•°ï¼Œå•æ¬¡é»˜è®¤è¿”å›2000æ¡æ•°æ®")
    
    return "\n".join(result)


def format_pledge_detail_data(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–è‚¡æƒè´¨æŠ¼æ˜ç»†æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: è‚¡æƒè´¨æŠ¼æ˜ç»†æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„è‚¡æƒè´¨æŠ¼æ˜ç»†æ•°æ®"
    
    result = []
    result.append(f"ğŸ”’ {ts_code} è‚¡æƒè´¨æŠ¼æ˜ç»†æ•°æ®")
    result.append("=" * 180)
    result.append("")
    
    # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    if 'ann_date' in df.columns:
        df = df.sort_values('ann_date', ascending=False)
    
    result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è´¨æŠ¼è®°å½•")
    result.append("")
    
    # æŒ‰è‚¡ä¸œåç§°åˆ†ç»„æ˜¾ç¤º
    if 'holder_name' in df.columns and len(df['holder_name'].unique()) > 1:
        holders = sorted(df['holder_name'].unique())
        result.append(f"æ¶‰åŠ {len(holders)} ä¸ªè‚¡ä¸œ")
        result.append("")
        
        # æŒ‰è‚¡ä¸œåç§°åˆ†ç»„æ˜¾ç¤º
        for holder in holders[:30]:  # æœ€å¤šæ˜¾ç¤ºå‰30ä¸ªè‚¡ä¸œ
            holder_df = df[df['holder_name'] == holder]
            if not holder_df.empty:
                result.append(f"ğŸ‘¤ {holder}")
                result.append("-" * 180)
                result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è´¨æŠ¼å¼€å§‹æ—¥æœŸ':<12} {'è´¨æŠ¼ç»“æŸæ—¥æœŸ':<12} {'è´¨æŠ¼æ•°é‡(ä¸‡è‚¡)':<18} {'æ˜¯å¦å·²è§£æŠ¼':<12} {'è§£æŠ¼æ—¥æœŸ':<12} {'è´¨æŠ¼æ–¹':<25} {'æŒè‚¡æ€»æ•°(ä¸‡è‚¡)':<18} {'è´¨æŠ¼æ€»æ•°(ä¸‡è‚¡)':<18} {'æœ¬æ¬¡è´¨æŠ¼å æ€»è‚¡æœ¬æ¯”ä¾‹(%)':<20} {'æŒè‚¡æ€»æ•°å æ€»è‚¡æœ¬æ¯”ä¾‹(%)':<20} {'æ˜¯å¦å›è´­':<10}")
                result.append("-" * 180)
                
                # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                if 'ann_date' in holder_df.columns:
                    holder_df = holder_df.sort_values('ann_date', ascending=False)
                
                for _, row in holder_df.iterrows():
                    ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
                    start_date = format_date(str(row.get('start_date', '-'))) if pd.notna(row.get('start_date')) else "-"
                    end_date = format_date(str(row.get('end_date', '-'))) if pd.notna(row.get('end_date')) else "-"
                    pledge_amount = f"{row.get('pledge_amount', 0):,.2f}" if pd.notna(row.get('pledge_amount')) else "-"
                    is_release = str(row.get('is_release', '-'))[:10]
                    release_date = format_date(str(row.get('release_date', '-'))) if pd.notna(row.get('release_date')) else "-"
                    pledgor = str(row.get('pledgor', '-'))[:23]
                    holding_amount = f"{row.get('holding_amount', 0):,.2f}" if pd.notna(row.get('holding_amount')) else "-"
                    pledged_amount = f"{row.get('pledged_amount', 0):,.2f}" if pd.notna(row.get('pledged_amount')) else "-"
                    p_total_ratio = f"{row.get('p_total_ratio', 0):.4f}%" if pd.notna(row.get('p_total_ratio')) else "-"
                    h_total_ratio = f"{row.get('h_total_ratio', 0):.4f}%" if pd.notna(row.get('h_total_ratio')) else "-"
                    is_buyback = "æ˜¯" if pd.notna(row.get('is_buyback')) and str(row.get('is_buyback')) == '1' else "å¦"
                    
                    result.append(f"{ann_date:<12} {start_date:<12} {end_date:<12} {pledge_amount:<18} {is_release:<12} {release_date:<12} {pledgor:<25} {holding_amount:<18} {pledged_amount:<18} {p_total_ratio:<20} {h_total_ratio:<20} {is_buyback:<10}")
                
                result.append("")
        
        if len(holders) > 30:
            result.append(f"  ... è¿˜æœ‰ {len(holders) - 30} ä¸ªè‚¡ä¸œæœªæ˜¾ç¤º")
    else:
        # å•ä¸ªè‚¡ä¸œæˆ–æ²¡æœ‰holder_nameå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
        if 'holder_name' in df.columns and not df.empty:
            holder = df.iloc[0].get('holder_name', '-')
            result.append(f"ğŸ‘¤ {holder} çš„è´¨æŠ¼è®°å½•")
        else:
            result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è´¨æŠ¼è®°å½•")
        result.append("")
        result.append(f"{'å…¬å‘Šæ—¥æœŸ':<12} {'è‚¡ä¸œåç§°':<25} {'è´¨æŠ¼å¼€å§‹æ—¥æœŸ':<12} {'è´¨æŠ¼ç»“æŸæ—¥æœŸ':<12} {'è´¨æŠ¼æ•°é‡(ä¸‡è‚¡)':<18} {'æ˜¯å¦å·²è§£æŠ¼':<12} {'è§£æŠ¼æ—¥æœŸ':<12} {'è´¨æŠ¼æ–¹':<25} {'æŒè‚¡æ€»æ•°(ä¸‡è‚¡)':<18} {'è´¨æŠ¼æ€»æ•°(ä¸‡è‚¡)':<18} {'æœ¬æ¬¡è´¨æŠ¼å æ€»è‚¡æœ¬æ¯”ä¾‹(%)':<20} {'æŒè‚¡æ€»æ•°å æ€»è‚¡æœ¬æ¯”ä¾‹(%)':<20} {'æ˜¯å¦å›è´­':<10}")
        result.append("-" * 180)
        
        display_count = min(200, len(df))
        for _, row in df.head(display_count).iterrows():
            ann_date = format_date(str(row.get('ann_date', '-'))) if pd.notna(row.get('ann_date')) else "-"
            holder_name = str(row.get('holder_name', '-'))[:23]
            start_date = format_date(str(row.get('start_date', '-'))) if pd.notna(row.get('start_date')) else "-"
            end_date = format_date(str(row.get('end_date', '-'))) if pd.notna(row.get('end_date')) else "-"
            pledge_amount = f"{row.get('pledge_amount', 0):,.2f}" if pd.notna(row.get('pledge_amount')) else "-"
            is_release = str(row.get('is_release', '-'))[:10]
            release_date = format_date(str(row.get('release_date', '-'))) if pd.notna(row.get('release_date')) else "-"
            pledgor = str(row.get('pledgor', '-'))[:23]
            holding_amount = f"{row.get('holding_amount', 0):,.2f}" if pd.notna(row.get('holding_amount')) else "-"
            pledged_amount = f"{row.get('pledged_amount', 0):,.2f}" if pd.notna(row.get('pledged_amount')) else "-"
            p_total_ratio = f"{row.get('p_total_ratio', 0):.4f}%" if pd.notna(row.get('p_total_ratio')) else "-"
            h_total_ratio = f"{row.get('h_total_ratio', 0):.4f}%" if pd.notna(row.get('h_total_ratio')) else "-"
            is_buyback = "æ˜¯" if pd.notna(row.get('is_buyback')) and str(row.get('is_buyback')) == '1' else "å¦"
            
            result.append(f"{ann_date:<12} {holder_name:<25} {start_date:<12} {end_date:<12} {pledge_amount:<18} {is_release:<12} {release_date:<12} {pledgor:<25} {holding_amount:<18} {pledged_amount:<18} {p_total_ratio:<20} {h_total_ratio:<20} {is_buyback:<10}")
        
        if len(df) > display_count:
            result.append("")
            result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        
        if 'holder_name' in df.columns:
            result.append(f"æ¶‰åŠè‚¡ä¸œæ•°é‡: {len(df['holder_name'].unique())} ä¸ª")
        
        if 'ann_date' in df.columns:
            result.append(f"æ¶‰åŠå…¬å‘Šæ—¥æœŸ: {len(df['ann_date'].unique())} ä¸ª")
        
        # è®¡ç®—æ€»è´¨æŠ¼æ•°é‡
        if 'pledge_amount' in df.columns:
            total_pledge = df['pledge_amount'].sum()
            result.append(f"æ€»è´¨æŠ¼æ•°é‡: {total_pledge:,.2f} ä¸‡è‚¡")
        
        # è®¡ç®—æ€»æŒè‚¡æ•°é‡
        if 'holding_amount' in df.columns:
            total_holding = df['holding_amount'].sum()
            if total_holding > 0:
                result.append(f"æ€»æŒè‚¡æ•°é‡: {total_holding:,.2f} ä¸‡è‚¡")
        
        # è®¡ç®—æ€»è´¨æŠ¼æ•°é‡ï¼ˆpledged_amountï¼‰
        if 'pledged_amount' in df.columns:
            total_pledged = df['pledged_amount'].sum()
            if total_pledged > 0:
                result.append(f"ç´¯è®¡è´¨æŠ¼æ€»æ•°: {total_pledged:,.2f} ä¸‡è‚¡")
        
        # ç»Ÿè®¡è§£æŠ¼æƒ…å†µ
        if 'is_release' in df.columns:
            released_count = len(df[df['is_release'] == 'æ˜¯' if 'is_release' in df.columns else False])
            not_released_count = len(df) - released_count
            result.append("")
            result.append(f"å·²è§£æŠ¼: {released_count} æ¡ï¼Œæœªè§£æŠ¼: {not_released_count} æ¡")
        
        # ç»Ÿè®¡å›è´­æƒ…å†µ
        if 'is_buyback' in df.columns:
            buyback_count = len(df[df['is_buyback'] == '1' if 'is_buyback' in df.columns else False])
            if buyback_count > 0:
                result.append(f"æ¶‰åŠå›è´­: {buyback_count} æ¡")
        
        # è®¡ç®—å¹³å‡è´¨æŠ¼æ¯”ä¾‹
        if 'p_total_ratio' in df.columns:
            avg_ratio = df['p_total_ratio'].mean()
            result.append(f"å¹³å‡æœ¬æ¬¡è´¨æŠ¼å æ€»è‚¡æœ¬æ¯”ä¾‹: {avg_ratio:.4f}%")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare pledge_detailæ¥å£")
    result.append("  - æ˜¾ç¤ºè‚¡ç¥¨è´¨æŠ¼æ˜ç»†æ•°æ®ï¼ŒåŒ…æ‹¬å…¬å‘Šæ—¥æœŸã€è‚¡ä¸œåç§°ã€è´¨æŠ¼æ•°é‡ã€è´¨æŠ¼å¼€å§‹/ç»“æŸæ—¥æœŸã€æ˜¯å¦å·²è§£æŠ¼ã€è§£æŠ¼æ—¥æœŸã€è´¨æŠ¼æ–¹ã€æŒè‚¡æ€»æ•°ã€è´¨æŠ¼æ€»æ•°ã€è´¨æŠ¼æ¯”ä¾‹ç­‰ä¿¡æ¯")
    result.append("  - æƒé™è¦æ±‚ï¼š500ç§¯åˆ†")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è°ƒå–1000æ¡æ•°æ®")
    
    return "\n".join(result)


def format_block_trade_data(df: pd.DataFrame, ts_code: str = "", date_filter: str = "") -> str:
    """
    æ ¼å¼åŒ–å¤§å®—äº¤æ˜“æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: å¤§å®—äº¤æ˜“æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        date_filter: æ—¥æœŸç­›é€‰æ¡ä»¶ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¤§å®—äº¤æ˜“æ•°æ®"
    
    result = []
    result.append("ğŸ’¼ å¤§å®—äº¤æ˜“æ•°æ®")
    result.append("=" * 180)
    result.append("")
    
    # æŒ‰äº¤æ˜“æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    if 'trade_date' in df.columns:
        df = df.sort_values('trade_date', ascending=False)
    
    # å¦‚æœæœ‰å¤šä¸ªè‚¡ç¥¨ï¼ŒæŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
    if 'ts_code' in df.columns and len(df['ts_code'].unique()) > 1:
        codes = sorted(df['ts_code'].unique())
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•ï¼Œæ¶‰åŠ {len(codes)} åªè‚¡ç¥¨")
        if date_filter:
            result.append(f"æŸ¥è¯¢æ¡ä»¶: {date_filter}")
        result.append("")
        
        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„æ˜¾ç¤º
        for code in codes[:50]:  # æœ€å¤šæ˜¾ç¤ºå‰50åªè‚¡ç¥¨
            code_df = df[df['ts_code'] == code]
            if not code_df.empty:
                result.append(f"ğŸ“Š {code} å¤§å®—äº¤æ˜“æ•°æ®")
                result.append("-" * 180)
                
                # å¦‚æœæœ‰å¤šä¸ªæ—¥æœŸï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„
                if 'trade_date' in code_df.columns and len(code_df['trade_date'].unique()) > 1:
                    dates = sorted(code_df['trade_date'].unique(), reverse=True)
                    for date in dates[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                        date_df = code_df[code_df['trade_date'] == date]
                        if not date_df.empty:
                            result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(str(date))}")
                            result.append(f"{'æˆäº¤ä»·(å…ƒ)':<12} {'æˆäº¤é‡(ä¸‡è‚¡)':<18} {'æˆäº¤é‡‘é¢(ä¸‡å…ƒ)':<18} {'ä¹°æ–¹è¥ä¸šéƒ¨':<40} {'å–æ–¹è¥ä¸šéƒ¨':<40}")
                            result.append("-" * 180)
                            
                            # æŒ‰æˆäº¤é‡‘é¢æ’åºï¼ˆé™åºï¼‰
                            if 'amount' in date_df.columns:
                                date_df = date_df.sort_values('amount', ascending=False, na_position='last')
                            
                            for _, row in date_df.iterrows():
                                price = f"{row.get('price', 0):.2f}" if pd.notna(row.get('price')) else "-"
                                vol = f"{row.get('vol', 0):,.2f}" if pd.notna(row.get('vol')) else "-"
                                amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
                                buyer = str(row.get('buyer', '-'))[:38]
                                seller = str(row.get('seller', '-'))[:38]
                                
                                result.append(f"{price:<12} {vol:<18} {amount:<18} {buyer:<40} {seller:<40}")
                            
                            result.append("")
                else:
                    # å•ä¸ªæ—¥æœŸï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
                    result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'æˆäº¤ä»·(å…ƒ)':<12} {'æˆäº¤é‡(ä¸‡è‚¡)':<18} {'æˆäº¤é‡‘é¢(ä¸‡å…ƒ)':<18} {'ä¹°æ–¹è¥ä¸šéƒ¨':<40} {'å–æ–¹è¥ä¸šéƒ¨':<40}")
                    result.append("-" * 180)
                    
                    # æŒ‰æˆäº¤é‡‘é¢æ’åºï¼ˆé™åºï¼‰
                    if 'amount' in code_df.columns:
                        code_df = code_df.sort_values('amount', ascending=False, na_position='last')
                    
                    for _, row in code_df.iterrows():
                        trade_date = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
                        price = f"{row.get('price', 0):.2f}" if pd.notna(row.get('price')) else "-"
                        vol = f"{row.get('vol', 0):,.2f}" if pd.notna(row.get('vol')) else "-"
                        amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
                        buyer = str(row.get('buyer', '-'))[:38]
                        seller = str(row.get('seller', '-'))[:38]
                        
                        result.append(f"{trade_date:<12} {price:<12} {vol:<18} {amount:<18} {buyer:<40} {seller:<40}")
                    
                    result.append("")
        
        if len(codes) > 50:
            result.append(f"  ... è¿˜æœ‰ {len(codes) - 50} åªè‚¡ç¥¨æœªæ˜¾ç¤º")
    else:
        # å•ä¸ªè‚¡ç¥¨æˆ–æ²¡æœ‰ts_codeå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
        if 'ts_code' in df.columns and not df.empty:
            code = df.iloc[0].get('ts_code', ts_code or '-')
            result.append(f"ğŸ“Š {code} å¤§å®—äº¤æ˜“æ•°æ®")
        else:
            result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡è®°å½•")
        result.append("")
        if date_filter:
            result.append(f"æŸ¥è¯¢æ¡ä»¶: {date_filter}")
        result.append("")
        
        # å¦‚æœæœ‰å¤šä¸ªæ—¥æœŸï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„
        if 'trade_date' in df.columns and len(df['trade_date'].unique()) > 1:
            dates = sorted(df['trade_date'].unique(), reverse=True)
            for date in dates[:20]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘20ä¸ªäº¤æ˜“æ—¥
                date_df = df[df['trade_date'] == date]
                if not date_df.empty:
                    result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(str(date))}")
                    result.append(f"{'æˆäº¤ä»·(å…ƒ)':<12} {'æˆäº¤é‡(ä¸‡è‚¡)':<18} {'æˆäº¤é‡‘é¢(ä¸‡å…ƒ)':<18} {'ä¹°æ–¹è¥ä¸šéƒ¨':<40} {'å–æ–¹è¥ä¸šéƒ¨':<40}")
                    result.append("-" * 180)
                    
                    # æŒ‰æˆäº¤é‡‘é¢æ’åºï¼ˆé™åºï¼‰
                    if 'amount' in date_df.columns:
                        date_df = date_df.sort_values('amount', ascending=False, na_position='last')
                    
                    display_count = min(100, len(date_df))
                    for _, row in date_df.head(display_count).iterrows():
                        price = f"{row.get('price', 0):.2f}" if pd.notna(row.get('price')) else "-"
                        vol = f"{row.get('vol', 0):,.2f}" if pd.notna(row.get('vol')) else "-"
                        amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
                        buyer = str(row.get('buyer', '-'))[:38]
                        seller = str(row.get('seller', '-'))[:38]
                        
                        result.append(f"{price:<12} {vol:<18} {amount:<18} {buyer:<40} {seller:<40}")
                    
                    if len(date_df) > display_count:
                        result.append(f"  ... è¿˜æœ‰ {len(date_df) - display_count} æ¡è®°å½•æœªæ˜¾ç¤º")
                    result.append("")
        else:
            # å•ä¸ªæ—¥æœŸï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
            result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'æˆäº¤ä»·(å…ƒ)':<12} {'æˆäº¤é‡(ä¸‡è‚¡)':<18} {'æˆäº¤é‡‘é¢(ä¸‡å…ƒ)':<18} {'ä¹°æ–¹è¥ä¸šéƒ¨':<40} {'å–æ–¹è¥ä¸šéƒ¨':<40}")
            result.append("-" * 180)
            
            # æŒ‰æˆäº¤é‡‘é¢æ’åºï¼ˆé™åºï¼‰
            if 'amount' in df.columns:
                df = df.sort_values('amount', ascending=False, na_position='last')
            
            display_count = min(200, len(df))
            for _, row in df.head(display_count).iterrows():
                trade_date = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
                price = f"{row.get('price', 0):.2f}" if pd.notna(row.get('price')) else "-"
                vol = f"{row.get('vol', 0):,.2f}" if pd.notna(row.get('vol')) else "-"
                amount = f"{row.get('amount', 0):,.2f}" if pd.notna(row.get('amount')) else "-"
                buyer = str(row.get('buyer', '-'))[:38]
                seller = str(row.get('seller', '-'))[:38]
                
                result.append(f"{trade_date:<12} {price:<12} {vol:<18} {amount:<18} {buyer:<40} {seller:<40}")
            
            if len(df) > display_count:
                result.append("")
                result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼ŒæŒ‰æˆäº¤é‡‘é¢é™åºæ’åˆ—ï¼‰")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 180)
        
        if 'ts_code' in df.columns:
            result.append(f"æ¶‰åŠè‚¡ç¥¨æ•°é‡: {len(df['ts_code'].unique())} åª")
        
        if 'trade_date' in df.columns:
            result.append(f"æ¶‰åŠäº¤æ˜“æ—¥æœŸ: {len(df['trade_date'].unique())} ä¸ª")
        
        # è®¡ç®—æ€»æˆäº¤é‡å’Œæˆäº¤é‡‘é¢
        if 'vol' in df.columns:
            total_vol = df['vol'].sum()
            result.append(f"æ€»æˆäº¤é‡: {total_vol:,.2f} ä¸‡è‚¡")
        
        if 'amount' in df.columns:
            total_amount = df['amount'].sum()
            result.append(f"æ€»æˆäº¤é‡‘é¢: {total_amount:,.2f} ä¸‡å…ƒ")
        
        # è®¡ç®—å¹³å‡æˆäº¤ä»·
        if 'price' in df.columns:
            avg_price = df['price'].mean()
            result.append(f"å¹³å‡æˆäº¤ä»·: {avg_price:.2f} å…ƒ")
        
        # ç»Ÿè®¡ä¹°æ–¹è¥ä¸šéƒ¨
        if 'buyer' in df.columns:
            buyer_count = len(df['buyer'].unique())
            result.append(f"æ¶‰åŠä¹°æ–¹è¥ä¸šéƒ¨: {buyer_count} ä¸ª")
        
        # ç»Ÿè®¡å–æ–¹è¥ä¸šéƒ¨
        if 'seller' in df.columns:
            seller_count = len(df['seller'].unique())
            result.append(f"æ¶‰åŠå–æ–¹è¥ä¸šéƒ¨: {seller_count} ä¸ª")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare block_tradeæ¥å£")
    result.append("  - æ˜¾ç¤ºå¤§å®—äº¤æ˜“æ•°æ®ï¼ŒåŒ…æ‹¬äº¤æ˜“æ—¥æœŸã€æˆäº¤ä»·ã€æˆäº¤é‡ã€æˆäº¤é‡‘é¢ã€ä¹°æ–¹è¥ä¸šéƒ¨ã€å–æ–¹è¥ä¸šéƒ¨ç­‰ä¿¡æ¯")
    result.append("  - æƒé™è¦æ±‚ï¼šè¯·æŸ¥çœ‹Tushareæ–‡æ¡£ç¡®è®¤å…·ä½“æƒé™è¦æ±‚")
    
    return "\n".join(result)


def format_limit_list_data(df: pd.DataFrame, trade_date: str = "", ts_code: str = "", limit_type: str = "") -> str:
    """
    æ ¼å¼åŒ–æ¶¨è·Œåœåˆ—è¡¨æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ¶¨è·Œåœæ•°æ®DataFrame
        trade_date: äº¤æ˜“æ—¥æœŸï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        limit_type: æ¶¨è·Œåœç±»å‹ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¶¨è·Œåœæ•°æ®"
    
    result = []
    result.append("ğŸ“ˆ æ¶¨è·Œåœåˆ—è¡¨æ•°æ®")
    result.append("=" * 200)
    result.append("")
    
    # æ˜¾ç¤ºæŸ¥è¯¢æ¡ä»¶
    if trade_date:
        result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(trade_date)}")
    if ts_code:
        result.append(f"ğŸ“Š è‚¡ç¥¨ä»£ç : {ts_code}")
    if limit_type:
        limit_type_map = {'U': 'æ¶¨åœ', 'D': 'è·Œåœ', 'Z': 'ç‚¸æ¿'}
        result.append(f"ğŸ”– ç±»å‹: {limit_type_map.get(limit_type.upper(), limit_type)}")
    result.append("")
    
    # ç»Ÿè®¡ä¿¡æ¯
    if 'limit' in df.columns:
        limit_stats = df['limit'].value_counts()
        result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        result.append("-" * 200)
        limit_type_map = {'U': 'æ¶¨åœ', 'D': 'è·Œåœ', 'Z': 'ç‚¸æ¿'}
        for limit_val, count in limit_stats.items():
            type_name = limit_type_map.get(str(limit_val), str(limit_val))
            result.append(f"  - {type_name}: {count} åª")
        result.append("")
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªè‚¡ç¥¨
    if ts_code and 'ts_code' in df.columns:
        stock_df = df[df['ts_code'] == ts_code]
        if not stock_df.empty:
            result.append(f"å…±æ‰¾åˆ° {len(stock_df)} æ¡è®°å½•")
            result.append("")
            result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'è‚¡ç¥¨ä»£ç ':<15} {'è‚¡ç¥¨åç§°':<15} {'è¡Œä¸š':<15} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é¢(å…ƒ)':<18} {'å°å•é‡‘é¢(å…ƒ)':<18} {'é¦–æ¬¡å°æ¿':<12} {'æœ€åå°æ¿':<12} {'ç‚¸æ¿æ¬¡æ•°':<10} {'è¿æ¿æ•°':<8} {'æ¶¨åœç»Ÿè®¡':<15}")
            result.append("-" * 200)
            
            for _, row in stock_df.iterrows():
                trade_date_str = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
                code = str(row.get('ts_code', '-'))[:13]
                name = str(row.get('name', '-'))[:13]
                industry = str(row.get('industry', '-'))[:13]
                close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
                pct_chg = f"{row.get('pct_chg', 0):+.2f}%" if pd.notna(row.get('pct_chg')) else "-"
                amount = format_large_number(row.get('amount', 0)) if pd.notna(row.get('amount')) else "-"
                fd_amount = format_large_number(row.get('fd_amount', 0)) if pd.notna(row.get('fd_amount')) else "-"
                first_time = str(row.get('first_time', '-'))[:10] if pd.notna(row.get('first_time')) else "-"
                last_time = str(row.get('last_time', '-'))[:10] if pd.notna(row.get('last_time')) else "-"
                open_times = str(int(row.get('open_times', 0))) if pd.notna(row.get('open_times')) else "-"
                limit_times = str(int(row.get('limit_times', 0))) if pd.notna(row.get('limit_times')) else "-"
                up_stat = str(row.get('up_stat', '-'))[:13] if pd.notna(row.get('up_stat')) else "-"
                
                result.append(f"{trade_date_str:<12} {code:<15} {name:<15} {industry:<15} {close:<10} {pct_chg:<10} {amount:<18} {fd_amount:<18} {first_time:<12} {last_time:<12} {open_times:<10} {limit_times:<8} {up_stat:<15}")
            
            return "\n".join(result)
    
    # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
    if 'limit' in df.columns:
        # æŒ‰è¿æ¿æ•°æ’åºï¼ˆé™åºï¼‰ï¼Œç„¶åæŒ‰å°å•é‡‘é¢æ’åºï¼ˆé™åºï¼‰
        if 'limit_times' in df.columns:
            df = df.sort_values(['limit_times', 'fd_amount'], ascending=[False, False], na_position='last')
        elif 'fd_amount' in df.columns:
            df = df.sort_values('fd_amount', ascending=False, na_position='last')
        
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æ¶¨è·Œåœè®°å½•ï¼Œæ¶‰åŠ {len(df['ts_code'].unique()) if 'ts_code' in df.columns else len(df)} åªè‚¡ç¥¨")
        result.append("")
        result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'è‚¡ç¥¨ä»£ç ':<15} {'è‚¡ç¥¨åç§°':<15} {'è¡Œä¸š':<15} {'ç±»å‹':<8} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é¢(å…ƒ)':<18} {'å°å•é‡‘é¢(å…ƒ)':<18} {'é¦–æ¬¡å°æ¿':<12} {'æœ€åå°æ¿':<12} {'ç‚¸æ¿æ¬¡æ•°':<10} {'è¿æ¿æ•°':<8} {'æ¶¨åœç»Ÿè®¡':<15}")
        result.append("-" * 200)
        
        display_count = min(100, len(df))
        for _, row in df.head(display_count).iterrows():
            trade_date_str = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
            code = str(row.get('ts_code', '-'))[:13]
            name = str(row.get('name', '-'))[:13]
            industry = str(row.get('industry', '-'))[:13]
            limit_val = str(row.get('limit', '-'))
            limit_type_map = {'U': 'æ¶¨åœ', 'D': 'è·Œåœ', 'Z': 'ç‚¸æ¿'}
            limit_type_name = limit_type_map.get(limit_val, limit_val)
            close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
            pct_chg = f"{row.get('pct_chg', 0):+.2f}%" if pd.notna(row.get('pct_chg')) else "-"
            amount = format_large_number(row.get('amount', 0)) if pd.notna(row.get('amount')) else "-"
            fd_amount = format_large_number(row.get('fd_amount', 0)) if pd.notna(row.get('fd_amount')) else "-"
            first_time = str(row.get('first_time', '-'))[:10] if pd.notna(row.get('first_time')) else "-"
            last_time = str(row.get('last_time', '-'))[:10] if pd.notna(row.get('last_time')) else "-"
            open_times = str(int(row.get('open_times', 0))) if pd.notna(row.get('open_times')) else "-"
            limit_times = str(int(row.get('limit_times', 0))) if pd.notna(row.get('limit_times')) else "-"
            up_stat = str(row.get('up_stat', '-'))[:13] if pd.notna(row.get('up_stat')) else "-"
            
            result.append(f"{trade_date_str:<12} {code:<15} {name:<15} {industry:<15} {limit_type_name:<8} {close:<10} {pct_chg:<10} {amount:<18} {fd_amount:<18} {first_time:<12} {last_time:<12} {open_times:<10} {limit_times:<8} {up_stat:<15}")
        
        if len(df) > display_count:
            result.append("")
            result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    else:
        # å¦‚æœæ²¡æœ‰limitå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰è®°å½•
        result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æ¶¨è·Œåœè®°å½•")
        result.append("")
        result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'è‚¡ç¥¨ä»£ç ':<15} {'è‚¡ç¥¨åç§°':<15} {'è¡Œä¸š':<15} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é¢(å…ƒ)':<18} {'å°å•é‡‘é¢(å…ƒ)':<18} {'é¦–æ¬¡å°æ¿':<12} {'æœ€åå°æ¿':<12} {'ç‚¸æ¿æ¬¡æ•°':<10} {'è¿æ¿æ•°':<8} {'æ¶¨åœç»Ÿè®¡':<15}")
        result.append("-" * 200)
        
        display_count = min(100, len(df))
        for _, row in df.head(display_count).iterrows():
            trade_date_str = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
            code = str(row.get('ts_code', '-'))[:13]
            name = str(row.get('name', '-'))[:13]
            industry = str(row.get('industry', '-'))[:13]
            close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
            pct_chg = f"{row.get('pct_chg', 0):+.2f}%" if pd.notna(row.get('pct_chg')) else "-"
            amount = format_large_number(row.get('amount', 0)) if pd.notna(row.get('amount')) else "-"
            fd_amount = format_large_number(row.get('fd_amount', 0)) if pd.notna(row.get('fd_amount')) else "-"
            first_time = str(row.get('first_time', '-'))[:10] if pd.notna(row.get('first_time')) else "-"
            last_time = str(row.get('last_time', '-'))[:10] if pd.notna(row.get('last_time')) else "-"
            open_times = str(int(row.get('open_times', 0))) if pd.notna(row.get('open_times')) else "-"
            limit_times = str(int(row.get('limit_times', 0))) if pd.notna(row.get('limit_times')) else "-"
            up_stat = str(row.get('up_stat', '-'))[:13] if pd.notna(row.get('up_stat')) else "-"
            
            result.append(f"{trade_date_str:<12} {code:<15} {name:<15} {industry:<15} {close:<10} {pct_chg:<10} {amount:<18} {fd_amount:<18} {first_time:<12} {last_time:<12} {open_times:<10} {limit_times:<8} {up_stat:<15}")
        
        if len(df) > display_count:
            result.append("")
            result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ï¼š")
        result.append("-" * 200)
        
        if 'ts_code' in df.columns:
            result.append(f"æ¶‰åŠè‚¡ç¥¨æ•°é‡: {len(df['ts_code'].unique())} åª")
        
        if 'trade_date' in df.columns:
            result.append(f"æ¶‰åŠäº¤æ˜“æ—¥æœŸ: {len(df['trade_date'].unique())} ä¸ª")
        
        # è®¡ç®—æ€»æˆäº¤é¢
        if 'amount' in df.columns:
            total_amount = df['amount'].sum()
            result.append(f"æ€»æˆäº¤é¢: {format_large_number(total_amount)} å…ƒ")
        
        # è®¡ç®—æ€»å°å•é‡‘é¢
        if 'fd_amount' in df.columns:
            total_fd_amount = df['fd_amount'].sum()
            result.append(f"æ€»å°å•é‡‘é¢: {format_large_number(total_fd_amount)} å…ƒ")
        
        # ç»Ÿè®¡è¿æ¿æƒ…å†µ
        if 'limit_times' in df.columns:
            max_limit_times = df['limit_times'].max()
            if pd.notna(max_limit_times):
                result.append(f"æœ€é«˜è¿æ¿æ•°: {int(max_limit_times)} æ¿")
        
        # ç»Ÿè®¡ç‚¸æ¿æƒ…å†µ
        if 'open_times' in df.columns:
            total_open_times = df['open_times'].sum()
            result.append(f"æ€»ç‚¸æ¿æ¬¡æ•°: {int(total_open_times)} æ¬¡")
            avg_open_times = df['open_times'].mean()
            if pd.notna(avg_open_times):
                result.append(f"å¹³å‡ç‚¸æ¿æ¬¡æ•°: {avg_open_times:.2f} æ¬¡")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare limit_list_dæ¥å£")
    result.append("  - æ•°æ®å†å²ï¼š2020å¹´è‡³ä»Šï¼ˆä¸æä¾›STè‚¡ç¥¨çš„ç»Ÿè®¡ï¼‰")
    result.append("  - ç±»å‹è¯´æ˜ï¼šU=æ¶¨åœï¼ŒD=è·Œåœï¼ŒZ=ç‚¸æ¿")
    result.append("  - å°å•é‡‘é¢ï¼šä»¥æ¶¨åœä»·ä¹°å…¥æŒ‚å•çš„èµ„é‡‘æ€»é‡ï¼ˆè·Œåœæ— æ­¤æ•°æ®ï¼‰")
    result.append("  - é¦–æ¬¡å°æ¿æ—¶é—´ï¼šè‚¡ç¥¨é¦–æ¬¡è¾¾åˆ°æ¶¨åœä»·çš„æ—¶é—´ï¼ˆè·Œåœæ— æ­¤æ•°æ®ï¼‰")
    result.append("  - ç‚¸æ¿æ¬¡æ•°ï¼šæ¶¨åœåå¼€æ¿çš„æ¬¡æ•°ï¼ˆè·Œåœä¸ºå¼€æ¿æ¬¡æ•°ï¼‰")
    result.append("  - è¿æ¿æ•°ï¼šä¸ªè‚¡è¿ç»­å°æ¿æ•°é‡")
    result.append("  - æ¶¨åœç»Ÿè®¡ï¼šæ ¼å¼ä¸ºN/Tï¼Œè¡¨ç¤ºTå¤©å†…æœ‰Næ¬¡æ¶¨åœ")
    result.append("  - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†ï¼ˆæ¯åˆ†é’Ÿ200æ¬¡ï¼Œæ¯å¤©æ€»é‡1ä¸‡æ¬¡ï¼‰ï¼Œ8000ç§¯åˆ†ä»¥ä¸Šï¼ˆæ¯åˆ†é’Ÿ500æ¬¡ï¼Œæ¯å¤©æ€»é‡ä¸é™åˆ¶ï¼‰")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è·å–2500æ¡æ•°æ®ï¼Œå¯é€šè¿‡æ—¥æœŸæˆ–è‚¡ç¥¨å¾ªç¯æå–")
    
    return "\n".join(result)


def format_limit_cpt_list_data(df: pd.DataFrame, trade_date: str = "", ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–æœ€å¼ºæ¿å—ç»Ÿè®¡æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æœ€å¼ºæ¿å—ç»Ÿè®¡æ•°æ®DataFrame
        trade_date: äº¤æ˜“æ—¥æœŸï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        ts_code: æ¿å—ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æœ€å¼ºæ¿å—ç»Ÿè®¡æ•°æ®"
    
    result = []
    result.append("ğŸ† æœ€å¼ºæ¿å—ç»Ÿè®¡")
    result.append("=" * 200)
    result.append("")
    
    # æ˜¾ç¤ºæŸ¥è¯¢æ¡ä»¶
    if trade_date:
        result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(trade_date)}")
    if ts_code:
        result.append(f"ğŸ“Š æ¿å—ä»£ç : {ts_code}")
    result.append("")
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªæ¿å—
    if ts_code and 'ts_code' in df.columns:
        cpt_df = df[df['ts_code'] == ts_code]
        if not cpt_df.empty:
            result.append(f"å…±æ‰¾åˆ° {len(cpt_df)} æ¡è®°å½•")
            result.append("")
            result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'æ¿å—ä»£ç ':<20} {'æ¿å—åç§°':<20} {'ä¸Šæ¦œå¤©æ•°':<10} {'è¿æ¿é«˜åº¦':<15} {'è¿æ¿å®¶æ•°':<10} {'æ¶¨åœå®¶æ•°':<10} {'æ¶¨è·Œå¹…(%)':<12} {'æ¿å—çƒ­ç‚¹æ’å':<15}")
            result.append("-" * 200)
            
            for _, row in cpt_df.iterrows():
                trade_date_str = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
                code = str(row.get('ts_code', '-'))[:18]
                name = str(row.get('name', '-'))[:18]
                days = str(int(row.get('days', 0))) if pd.notna(row.get('days')) else "-"
                up_stat = str(row.get('up_stat', '-'))[:13] if pd.notna(row.get('up_stat')) else "-"
                cons_nums = str(int(row.get('cons_nums', 0))) if pd.notna(row.get('cons_nums')) else "-"
                up_nums = str(row.get('up_nums', '-'))[:8] if pd.notna(row.get('up_nums')) else "-"
                pct_chg = f"{row.get('pct_chg', 0):+.2f}%" if pd.notna(row.get('pct_chg')) else "-"
                rank = str(row.get('rank', '-'))[:13] if pd.notna(row.get('rank')) else "-"
                
                result.append(f"{trade_date_str:<12} {code:<20} {name:<20} {days:<10} {up_stat:<15} {cons_nums:<10} {up_nums:<10} {pct_chg:<12} {rank:<15}")
            
            return "\n".join(result)
    
    # æŒ‰æ¿å—çƒ­ç‚¹æ’åæ’åºæ˜¾ç¤º
    result.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æœ€å¼ºæ¿å—è®°å½•ï¼Œæ¶‰åŠ {len(df['ts_code'].unique()) if 'ts_code' in df.columns else len(df)} ä¸ªæ¿å—")
    result.append("")
    result.append(f"{'æ’å':<8} {'æ¿å—ä»£ç ':<20} {'æ¿å—åç§°':<20} {'äº¤æ˜“æ—¥æœŸ':<12} {'ä¸Šæ¦œå¤©æ•°':<10} {'è¿æ¿é«˜åº¦':<15} {'è¿æ¿å®¶æ•°':<10} {'æ¶¨åœå®¶æ•°':<10} {'æ¶¨è·Œå¹…(%)':<12}")
    result.append("-" * 200)
    
    display_count = min(100, len(df))
    for idx, (_, row) in enumerate(df.head(display_count).iterrows(), 1):
        rank = str(row.get('rank', idx))[:6] if pd.notna(row.get('rank')) else str(idx)
        code = str(row.get('ts_code', '-'))[:18]
        name = str(row.get('name', '-'))[:18]
        trade_date_str = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
        days = str(int(row.get('days', 0))) if pd.notna(row.get('days')) else "-"
        up_stat = str(row.get('up_stat', '-'))[:13] if pd.notna(row.get('up_stat')) else "-"
        cons_nums = str(int(row.get('cons_nums', 0))) if pd.notna(row.get('cons_nums')) else "-"
        up_nums = str(row.get('up_nums', '-'))[:8] if pd.notna(row.get('up_nums')) else "-"
        pct_chg = f"{row.get('pct_chg', 0):+.2f}%" if pd.notna(row.get('pct_chg')) else "-"
        
        result.append(f"{rank:<8} {code:<20} {name:<20} {trade_date_str:<12} {days:<10} {up_stat:<15} {cons_nums:<10} {up_nums:<10} {pct_chg:<12}")
    
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºå‰ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    if not df.empty:
        result.append("")
        result.append("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ï¼š")
        result.append("-" * 200)
        
        if 'ts_code' in df.columns:
            result.append(f"æ¶‰åŠæ¿å—æ•°é‡: {len(df['ts_code'].unique())} ä¸ª")
        
        if 'trade_date' in df.columns:
            result.append(f"æ¶‰åŠäº¤æ˜“æ—¥æœŸ: {len(df['trade_date'].unique())} ä¸ª")
        
        # ç»Ÿè®¡æ¶¨åœå®¶æ•°
        if 'up_nums' in df.columns:
            # up_numså¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢
            try:
                up_nums_list = []
                for val in df['up_nums']:
                    if pd.notna(val):
                        # å°è¯•æå–æ•°å­—
                        import re
                        nums = re.findall(r'\d+', str(val))
                        if nums:
                            up_nums_list.append(int(nums[0]))
                if up_nums_list:
                    total_up_nums = sum(up_nums_list)
                    result.append(f"æ€»æ¶¨åœå®¶æ•°: {total_up_nums} å®¶")
                    avg_up_nums = total_up_nums / len(up_nums_list)
                    result.append(f"å¹³å‡æ¶¨åœå®¶æ•°: {avg_up_nums:.2f} å®¶")
            except:
                pass
        
        # ç»Ÿè®¡è¿æ¿å®¶æ•°
        if 'cons_nums' in df.columns:
            total_cons_nums = df['cons_nums'].sum()
            result.append(f"æ€»è¿æ¿å®¶æ•°: {int(total_cons_nums)} å®¶")
            avg_cons_nums = df['cons_nums'].mean()
            if pd.notna(avg_cons_nums):
                result.append(f"å¹³å‡è¿æ¿å®¶æ•°: {avg_cons_nums:.2f} å®¶")
        
        # ç»Ÿè®¡æ¶¨è·Œå¹…
        if 'pct_chg' in df.columns:
            avg_pct_chg = df['pct_chg'].mean()
            if pd.notna(avg_pct_chg):
                result.append(f"å¹³å‡æ¶¨è·Œå¹…: {avg_pct_chg:+.2f}%")
            max_pct_chg = df['pct_chg'].max()
            if pd.notna(max_pct_chg):
                result.append(f"æœ€é«˜æ¶¨è·Œå¹…: {max_pct_chg:+.2f}%")
        
        # ç»Ÿè®¡ä¸Šæ¦œå¤©æ•°
        if 'days' in df.columns:
            max_days = df['days'].max()
            if pd.notna(max_days):
                result.append(f"æœ€é•¿ä¸Šæ¦œå¤©æ•°: {int(max_days)} å¤©")
            avg_days = df['days'].mean()
            if pd.notna(avg_days):
                result.append(f"å¹³å‡ä¸Šæ¦œå¤©æ•°: {avg_days:.2f} å¤©")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare limit_cpt_listæ¥å£")
    result.append("  - åŠŸèƒ½ï¼šè·å–æ¯å¤©æ¶¨åœè‚¡ç¥¨æœ€å¤šæœ€å¼ºçš„æ¦‚å¿µæ¿å—ï¼Œå¯ä»¥åˆ†æå¼ºåŠ¿æ¿å—çš„è½®åŠ¨ï¼Œåˆ¤æ–­èµ„é‡‘åŠ¨å‘")
    result.append("  - ä¸Šæ¦œå¤©æ•°ï¼šè¯¥æ¿å—è¿ç»­ä¸Šæ¦œçš„å¤©æ•°")
    result.append("  - è¿æ¿é«˜åº¦ï¼šæ¿å—å†…è‚¡ç¥¨çš„è¿æ¿æƒ…å†µï¼ˆå¦‚ï¼š9å¤©7æ¿è¡¨ç¤º9ä¸ªäº¤æ˜“æ—¥å†…æœ‰7ä¸ªæ¶¨åœæ¿ï¼‰")
    result.append("  - è¿æ¿å®¶æ•°ï¼šæ¿å—å†…è¿ç»­æ¶¨åœçš„è‚¡ç¥¨æ•°é‡")
    result.append("  - æ¶¨åœå®¶æ•°ï¼šæ¿å—å†…å½“æ—¥æ¶¨åœçš„è‚¡ç¥¨æ•°é‡")
    result.append("  - æ¿å—çƒ­ç‚¹æ’åï¼šæ ¹æ®æ¶¨åœå®¶æ•°ã€è¿æ¿é«˜åº¦ç­‰æŒ‡æ ‡ç»¼åˆæ’åï¼Œæ’åè¶Šå°è¶Šå¼º")
    result.append("  - æƒé™è¦æ±‚ï¼š8000ç§¯åˆ†ä»¥ä¸Šæ¯åˆ†é’Ÿ500æ¬¡ï¼Œæ¯å¤©æ€»é‡ä¸é™åˆ¶")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§2000è¡Œæ•°æ®ï¼Œå¯æ ¹æ®è‚¡ç¥¨ä»£ç æˆ–æ—¥æœŸå¾ªç¯æå–å…¨éƒ¨")
    
    return "\n".join(result)


def format_stock_auction_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–é›†åˆç«ä»·æ•°æ®
    
    å‚æ•°:
        df: é›†åˆç«ä»·æ•°æ®DataFrame
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆå¯é€‰ï¼Œç”¨äºå•è‚¡ç¥¨æŸ¥è¯¢æ—¶çš„æ ‡é¢˜ï¼‰
    """
    if df.empty:
        return "æœªæ‰¾åˆ°é›†åˆç«ä»·æ•°æ®"
    
    result = []
    
    # æ ‡é¢˜
    if ts_code:
        result.append(f"ğŸ“Š è‚¡ç¥¨ {ts_code} é›†åˆç«ä»·æˆäº¤æƒ…å†µ")
    else:
        result.append("ğŸ“Š é›†åˆç«ä»·æˆäº¤æƒ…å†µ")
    result.append("=" * 80)
    result.append("")
    
    # æ•°æ®ç»Ÿè®¡
    result.append("ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    result.append(f"  - è®°å½•æ•°é‡: {len(df)} æ¡")
    
    # æ—¥æœŸèŒƒå›´
    if 'trade_date' in df.columns:
        dates = df['trade_date'].unique()
        if len(dates) == 1:
            result.append(f"  - äº¤æ˜“æ—¥æœŸ: {dates[0]}")
        else:
            result.append(f"  - æ—¥æœŸèŒƒå›´: {min(dates)} è‡³ {max(dates)}")
    
    result.append("")
    
    # æ•°æ®è¡¨æ ¼
    result.append("ğŸ“‹ è¯¦ç»†æ•°æ®:")
    result.append("")
    
    # æ„å»ºè¡¨å¤´
    headers = []
    if 'ts_code' in df.columns:
        headers.append(('è‚¡ç¥¨ä»£ç ', 12))
    if 'trade_date' in df.columns:
        headers.append(('äº¤æ˜“æ—¥æœŸ', 12))
    if 'vol' in df.columns:
        headers.append(('æˆäº¤é‡(è‚¡)', 15))
    if 'price' in df.columns:
        headers.append(('æˆäº¤å‡ä»·(å…ƒ)', 15))
    if 'amount' in df.columns:
        headers.append(('æˆäº¤é‡‘é¢(å…ƒ)', 18))
    if 'pre_close' in df.columns:
        headers.append(('æ˜¨æ”¶ä»·(å…ƒ)', 15))
    if 'turnover_rate' in df.columns:
        headers.append(('æ¢æ‰‹ç‡(%)', 12))
    if 'volume_ratio' in df.columns:
        headers.append(('é‡æ¯”', 10))
    if 'float_share' in df.columns:
        headers.append(('æµé€šè‚¡æœ¬(ä¸‡è‚¡)', 15))
    
    # æ‰“å°è¡¨å¤´
    if headers:
        header_line = " | ".join([f"{h[0]:<{h[1]}}" for h in headers])
        result.append(header_line)
        result.append("-" * len(header_line))
    
    # æ‰“å°æ•°æ®è¡Œ
    for idx, row in df.iterrows():
        row_data = []
        for header, width in headers:
            field = header.split('(')[0].replace(' ', '_').lower()
            # å­—æ®µåæ˜ å°„
            field_map = {
                'è‚¡ç¥¨ä»£ç ': 'ts_code',
                'äº¤æ˜“æ—¥æœŸ': 'trade_date',
                'æˆäº¤é‡(è‚¡)': 'vol',
                'æˆäº¤å‡ä»·(å…ƒ)': 'price',
                'æˆäº¤é‡‘é¢(å…ƒ)': 'amount',
                'æ˜¨æ”¶ä»·(å…ƒ)': 'pre_close',
                'æ¢æ‰‹ç‡(%)': 'turnover_rate',
                'é‡æ¯”': 'volume_ratio',
                'æµé€šè‚¡æœ¬(ä¸‡è‚¡)': 'float_share'
            }
            field_name = field_map.get(header, field)
            
            if field_name in row.index:
                value = row[field_name]
                if pd.isna(value):
                    row_data.append(f"{'-':<{width}}")
                elif field_name in ['vol', 'amount', 'float_share']:
                    if field_name == 'vol':
                        # æˆäº¤é‡ï¼Œæ•´æ•°æ˜¾ç¤º
                        row_data.append(f"{int(value):<{width},}")
                    elif field_name == 'amount':
                        # æˆäº¤é‡‘é¢ï¼Œä¿ç•™2ä½å°æ•°
                        row_data.append(f"{float(value):<{width},.2f}")
                    else:
                        # æµé€šè‚¡æœ¬ï¼Œä¿ç•™2ä½å°æ•°
                        row_data.append(f"{float(value):<{width},.2f}")
                elif field_name in ['price', 'pre_close']:
                    # ä»·æ ¼ï¼Œä¿ç•™2ä½å°æ•°
                    row_data.append(f"{float(value):<{width},.2f}")
                elif field_name in ['turnover_rate', 'volume_ratio']:
                    # ç™¾åˆ†æ¯”å’Œæ¯”ç‡ï¼Œä¿ç•™4ä½å°æ•°
                    row_data.append(f"{float(value):<{width},.4f}")
                else:
                    row_data.append(f"{str(value):<{width}}")
            else:
                row_data.append(f"{'-':<{width}}")
        
        result.append(" | ".join(row_data))
    
    result.append("")
    
    # ç»Ÿè®¡ä¿¡æ¯
    result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    if 'vol' in df.columns:
        total_vol = df['vol'].sum()
        result.append(f"  - æ€»æˆäº¤é‡: {total_vol:,} è‚¡")
    if 'amount' in df.columns:
        total_amount = df['amount'].sum()
        result.append(f"  - æ€»æˆäº¤é‡‘é¢: {total_amount:,.2f} å…ƒ")
    if 'price' in df.columns:
        avg_price = df['price'].mean()
        if pd.notna(avg_price):
            result.append(f"  - å¹³å‡æˆäº¤ä»·: {avg_price:.2f} å…ƒ")
    if 'turnover_rate' in df.columns:
        avg_turnover = df['turnover_rate'].mean()
        if pd.notna(avg_turnover):
            result.append(f"  - å¹³å‡æ¢æ‰‹ç‡: {avg_turnover:.4f}%")
    if 'volume_ratio' in df.columns:
        avg_vol_ratio = df['volume_ratio'].mean()
        if pd.notna(avg_vol_ratio):
            result.append(f"  - å¹³å‡é‡æ¯”: {avg_vol_ratio:.4f}")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šTushare stk_auctionæ¥å£")
    result.append("  - åŠŸèƒ½ï¼šè·å–å½“æ—¥ä¸ªè‚¡å’ŒETFçš„é›†åˆç«ä»·æˆäº¤æƒ…å†µ")
    result.append("  - æŸ¥è¯¢æ—¶é—´ï¼šæ¯å¤©9ç‚¹25~29åˆ†ä¹‹é—´å¯ä»¥è·å–å½“æ—¥çš„é›†åˆç«ä»·æˆäº¤æ•°æ®")
    result.append("  - æƒé™è¦æ±‚ï¼šæœ¬æ¥å£æ˜¯å•ç‹¬å¼€æƒé™çš„æ•°æ®ï¼Œå·²ç»å¼€é€šäº†è‚¡ç¥¨åˆ†é’Ÿæƒé™çš„ç”¨æˆ·å¯è‡ªåŠ¨è·å¾—æœ¬æ¥å£æƒé™")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§è¿”å›8000è¡Œæ•°æ®ï¼Œå¯æ ¹æ®æ—¥æœŸæˆ–ä»£ç å¾ªç¯è·å–å†å²")
    result.append("  - æˆäº¤é‡ï¼šé›†åˆç«ä»·æœŸé—´çš„æˆäº¤é‡ï¼ˆè‚¡ï¼‰")
    result.append("  - æˆäº¤å‡ä»·ï¼šé›†åˆç«ä»·æœŸé—´çš„æˆäº¤å‡ä»·ï¼ˆå…ƒï¼‰")
    result.append("  - æˆäº¤é‡‘é¢ï¼šé›†åˆç«ä»·æœŸé—´çš„æˆäº¤é‡‘é¢ï¼ˆå…ƒï¼‰")
    result.append("  - æ¢æ‰‹ç‡ï¼šé›†åˆç«ä»·æœŸé—´çš„æ¢æ‰‹ç‡ï¼ˆ%ï¼‰")
    result.append("  - é‡æ¯”ï¼šé›†åˆç«ä»·æœŸé—´çš„é‡æ¯”")
    
    return "\n".join(result)