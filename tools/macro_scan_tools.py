"""å®è§‚å…¨æ™¯æ‰«æ MCP å·¥å…·

è¯¥æ¨¡å—æä¾›å®è§‚å¸‚åœºåˆ†æå·¥å…·ï¼Œç»¼åˆåˆ†æå¸‚åœºé‡èƒ½ã€é£æ ¼ã€æƒ…ç»ªå’Œå¤–éƒ¨ç¯å¢ƒã€‚

æ³¨æ„ï¼šæœ¬å·¥å…·ä»…é€‚ç”¨äº 15:30 æ”¶ç›˜åæ‰§è¡Œï¼Œç›˜ä¸­æ‰§è¡Œå¯èƒ½å› æ•°æ®æœªå…¥åº“å¯¼è‡´åå·®ã€‚
"""
import tushare as ts
import pandas as pd
from datetime import datetime, timedelta
from typing import TYPE_CHECKING, Optional, Dict, Any, Tuple
from config.token_manager import get_tushare_token
from cache.index_daily_cache_manager import index_daily_cache_manager
from cache.cache_manager import cache_manager

if TYPE_CHECKING:
    from mcp.server.fastmcp import FastMCP


def register_macro_scan_tools(mcp: "FastMCP"):
    """æ³¨å†Œå®è§‚å…¨æ™¯æ‰«æå·¥å…·"""
    
    @mcp.tool()
    def macro_scan(
        trade_date: str = "",
        seal_rate_warning: float = 60.0,
        limit_down_warning: int = 20
    ) -> str:
        """
        å®è§‚å…¨æ™¯æ‰«æ - ç»¼åˆåˆ†æå¸‚åœºå®è§‚æ€åŠ¿
        
        å‚æ•°:
            trade_date: åˆ†ææ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241209ï¼Œé»˜è®¤ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥ï¼‰
            seal_rate_warning: å°æ¿ç‡é¢„è­¦é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œä½äºæ­¤å€¼è§¦å‘é¢„è­¦ï¼Œé»˜è®¤60%
            limit_down_warning: è·Œåœå®¶æ•°é¢„è­¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è§¦å‘é¢„è­¦ï¼Œé»˜è®¤20å®¶
        
        è¿”å›:
            åŒ…å«å››ä¸ªç»´åº¦åˆ†æçš„å®è§‚å…¨æ™¯æ‰«ææŠ¥å‘Š
        
        æ³¨æ„:
            - æœ¬å·¥å…·ä»…é€‚ç”¨äº 15:30 æ”¶ç›˜åæ‰§è¡Œ
            - ç›˜ä¸­æ‰§è¡Œå¯èƒ½å› æ•°æ®æœªå…¥åº“å¯¼è‡´åå·®
        
        åˆ†æç»´åº¦:
            1. å¸‚åœºé‡èƒ½åˆ¤å®š - ä¸Šè¯+æ·±è¯å…¨å£å¾„æˆäº¤é¢å¯¹æ¯”
            2. é£æ ¼ä¸èµšé’±æ•ˆåº” - æ²ªæ·±300/å›½è¯2000/ç§‘åˆ›50 å¤§å°ç›˜å‰ªåˆ€å·®
            3. æƒ…ç»ªæå€¼æ¢æµ‹ - å°æ¿ç‡ã€è·Œåœå®¶æ•°ã€å†°ç‚¹æœŸåˆ¤å®š
            4. é¾™è™æ¦œæœºæ„æ€åº¦ - æœºæ„ä¸“ç”¨å¸­ä½ä¹°å…¥å‡€é¢å æ¯”
            5. å¤–éƒ¨éªŒè¯ - çº³æŒ‡ETF/ä¸­æ¦‚äº’è”ETFæŠ˜ç®—å¤–ç›˜å¹²æ‰°
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        try:
            # ç¡®å®šåˆ†ææ—¥æœŸ
            if not trade_date:
                trade_date = _get_latest_trade_date()
            
            # æ‰§è¡Œå››ä¸ªåˆ†ææ¨¡å—
            volume_result = _analyze_market_volume(trade_date)
            style_result = _analyze_style_and_profit_effect(trade_date)
            sentiment_result = _analyze_sentiment_extremes(trade_date, seal_rate_warning, limit_down_warning, style_result)
            inst_result = _analyze_institutional_sentiment(trade_date, volume_result.get("today_amount", 0))
            external_result = _analyze_external_validation(trade_date)
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            report = _format_macro_scan_report(
                trade_date,
                volume_result,
                style_result,
                sentiment_result,
                inst_result,
                external_result
            )
            
            return report
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"å®è§‚å…¨æ™¯æ‰«æå¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"


def _get_latest_trade_date() -> str:
    """è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼ˆç®€å•å®ç°ï¼Œä½¿ç”¨å½“å¤©æˆ–æœ€è¿‘å·¥ä½œæ—¥ï¼‰"""
    today = datetime.now()
    # å¦‚æœæ˜¯å‘¨æœ«ï¼Œå›é€€åˆ°å‘¨äº”
    while today.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
        today -= timedelta(days=1)
    return today.strftime("%Y%m%d")


def _get_previous_trading_date(trade_date: str) -> Optional[str]:
    """
    è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
    
    å‚æ•°:
        trade_date: å½“å‰äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰
    
    è¿”å›:
        å‰ä¸€ä¸ªäº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›None
    """
    try:
        pro = ts.pro_api()
        
        # ä½¿ç”¨äº¤æ˜“æ—¥å†æ¥å£è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
        # è·å–æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°å‰ä¸€ä¸ªäº¤æ˜“æ—¥
        end_date_obj = datetime.strptime(trade_date, '%Y%m%d')
        start_date_obj = end_date_obj - timedelta(days=10)
        start_date = start_date_obj.strftime('%Y%m%d')
        
        # è·å–äº¤æ˜“æ—¥å†
        cal_df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=trade_date, is_open=1)
        
        if cal_df is not None and not cal_df.empty:
            # ç­›é€‰å‡ºäº¤æ˜“æ—¥ï¼ŒæŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            cal_df = cal_df.sort_values('cal_date', ascending=False)
            # ç¡®ä¿cal_dateåˆ—æ˜¯æ•´æ•°ç±»å‹
            if cal_df['cal_date'].dtype != 'int64':
                cal_df['cal_date'] = pd.to_numeric(cal_df['cal_date'], errors='coerce')
            end_date_int = int(trade_date) if isinstance(trade_date, str) else trade_date
            cal_df = cal_df[cal_df['cal_date'] <= end_date_int]
            
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å»é‡
            trading_dates = cal_df['cal_date'].astype(str).unique().tolist()
            trading_dates = list(dict.fromkeys(trading_dates))  # ä¿æŒé¡ºåºçš„å»é‡
            
            if len(trading_dates) >= 2:
                # è¿”å›å‰ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆç¬¬äºŒä¸ªï¼‰
                return trading_dates[1]
            elif len(trading_dates) == 1:
                # åªæœ‰ä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œè¯´æ˜å¯èƒ½æ˜¯ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œæ— æ³•è·å–å‰ä¸€ä¸ª
                return None
        return None
    except Exception as e:
        return None


def _analyze_market_volume(trade_date: str) -> Dict[str, Any]:
    """
    æ¨¡å—1: å¸‚åœºé‡èƒ½åˆ¤å®š (å…¨å£å¾„)
    
    å·¥å…·: ä¸Šè¯æŒ‡æ•°(000001.SH) + æ·±è¯æˆæŒ‡(399001.SZ)
    è®¡ç®—: ä»Šæ—¥æ€»æˆäº¤é¢ = ä¸Šè¯amount + æ·±è¯amount
    å¯¹æ¯”: (ä»Šæ—¥æ€»é¢ / æ˜¨æ—¥æ€»é¢) - 1
    """
    result = {
        "success": False,
        "today_amount": 0,
        "yesterday_amount": 0,
        "sh_amount": 0,
        "sz_amount": 0,
        "change_pct": 0,
        "diagnosis": "",
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        
        # ä½¿ç”¨äº¤æ˜“æ—¥å†è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
        yesterday_date = _get_previous_trading_date(trade_date)
        if not yesterday_date:
            result["error"] = f"æ— æ³•è·å– {trade_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥"
            return result
        
        # è·å–ä¸Šè¯æŒ‡æ•°ä»Šæ—¥æ•°æ®
        sh_today_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="000001.SH",
            trade_date=trade_date
        )
        if sh_today_df is None or sh_today_df.empty:
            sh_today_df = pro.index_daily(ts_code="000001.SH", trade_date=trade_date)
            if not sh_today_df.empty:
                index_daily_cache_manager.save_index_daily_data(sh_today_df)
        
        # è·å–ä¸Šè¯æŒ‡æ•°æ˜¨æ—¥æ•°æ®
        sh_yesterday_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="000001.SH",
            trade_date=yesterday_date
        )
        if sh_yesterday_df is None or sh_yesterday_df.empty:
            sh_yesterday_df = pro.index_daily(ts_code="000001.SH", trade_date=yesterday_date)
            if not sh_yesterday_df.empty:
                index_daily_cache_manager.save_index_daily_data(sh_yesterday_df)
        
        # è·å–æ·±è¯æˆæŒ‡ä»Šæ—¥æ•°æ®
        sz_today_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="399001.SZ",
            trade_date=trade_date
        )
        if sz_today_df is None or sz_today_df.empty:
            sz_today_df = pro.index_daily(ts_code="399001.SZ", trade_date=trade_date)
            if not sz_today_df.empty:
                index_daily_cache_manager.save_index_daily_data(sz_today_df)
        
        # è·å–æ·±è¯æˆæŒ‡æ˜¨æ—¥æ•°æ®
        sz_yesterday_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="399001.SZ",
            trade_date=yesterday_date
        )
        if sz_yesterday_df is None or sz_yesterday_df.empty:
            sz_yesterday_df = pro.index_daily(ts_code="399001.SZ", trade_date=yesterday_date)
            if not sz_yesterday_df.empty:
                index_daily_cache_manager.save_index_daily_data(sz_yesterday_df)
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´
        if (sh_today_df is None or sh_today_df.empty or 
            sh_yesterday_df is None or sh_yesterday_df.empty or
            sz_today_df is None or sz_today_df.empty or
            sz_yesterday_df is None or sz_yesterday_df.empty):
            result["error"] = "æ— æ³•è·å–å®Œæ•´çš„æŒ‡æ•°æ•°æ®"
            return result
        
        # è®¡ç®—ä»Šæ—¥å’Œæ˜¨æ—¥æˆäº¤é¢ (amount å•ä½ä¸ºåƒå…ƒ)
        sh_today = float(sh_today_df.iloc[0]['amount']) if pd.notna(sh_today_df.iloc[0]['amount']) else 0
        sh_yesterday = float(sh_yesterday_df.iloc[0]['amount']) if pd.notna(sh_yesterday_df.iloc[0]['amount']) else 0
        sz_today = float(sz_today_df.iloc[0]['amount']) if pd.notna(sz_today_df.iloc[0]['amount']) else 0
        sz_yesterday = float(sz_yesterday_df.iloc[0]['amount']) if pd.notna(sz_yesterday_df.iloc[0]['amount']) else 0
        
        today_total = sh_today + sz_today
        yesterday_total = sh_yesterday + sz_yesterday
        
        # è®¡ç®—å˜åŒ–ç‡
        if yesterday_total > 0:
            change_pct = (today_total / yesterday_total - 1) * 100
        else:
            change_pct = 0
        
        # è·å–æ—¥æœŸä¿¡æ¯
        sh_today_date = str(sh_today_df.iloc[0]['trade_date']) if pd.notna(sh_today_df.iloc[0]['trade_date']) else trade_date
        sh_yesterday_date = str(sh_yesterday_df.iloc[0]['trade_date']) if pd.notna(sh_yesterday_df.iloc[0]['trade_date']) else yesterday_date
        
        # è½¬æ¢ä¸ºäº¿å…ƒ
        sh_amount_yuan = sh_today / 10000  # è½¬æ¢ä¸ºäº¿å…ƒ
        sz_amount_yuan = sz_today / 10000
        today_amount_yuan = today_total / 10000
        yesterday_amount_yuan = yesterday_total / 10000
        
        # è®¾ç½®æ•°æ®å­—æ®µï¼ˆæ— è®ºéªŒè¯æ˜¯å¦é€šè¿‡éƒ½å…ˆè®¾ç½®ï¼Œç¡®ä¿èƒ½æ˜¾ç¤ºæ•°æ®ï¼‰
        result["sh_amount"] = sh_amount_yuan
        result["sz_amount"] = sz_amount_yuan
        result["today_amount"] = today_amount_yuan
        result["yesterday_amount"] = yesterday_amount_yuan
        result["change_pct"] = change_pct
        result["today_date"] = sh_today_date
        result["yesterday_date"] = sh_yesterday_date
        
        # æ•°æ®éªŒè¯ï¼šä»…ä½œä¸ºè­¦å‘Šï¼Œä¸å½±å“æ•°æ®å±•ç¤º
        # ç§»é™¤ä¸¥æ ¼çš„èŒƒå›´é™åˆ¶ï¼Œå› ä¸ºå®é™…å¸‚åœºæˆäº¤é¢å¯èƒ½è¶…å‡ºé¢„æœŸèŒƒå›´
        result["success"] = True
        
        # è¯Šæ–­
        if change_pct > 10:
            result["diagnosis"] = "ğŸ“ˆ æ˜¾è‘—æ”¾é‡"
        elif change_pct > 0:
            result["diagnosis"] = "ğŸ“ˆ æ¸©å’Œæ”¾é‡"
        elif change_pct > -10:
            result["diagnosis"] = "ğŸ“‰ æ¸©å’Œç¼©é‡"
        else:
            result["diagnosis"] = "ğŸ“‰ æ˜¾è‘—ç¼©é‡"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _analyze_style_and_profit_effect(trade_date: str) -> Dict[str, Any]:
    """
    æ¨¡å—2: é£æ ¼ä¸èµšé’±æ•ˆåº” (å¤§å°ç›˜å‰ªåˆ€å·®)
    
    å·¥å…·: æ²ªæ·±300(000300.SH), å›½è¯2000(399303.SZ), ç§‘åˆ›50(000688.SH)
    é€»è¾‘:
        300â†‘ + 2000â†‘ = å…¨é¢åšå¤š
        300â†‘ + 2000â†“ = åªèµšæŒ‡æ•°ï¼ˆè°¨æ…ï¼‰
        300â†“ + 2000â†‘ = é¢˜ææ´»è·ƒï¼ˆè½»æŒ‡æ•°é‡ä¸ªè‚¡ï¼‰
        300â†“ + 2000â†“ = å…¨é¢é€€æ½®
    """
    result = {
        "success": False,
        "hs300": {"pct_chg": 0, "close": 0},
        "gz2000": {"pct_chg": 0, "close": 0},
        "kc50": {"pct_chg": 0, "close": 0},
        "diagnosis": "",
        "diagnosis_detail": "",
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        index_codes = ["000300.SH", "399303.SZ", "000688.SH"]
        index_data = {}
        
        for code in index_codes:
            df = index_daily_cache_manager.get_index_daily_data(
                ts_code=code,
                trade_date=trade_date
            )
            
            if df is None or df.empty:
                df = pro.index_daily(ts_code=code, trade_date=trade_date)
                if not df.empty:
                    index_daily_cache_manager.save_index_daily_data(df)
            
            if df is not None and not df.empty:
                index_data[code] = {
                    "pct_chg": float(df.iloc[0]['pct_chg']) if pd.notna(df.iloc[0]['pct_chg']) else 0,
                    "close": float(df.iloc[0]['close']) if pd.notna(df.iloc[0]['close']) else 0
                }
            else:
                index_data[code] = {"pct_chg": 0, "close": 0}
        
        result["success"] = True
        result["hs300"] = index_data.get("000300.SH", {"pct_chg": 0, "close": 0})
        result["gz2000"] = index_data.get("399303.SZ", {"pct_chg": 0, "close": 0})
        result["kc50"] = index_data.get("000688.SH", {"pct_chg": 0, "close": 0})
        
        hs300_up = result["hs300"]["pct_chg"] > 0
        gz2000_up = result["gz2000"]["pct_chg"] > 0
        
        # è¯Šæ–­é€»è¾‘
        if hs300_up and gz2000_up:
            result["diagnosis"] = "ğŸŸ¢ å…¨é¢åšå¤š"
            result["diagnosis_detail"] = "å¤§å°ç›˜å…±æŒ¯ä¸Šæ¶¨"
        elif hs300_up and not gz2000_up:
            result["diagnosis"] = "ğŸŸ¡ åªèµšæŒ‡æ•°"
            result["diagnosis_detail"] = "æƒé‡æŠ¤ç›˜ï¼Œé¢˜æé€€æ½®ï¼Œè°¨æ…æ“ä½œ"
        elif not hs300_up and gz2000_up:
            result["diagnosis"] = "ğŸ”µ é¢˜ææ´»è·ƒ"
            result["diagnosis_detail"] = "è½»æŒ‡æ•°é‡ä¸ªè‚¡ï¼Œå°ç›˜è‚¡æ´»è·ƒ"
        else:
            result["diagnosis"] = "ğŸ”´ å…¨é¢é€€æ½®"
            result["diagnosis_detail"] = "å¤§å°ç›˜å…±æŒ¯ä¸‹è·Œ"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _analyze_sentiment_extremes(
    trade_date: str,
    seal_rate_warning: float,
    limit_down_warning: int,
    style_result: Dict[str, Any]
) -> Dict[str, Any]:
    """
    æ¨¡å—3: æƒ…ç»ªæå€¼æ¢æµ‹
    
    å·¥å…·: get_limit_list(limit_type='U'/'Z'/'D')
    è®¡ç®—: å°æ¿ç‡ = æ¶¨åœæ•° / (æ¶¨åœæ•° + ç‚¸æ¿æ•°)
    å†°ç‚¹æœŸåˆ¤å®š: è·Œåœå®¶æ•° > 20 ä¸” å›½è¯2000 ä¸‹è·Œ
    """
    result = {
        "success": False,
        "limit_up_count": 0,
        "limit_failed_count": 0,
        "limit_down_count": 0,
        "seal_rate": 0,
        "is_ice_period": False,
        "diagnosis": "",
        "warning": None,
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        
        # è·å–æ¶¨åœæ•°æ®
        up_df = pro.limit_list_d(trade_date=trade_date, limit_type='U')
        limit_up_count = len(up_df) if up_df is not None else 0
        
        # è·å–ç‚¸æ¿æ•°æ®
        failed_df = pro.limit_list_d(trade_date=trade_date, limit_type='Z')
        limit_failed_count = len(failed_df) if failed_df is not None else 0
        
        # è·å–è·Œåœæ•°æ®
        down_df = pro.limit_list_d(trade_date=trade_date, limit_type='D')
        limit_down_count = len(down_df) if down_df is not None else 0
        
        # è®¡ç®—å°æ¿ç‡
        if limit_up_count + limit_failed_count > 0:
            seal_rate = limit_up_count / (limit_up_count + limit_failed_count) * 100
        else:
            seal_rate = 0
        
        result["success"] = True
        result["limit_up_count"] = limit_up_count
        result["limit_failed_count"] = limit_failed_count
        result["limit_down_count"] = limit_down_count
        result["seal_rate"] = seal_rate
        
        # å†°ç‚¹æœŸåˆ¤å®šï¼šè·Œåœå®¶æ•° > é˜ˆå€¼ ä¸” å›½è¯2000 ä¸‹è·Œ
        gz2000_down = style_result.get("gz2000", {}).get("pct_chg", 0) < 0
        if limit_down_count > limit_down_warning and gz2000_down:
            result["is_ice_period"] = True
            result["warning"] = "ğŸ”´ã€å†°ç‚¹æœŸã€‘è·Œåœå®¶æ•°è¿‡å¤šä¸”å°ç›˜è‚¡ä¸‹è·Œ"
        
        # è¯Šæ–­
        if seal_rate < seal_rate_warning:
            result["diagnosis"] = "âš ï¸ å°æ¿ç‡åä½"
            if result["warning"] is None:
                result["warning"] = f"å°æ¿ç‡ä½äº {seal_rate_warning}%"
        elif seal_rate >= 80:
            result["diagnosis"] = "ğŸŸ¢ å¸‚åœºæƒ…ç»ªæ´»è·ƒ"
        else:
            result["diagnosis"] = "ğŸŸ¡ å¸‚åœºæƒ…ç»ªä¸€èˆ¬"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _analyze_institutional_sentiment(trade_date: str, market_total_amount_billion: float = 0) -> Dict[str, Any]:
    """
    æ¨¡å—5: é¾™è™æ¦œæœºæ„æ€åº¦ (æ–°ç‰ˆé‡æ„)
    
    å·¥å…·: top_list(æ¯æ—¥æ˜ç»†), top_inst(æœºæ„æ˜ç»†)
    åˆ†æç»´åº¦:
        1. net_buy (æœºæ„å‡€ä¹°å…¥): å®è§‚åŸºæœ¬é¢èµ„é‡‘çš„â€œæŠ•ç¥¨æƒâ€
        2. reason (ä¸Šæ¦œç†ç”±): è¯†åˆ«å®è§‚æ³¢åŠ¨çš„è¯±å› 
        3. amount_rate (æˆäº¤å æ¯”): è¡¡é‡çƒ­ç‚¹å¯¹å…¨å¸‚åœºçš„å¸é‡‘æ•ˆåº” (é¾™è™æ¦œæ€»æˆäº¤é¢ / å…¨å¸‚åœºæ€»æˆäº¤é¢)
        4. exalter (å¸­ä½åç§°): è¯†åˆ«â€œå›½å®¶é˜Ÿâ€æˆ–â€œçŸ¥åé¡¶çº§æœºæ„â€åŠ¨ä½œ
    """
    result = {
        "success": False,
        "net_buy": {
            "value": 0,
            "status": "å¹³ç¨³"
        },
        "reason": {
            "top_reasons": [],
            "diagnosis": ""
        },
        "amount_rate": {
            "top_list_amount": 0,
            "market_total_amount": 0,
            "ratio": 0,
            "diagnosis": ""
        },
        "exalter": {
            "key_institutions": [],  # çŸ¥åå¸­ä½åŠ¨ä½œ
            "diagnosis": ""
        },
        "diagnosis": "",
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        
        # 1. è·å–æ•°æ®
        top_list_df = pro.top_list(trade_date=trade_date)
        top_inst_df = pro.top_inst(trade_date=trade_date)
        
        if top_list_df is None or top_list_df.empty:
            result["diagnosis"] = "âšª ä»Šæ—¥æ— é¾™è™æ¦œæ•°æ®"
            result["success"] = True
            return result
            
        # ---------------------------------------------------------------------
        # åˆ†æç»´åº¦1: net_buy (æœºæ„å‡€ä¹°å…¥)
        # ---------------------------------------------------------------------
        inst_net_buy = 0
        inst_buy_rate = 0
        
        if top_inst_df is not None and not top_inst_df.empty:
            inst_only = top_inst_df[top_inst_df['exalter'].str.contains('æœºæ„ä¸“ç”¨', na=False)]
            if not inst_only.empty:
                buy_sum = inst_only['buy'].sum()
                sell_sum = inst_only['sell'].sum()
                inst_net_buy = (buy_sum - sell_sum) / 10000  # ä¸‡å…ƒ
                if 'buy_rate' in inst_only.columns:
                    inst_buy_rate = inst_only['buy_rate'].mean()
        
        # åˆ¤å®šçŠ¶æ€
        if inst_net_buy > 10000: # 1äº¿ä»¥ä¸Š
            if inst_buy_rate > 15:
                net_buy_status = "ğŸŸ¢ æœºæ„æç«¯å…±è¯† (å®è§‚ä¸»çº¿ç¡®è®¤)"
            else:
                net_buy_status = "ğŸŸ¢ æœºæ„é…ç½®æµå…¥ (åŸºçŸ³åŠ›é‡)"
        elif inst_net_buy > 2000: # 2000ä¸‡-1äº¿
            net_buy_status = "ğŸŸ¢ æœºæ„å‚ä¸æ´»è·ƒ"
        elif inst_net_buy < -10000:
            net_buy_status = "ğŸ”´ æœºæ„ååŒæŠ›å”® (å®è§‚é£é™©é‡Šæ”¾)"
        else:
            net_buy_status = "ğŸŸ¡ å­˜é‡åšå¼ˆ"
            
        result["net_buy"] = {
            "value": inst_net_buy,
            "status": net_buy_status
        }
        
        # ---------------------------------------------------------------------
        # åˆ†æç»´åº¦2: reason (ä¸Šæ¦œç†ç”±)
        # ---------------------------------------------------------------------
        if 'reason' in top_list_df.columns:
            reasons = top_list_df['reason'].dropna().astype(str).tolist()
            
            # å…³é”®è¯æ˜ å°„
            categories = {
                "æ³¢æ®µè¶‹åŠ¿ (Trend)": ["è¿ç»­ä¸‰ä¸ªäº¤æ˜“æ—¥"],  # è¿™æ˜¯å®è§‚èµ„é‡‘æœ€æ ¸å¿ƒçš„æˆ˜åœº
                "å•æ—¥è„‰å†² (Impulse)": ["æ¶¨å¹…åç¦»", "æ¶¨å¹…è¾¾", "è·Œå¹…åç¦»", "è·Œå¹…è¾¾"],
                "åšå¼ˆæ¢æ‰‹ (Churn)": ["æ¢æ‰‹ç‡", "æŒ¯å¹…", "å¼‚å¸¸æ³¢åŠ¨"],
                "å…¶å®ƒ": []
            }
            
            # ç»Ÿè®¡
            cat_stats = {k: 0 for k in categories.keys()}
            
            for r in reasons:
                found = False
                for cat, keywords in categories.items():
                    if any(kw in r for kw in keywords):
                        cat_stats[cat] += 1
                        found = True
                        break
                if not found:
                    cat_stats["å…¶å®ƒ"] += 1
            
            # æ‰¾å‡ºä¸»è¦è¯±å› 
            sorted_cats = sorted(cat_stats.items(), key=lambda x: x[1], reverse=True)
            top_cat = sorted_cats[0][0]
            
            top_reasons_list = [f"{k}({v})" for k, v in sorted_cats if v > 0]
            
            # è¯Šæ–­é€»è¾‘é‡æ„
            diagnosis = f"æ³¢åŠ¨è¯±å› : {top_cat}"
            if top_cat == "æ³¢æ®µè¶‹åŠ¿ (Trend)":
                # ç»“åˆä¹‹å‰è®¡ç®—çš„ inst_net_buy
                if inst_net_buy > 0:
                    diagnosis = "å®è§‚ç”»åƒ: å¼ºè¶‹åŠ¿ç¡®è®¤ (æœºæ„åˆåŠ›ä¸»æ¨)"
                else:
                    diagnosis = "å®è§‚ç”»åƒ: æƒ…ç»ªé©±åŠ¨çš„æ³¢æ®µè¡Œæƒ…"
            elif top_cat == "å•æ—¥è„‰å†² (Impulse)":
                diagnosis = "å®è§‚ç”»åƒ: çªå‘æ¶ˆæ¯åˆºæ¿€/æƒ…ç»ªè„‰å†²"
            elif top_cat == "åšå¼ˆæ¢æ‰‹ (Churn)":
                diagnosis = "å®è§‚ç”»åƒ: åˆ†æ­§åŠ å¤§ (é«˜æ¢æ‰‹åšå¼ˆ)"
                
            result["reason"] = {
                "top_reasons": top_reasons_list[:3],
                "diagnosis": diagnosis
            }
        
        # ---------------------------------------------------------------------
        # åˆ†æç»´åº¦3: amount_rate (æˆäº¤å æ¯”)
        # ---------------------------------------------------------------------
        # é¾™è™æ¦œæ€»æˆäº¤é¢ (amount å­—æ®µé€šå¸¸æ˜¯æ€»æˆäº¤é¢ï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”¨ l_buy+l_sell è¿‘ä¼¼ï¼Œä½† amount æ›´å‡†)
        # æ³¨æ„å»é‡ï¼šåŒä¸€åªè‚¡ç¥¨å¯èƒ½æœ‰å¤šæ¡è®°å½•
        top_list_dedup = top_list_df.drop_duplicates(subset=['ts_code'])
        list_amount = top_list_dedup['amount'].sum() / 100000000  # äº¿å…ƒ
        
        # å…¨å¸‚åœºæ€»æˆäº¤é¢ (ä¼ å…¥å‚æ•°ï¼Œå•ä½äº¿å…ƒ)
        market_amount = market_total_amount_billion
        
        ratio = 0
        amt_diagnosis = ""
        
        if market_amount > 0:
            ratio = (list_amount / market_amount) * 100
            
            if ratio > 15:
                amt_diagnosis = "ğŸ”´ æåº¦å¸é‡‘ (æµåŠ¨æ€§æ¯ç«­é£é™©)"
            elif ratio > 10:
                amt_diagnosis = "ğŸŸ¡ çƒ­ç‚¹å¸é‡‘æ˜æ˜¾"
            elif ratio < 2:
                amt_diagnosis = "ğŸ”µ æ¸¸èµ„æ´»è·ƒåº¦ä½"
            else:
                amt_diagnosis = "ğŸŸ¢ æµåŠ¨æ€§åˆ†å¸ƒå¥åº·"
        else:
            amt_diagnosis = "âš ï¸ æ— æ³•è®¡ç®— (ç¼ºå…¨å¸‚åœºæ•°æ®)"
            
        result["amount_rate"] = {
            "top_list_amount": list_amount,
            "market_total_amount": market_amount,
            "ratio": ratio,
            "diagnosis": amt_diagnosis
        }
        
        # ---------------------------------------------------------------------
        # åˆ†æç»´åº¦4: exalter (é‡ç‚¹å¸­ä½)
        # ---------------------------------------------------------------------
        key_institutions = []
        inst_diagnosis = "å¸¸è§„åšå¼ˆ"
        
        if top_inst_df is not None and not top_inst_df.empty:
            # å®šä¹‰å…³æ³¨åå•
            # æ³¨æ„ï¼šå®é™…é¾™è™æ¦œä¸­â€œå›½å®¶é˜Ÿâ€å¾€å¾€éšèº«æˆ–ä½¿ç”¨ç‰¹å®šå¸­ä½ï¼Œè¿™é‡Œåˆ—ä¸¾å¸¸è§å¤´éƒ¨/ä»£è¡¨æ€§å¸­ä½
            watch_list = [
                "ä¸­ä¿¡è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ€»éƒ¨", "ä¸­é‡‘å…¬å¸", "ä¸­å¤®æ±‡é‡‘", 
                "æ²ªè‚¡é€šä¸“ç”¨", "æ·±è‚¡é€šä¸“ç”¨", # åŒ—å‘
                "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ€»éƒ¨", "ä¸­å›½é“¶æ²³è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ€»éƒ¨"
            ]
            
            # æ‰«æ
            for inst_name in watch_list:
                # æ¨¡ç³ŠåŒ¹é…
                matched = top_inst_df[top_inst_df['exalter'].str.contains(inst_name, na=False)]
                if not matched.empty:
                    # ç»Ÿè®¡åŠ¨ä½œ
                    buy = matched[matched['side'] == 0]['buy'].sum()
                    sell = matched[matched['side'] == 1]['sell'].sum()
                    net = buy - sell
                    
                    if buy + sell > 0: # æœ‰æ“ä½œ
                        action = "ä¹°å…¥" if net > 0 else "å–å‡º"
                        amt = abs(net) / 10000 # ä¸‡å…ƒ
                        key_institutions.append(f"{inst_name[:4]}: å‡€{action} {amt:.0f}ä¸‡")
            
            if len(key_institutions) > 0:
                inst_diagnosis = "ğŸ”¥ é¡¶çº§èµ„é‡‘ç°èº«"
            else:
                inst_diagnosis = "å¸¸è§„æœºæ„åšå¼ˆ"

        result["exalter"] = {
            "key_institutions": key_institutions[:5], # åªå–å‰5ä¸ª
            "diagnosis": inst_diagnosis
        }
        
        result["success"] = True
        
        # ç”Ÿæˆæ¨¡å—ç»¼åˆè¯Šæ–­
        diags = []
        diags.append(net_buy_status.split(' ')[0]) # ğŸŸ¢/ğŸ”´
        if result["amount_rate"]["ratio"] > 10:
            diags.append("çƒ­ç‚¹å¸é‡‘")
        if len(key_institutions) > 0:
            diags.append("ä¸»åŠ›ç°èº«")
            
        result["diagnosis"] = " ".join(diags)
            
    except Exception as e:
        result["error"] = str(e)
        
    return result


def _analyze_external_validation(trade_date: str) -> Dict[str, Any]:
    """
    æ¨¡å—4: å¤–éƒ¨éªŒè¯ (ETFæŠ˜ç®—)
    
    å·¥å…·: çº³æŒ‡ETF(513100.SH), ä¸­æ¦‚äº’è”ETF(513050.SH)
    é€»è¾‘: é€šè¿‡åœºå†…ETFæ¶¨è·Œï¼Œåæ¨å¤–å›´ç¯å¢ƒå¯¹Aè‚¡ä»Šæ—¥æƒ…ç»ªçš„å®é™…æ‰°åŠ¨
    """
    result = {
        "success": False,
        "nasdaq_etf": {"pct_chg": 0, "close": 0},
        "china_internet_etf": {"pct_chg": 0, "close": 0},
        "diagnosis": "",
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        etf_codes = ["513100.SH", "513050.SH"]
        etf_data = {}
        
        for code in etf_codes:
            # ETF ä½¿ç”¨ fund_daily æ¥å£
            df = pro.fund_daily(ts_code=code, trade_date=trade_date)
            
            if df is not None and not df.empty:
                etf_data[code] = {
                    "pct_chg": float(df.iloc[0]['pct_chg']) if pd.notna(df.iloc[0].get('pct_chg')) else 0,
                    "close": float(df.iloc[0]['close']) if pd.notna(df.iloc[0]['close']) else 0
                }
            else:
                etf_data[code] = {"pct_chg": 0, "close": 0}
        
        result["success"] = True
        result["nasdaq_etf"] = etf_data.get("513100.SH", {"pct_chg": 0, "close": 0})
        result["china_internet_etf"] = etf_data.get("513050.SH", {"pct_chg": 0, "close": 0})
        
        # è¯Šæ–­
        avg_pct = (result["nasdaq_etf"]["pct_chg"] + result["china_internet_etf"]["pct_chg"]) / 2
        if avg_pct > 1:
            result["diagnosis"] = "ğŸŸ¢ å¤–ç›˜ç¯å¢ƒç§¯æ"
        elif avg_pct > -1:
            result["diagnosis"] = "ğŸŸ¢ å¤–ç›˜å¹²æ‰°æœ‰é™"
        else:
            result["diagnosis"] = "ğŸ”´ å¤–ç›˜æ‹–ç´¯æ˜æ˜¾"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _format_macro_scan_report(
    trade_date: str,
    volume_result: Dict[str, Any],
    style_result: Dict[str, Any],
    sentiment_result: Dict[str, Any],
    inst_result: Dict[str, Any],
    external_result: Dict[str, Any]
) -> str:
    """æ ¼å¼åŒ–å®è§‚å…¨æ™¯æ‰«ææŠ¥å‘Š"""
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    formatted_date = f"{trade_date[:4]}-{trade_date[4:6]}-{trade_date[6:8]}" if len(trade_date) == 8 else trade_date
    
    lines = []
    lines.append("ğŸ“Š å®è§‚å…¨æ™¯æ‰«ææŠ¥å‘Š")
    lines.append("=" * 50)
    lines.append(f"ğŸ“… åˆ†ææ—¥æœŸ: {formatted_date}")
    lines.append("")
    
    # æ¨¡å—1: å¸‚åœºé‡èƒ½åˆ¤å®š
    lines.append("ã€ä¸€ã€å¸‚åœºé‡èƒ½åˆ¤å®šã€‘")
    if volume_result["success"]:
        today_date = volume_result.get('today_date', '')
        yesterday_date = volume_result.get('yesterday_date', '')
        
        # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
        if today_date and len(today_date) == 8:
            today_date_fmt = f"{today_date[:4]}-{today_date[4:6]}-{today_date[6:8]}"
        else:
            today_date_fmt = today_date
        
        if yesterday_date and len(yesterday_date) == 8:
            yesterday_date_fmt = f"{yesterday_date[:4]}-{yesterday_date[4:6]}-{yesterday_date[6:8]}"
        else:
            yesterday_date_fmt = yesterday_date
        
        lines.append(f"- ä»Šæ—¥({today_date_fmt})æ€»æˆäº¤é¢: {volume_result['today_amount']:.2f} äº¿å…ƒ")
        lines.append(f"  â€¢ ä¸Šè¯: {volume_result['sh_amount']:.2f} äº¿å…ƒ")
        lines.append(f"  â€¢ æ·±è¯: {volume_result['sz_amount']:.2f} äº¿å…ƒ")
        lines.append(f"- æ˜¨æ—¥({yesterday_date_fmt})æ€»æˆäº¤é¢: {volume_result['yesterday_amount']:.2f} äº¿å…ƒ")
        change_sign = "+" if volume_result['change_pct'] >= 0 else ""
        lines.append(f"- å˜åŒ–: {volume_result['diagnosis']} {change_sign}{volume_result['change_pct']:.1f}%")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {volume_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # æ¨¡å—2: é£æ ¼ä¸èµšé’±æ•ˆåº”
    lines.append("ã€äºŒã€é£æ ¼ä¸èµšé’±æ•ˆåº”ã€‘")
    if style_result["success"]:
        lines.append("| æŒ‡æ•°       | æ¶¨è·Œå¹…        | æ”¶ç›˜ç‚¹ä½     |")
        lines.append("|-----------|--------------|-------------|")
        
        hs300 = style_result["hs300"]
        gz2000 = style_result["gz2000"]
        kc50 = style_result["kc50"]
        
        lines.append(f"| æ²ªæ·±300   | {hs300['pct_chg']:+.2f}%      | {hs300['close']:.2f}      |")
        lines.append(f"| å›½è¯2000  | {gz2000['pct_chg']:+.2f}%      | {gz2000['close']:.2f}      |")
        lines.append(f"| ç§‘åˆ›50    | {kc50['pct_chg']:+.2f}%      | {kc50['close']:.2f}      |")
        lines.append(f"- è¯Šæ–­: {style_result['diagnosis']}ï¼ˆ{style_result['diagnosis_detail']}ï¼‰")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {style_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # æ¨¡å—3: æƒ…ç»ªæå€¼æ¢æµ‹
    lines.append("ã€ä¸‰ã€æƒ…ç»ªæå€¼æ¢æµ‹ã€‘")
    if sentiment_result["success"]:
        lines.append(f"- æ¶¨åœå®¶æ•°: {sentiment_result['limit_up_count']}")
        lines.append(f"- ç‚¸æ¿å®¶æ•°: {sentiment_result['limit_failed_count']}")
        lines.append(f"- è·Œåœå®¶æ•°: {sentiment_result['limit_down_count']}")
        lines.append(f"- å°æ¿ç‡: {sentiment_result['seal_rate']:.1f}%")
        lines.append(f"- è¯Šæ–­: {sentiment_result['diagnosis']}")
        if sentiment_result["warning"]:
            lines.append(f"- é¢„è­¦: {sentiment_result['warning']}")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {sentiment_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")

    # æ¨¡å—4: é¾™è™æ¦œæœºæ„æ€åº¦
    lines.append("ã€å››ã€é¾™è™æ¦œæœºæ„æ€åº¦ã€‘")
    if inst_result["success"]:
        net_buy = inst_result["net_buy"]
        reason = inst_result["reason"]
        amount_rate = inst_result["amount_rate"]
        exalter = inst_result["exalter"]
        
        # 1. æœºæ„å‡€ä¹°å…¥
        lines.append(f"1. æœºæ„å‡€ä¹° (net_buy): {net_buy['value']:+.1f} ä¸‡å…ƒ")
        lines.append(f"   â€¢ çŠ¶æ€: {net_buy['status']}")
        
        # 2. ä¸Šæ¦œç†ç”±
        lines.append(f"2. ä¸Šæ¦œç†ç”± (reason): {reason['diagnosis']}")
        if reason['top_reasons']:
            lines.append(f"   â€¢ åˆ†å¸ƒ: {', '.join(reason['top_reasons'])}")
            
        # 3. æˆäº¤å æ¯”
        lines.append(f"3. æˆäº¤å æ¯” (amount_rate): {amount_rate['ratio']:.2f}% (é¾™è™æ¦œ/å…¨å¸‚åœº)")
        lines.append(f"   â€¢ è¯Šæ–­: {amount_rate['diagnosis']}")
        
        # 4. é‡ç‚¹å¸­ä½
        lines.append(f"4. é‡ç‚¹å¸­ä½ (exalter): {exalter['diagnosis']}")
        if exalter['key_institutions']:
            lines.append(f"   â€¢ åŠ¨ä½œ: {', '.join(exalter['key_institutions'])}")
        
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {inst_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # æ¨¡å—5: å¤–éƒ¨éªŒè¯
    lines.append("ã€äº”ã€å¤–éƒ¨éªŒè¯ã€‘")
    if external_result["success"]:
        lines.append("| ETF           | æ¶¨è·Œå¹…        | æ”¶ç›˜ä»·       |")
        lines.append("|--------------|--------------|-------------|")
        
        nasdaq = external_result["nasdaq_etf"]
        china_internet = external_result["china_internet_etf"]
        
        lines.append(f"| çº³æŒ‡ETF      | {nasdaq['pct_chg']:+.2f}%      | {nasdaq['close']:.3f}      |")
        lines.append(f"| ä¸­æ¦‚äº’è”     | {china_internet['pct_chg']:+.2f}%      | {china_internet['close']:.3f}      |")
        lines.append(f"- è¯Šæ–­: {external_result['diagnosis']}")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {external_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # ç»¼åˆè¯Šæ–­
    lines.append("=" * 50)
    lines.append("ç»¼åˆè¯Šæ–­")
    lines.append("=" * 50)
    
    # ç»¼åˆè¯„ä¼°
    overall_score = 0
    issues = []
    
    if volume_result["success"]:
        if volume_result["change_pct"] > 0:
            overall_score += 1
        else:
            issues.append("é‡èƒ½èç¼©")
    
    if style_result["success"]:
        if style_result["diagnosis"].startswith("ğŸŸ¢"):
            overall_score += 2
        elif style_result["diagnosis"].startswith("ğŸ”µ"):
            overall_score += 1
        elif style_result["diagnosis"].startswith("ğŸ”´"):
            overall_score -= 1
            issues.append("å…¨é¢é€€æ½®")
    
    if sentiment_result["success"]:
        if sentiment_result["is_ice_period"]:
            overall_score -= 2
            issues.append("å†°ç‚¹æœŸ")
        elif sentiment_result["seal_rate"] >= 70:
            overall_score += 1
        elif sentiment_result["seal_rate"] < 60:
            issues.append("å°æ¿ç‡åä½")
    
    if inst_result["success"]:
        # æœºæ„å‡€ä¹°å…¥çŠ¶æ€
        net_buy_val = inst_result["net_buy"]["value"]
        if net_buy_val > 5000: # 5000ä¸‡
            overall_score += 1
        elif net_buy_val < -5000:
            overall_score -= 1
            issues.append("æœºæ„æŠ›å‹")
            
        # è™¹å¸æ•ˆåº”é£é™©
        if inst_result["amount_rate"]["ratio"] > 15:
            issues.append("çƒ­ç‚¹è™¹å¸ä¸¥é‡")
            
        # ä¸»åŠ›åŠ¨ä½œ
        if "é¡¶çº§èµ„é‡‘" in inst_result["exalter"]["diagnosis"]:
            overall_score += 1 # æƒé‡åŠ åˆ†
    
    if external_result["success"]:
        avg_pct = (external_result["nasdaq_etf"]["pct_chg"] + external_result["china_internet_etf"]["pct_chg"]) / 2
        if avg_pct < -1:
            issues.append("å¤–ç›˜æ‹–ç´¯")
    
    # è¾“å‡ºç»¼åˆè¯„ä¼°
    if overall_score >= 3:
        lines.append("ğŸŸ¢ å¸‚åœºæ•´ä½“ã€å¥åº·ã€‘")
    elif overall_score >= 1:
        lines.append("ğŸŸ¡ å¸‚åœºæ•´ä½“ã€è°¨æ…ä¹è§‚ã€‘")
    elif overall_score >= -1:
        lines.append("ğŸŸ¡ å¸‚åœºæ•´ä½“ã€éœ‡è¡åˆ†åŒ–ã€‘")
    else:
        lines.append("ğŸ”´ å¸‚åœºæ•´ä½“ã€é«˜é£é™©ã€‘")
    
    if issues:
        lines.append(f"- ä¸»è¦å…³æ³¨ç‚¹: {', '.join(issues)}")
    
    return "\n".join(lines)
