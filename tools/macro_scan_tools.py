"""å®è§‚å…¨æ™¯æ‰«æ MCP å·¥å…·

è¯¥æ¨¡å—æä¾›å®è§‚å¸‚åœºåˆ†æå·¥å…·ï¼Œç»¼åˆåˆ†æå¸‚åœºé‡èƒ½ã€é£æ ¼ã€æƒ…ç»ªå’Œå¤–éƒ¨ç¯å¢ƒã€‚

æ³¨æ„ï¼šæœ¬å·¥å…·ä»…é€‚ç”¨äº 15:30 æ”¶ç›˜åæ‰§è¡Œï¼Œç›˜ä¸­æ‰§è¡Œå¯èƒ½å› æ•°æ®æœªå…¥åº“å¯¼è‡´åå·®ã€‚
"""
import tushare as ts
import pandas as pd
from datetime import datetime, timedelta
from typing import TYPE_CHECKING, Optional, Dict, Any, Tuple
from config.token_manager import get_tushare_token
from cache.index_daily_cache_manager import index_daily_cache_manager
from cache.cache_manager import cache_manager

if TYPE_CHECKING:
    from mcp.server.fastmcp import FastMCP


def register_macro_scan_tools(mcp: "FastMCP"):
    """æ³¨å†Œå®è§‚å…¨æ™¯æ‰«æå·¥å…·"""
    
    @mcp.tool()
    def macro_scan(
        trade_date: str = "",
        seal_rate_warning: float = 60.0,
        limit_down_warning: int = 20
    ) -> str:
        """
        å®è§‚å…¨æ™¯æ‰«æ - ç»¼åˆåˆ†æå¸‚åœºå®è§‚æ€åŠ¿
        
        å‚æ•°:
            trade_date: åˆ†ææ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241209ï¼Œé»˜è®¤ä½¿ç”¨æœ€æ–°äº¤æ˜“æ—¥ï¼‰
            seal_rate_warning: å°æ¿ç‡é¢„è­¦é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œä½äºæ­¤å€¼è§¦å‘é¢„è­¦ï¼Œé»˜è®¤60%
            limit_down_warning: è·Œåœå®¶æ•°é¢„è­¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è§¦å‘é¢„è­¦ï¼Œé»˜è®¤20å®¶
        
        è¿”å›:
            åŒ…å«å››ä¸ªç»´åº¦åˆ†æçš„å®è§‚å…¨æ™¯æ‰«ææŠ¥å‘Š
        
        æ³¨æ„:
            - æœ¬å·¥å…·ä»…é€‚ç”¨äº 15:30 æ”¶ç›˜åæ‰§è¡Œ
            - ç›˜ä¸­æ‰§è¡Œå¯èƒ½å› æ•°æ®æœªå…¥åº“å¯¼è‡´åå·®
        
        åˆ†æç»´åº¦:
            1. å¸‚åœºé‡èƒ½åˆ¤å®š - ä¸Šè¯+æ·±è¯å…¨å£å¾„æˆäº¤é¢å¯¹æ¯”
            2. é£æ ¼ä¸èµšé’±æ•ˆåº” - æ²ªæ·±300/å›½è¯2000/ç§‘åˆ›50 å¤§å°ç›˜å‰ªåˆ€å·®
            3. æƒ…ç»ªæå€¼æ¢æµ‹ - å°æ¿ç‡ã€è·Œåœå®¶æ•°ã€å†°ç‚¹æœŸåˆ¤å®š
            4. å¤–éƒ¨éªŒè¯ - çº³æŒ‡ETF/ä¸­æ¦‚äº’è”ETFæŠ˜ç®—å¤–ç›˜å¹²æ‰°
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        try:
            # ç¡®å®šåˆ†ææ—¥æœŸ
            if not trade_date:
                trade_date = _get_latest_trade_date()
            
            # æ‰§è¡Œå››ä¸ªåˆ†ææ¨¡å—
            volume_result = _analyze_market_volume(trade_date)
            style_result = _analyze_style_and_profit_effect(trade_date)
            sentiment_result = _analyze_sentiment_extremes(trade_date, seal_rate_warning, limit_down_warning, style_result)
            external_result = _analyze_external_validation(trade_date)
            
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            report = _format_macro_scan_report(
                trade_date,
                volume_result,
                style_result,
                sentiment_result,
                external_result
            )
            
            return report
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"å®è§‚å…¨æ™¯æ‰«æå¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"


def _get_latest_trade_date() -> str:
    """è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼ˆç®€å•å®ç°ï¼Œä½¿ç”¨å½“å¤©æˆ–æœ€è¿‘å·¥ä½œæ—¥ï¼‰"""
    today = datetime.now()
    # å¦‚æœæ˜¯å‘¨æœ«ï¼Œå›é€€åˆ°å‘¨äº”
    while today.weekday() >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
        today -= timedelta(days=1)
    return today.strftime("%Y%m%d")


def _get_previous_trading_date(trade_date: str) -> Optional[str]:
    """
    è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
    
    å‚æ•°:
        trade_date: å½“å‰äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰
    
    è¿”å›:
        å‰ä¸€ä¸ªäº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›None
    """
    try:
        pro = ts.pro_api()
        
        # ä½¿ç”¨äº¤æ˜“æ—¥å†æ¥å£è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
        # è·å–æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°å‰ä¸€ä¸ªäº¤æ˜“æ—¥
        end_date_obj = datetime.strptime(trade_date, '%Y%m%d')
        start_date_obj = end_date_obj - timedelta(days=10)
        start_date = start_date_obj.strftime('%Y%m%d')
        
        # è·å–äº¤æ˜“æ—¥å†
        cal_df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=trade_date, is_open=1)
        
        if cal_df is not None and not cal_df.empty:
            # ç­›é€‰å‡ºäº¤æ˜“æ—¥ï¼ŒæŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            cal_df = cal_df.sort_values('cal_date', ascending=False)
            # ç¡®ä¿cal_dateåˆ—æ˜¯æ•´æ•°ç±»å‹
            if cal_df['cal_date'].dtype != 'int64':
                cal_df['cal_date'] = pd.to_numeric(cal_df['cal_date'], errors='coerce')
            end_date_int = int(trade_date) if isinstance(trade_date, str) else trade_date
            cal_df = cal_df[cal_df['cal_date'] <= end_date_int]
            
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å»é‡
            trading_dates = cal_df['cal_date'].astype(str).unique().tolist()
            trading_dates = list(dict.fromkeys(trading_dates))  # ä¿æŒé¡ºåºçš„å»é‡
            
            if len(trading_dates) >= 2:
                # è¿”å›å‰ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆç¬¬äºŒä¸ªï¼‰
                return trading_dates[1]
            elif len(trading_dates) == 1:
                # åªæœ‰ä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œè¯´æ˜å¯èƒ½æ˜¯ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œæ— æ³•è·å–å‰ä¸€ä¸ª
                return None
        return None
    except Exception as e:
        return None


def _analyze_market_volume(trade_date: str) -> Dict[str, Any]:
    """
    æ¨¡å—1: å¸‚åœºé‡èƒ½åˆ¤å®š (å…¨å£å¾„)
    
    å·¥å…·: ä¸Šè¯æŒ‡æ•°(000001.SH) + æ·±è¯æˆæŒ‡(399001.SZ)
    è®¡ç®—: ä»Šæ—¥æ€»æˆäº¤é¢ = ä¸Šè¯amount + æ·±è¯amount
    å¯¹æ¯”: (ä»Šæ—¥æ€»é¢ / æ˜¨æ—¥æ€»é¢) - 1
    """
    result = {
        "success": False,
        "today_amount": 0,
        "yesterday_amount": 0,
        "sh_amount": 0,
        "sz_amount": 0,
        "change_pct": 0,
        "diagnosis": "",
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        
        # ä½¿ç”¨äº¤æ˜“æ—¥å†è·å–å‰ä¸€ä¸ªäº¤æ˜“æ—¥
        yesterday_date = _get_previous_trading_date(trade_date)
        if not yesterday_date:
            result["error"] = f"æ— æ³•è·å– {trade_date} çš„å‰ä¸€ä¸ªäº¤æ˜“æ—¥"
            return result
        
        # è·å–ä¸Šè¯æŒ‡æ•°ä»Šæ—¥æ•°æ®
        sh_today_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="000001.SH",
            trade_date=trade_date
        )
        if sh_today_df is None or sh_today_df.empty:
            sh_today_df = pro.index_daily(ts_code="000001.SH", trade_date=trade_date)
            if not sh_today_df.empty:
                index_daily_cache_manager.save_index_daily_data(sh_today_df)
        
        # è·å–ä¸Šè¯æŒ‡æ•°æ˜¨æ—¥æ•°æ®
        sh_yesterday_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="000001.SH",
            trade_date=yesterday_date
        )
        if sh_yesterday_df is None or sh_yesterday_df.empty:
            sh_yesterday_df = pro.index_daily(ts_code="000001.SH", trade_date=yesterday_date)
            if not sh_yesterday_df.empty:
                index_daily_cache_manager.save_index_daily_data(sh_yesterday_df)
        
        # è·å–æ·±è¯æˆæŒ‡ä»Šæ—¥æ•°æ®
        sz_today_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="399001.SZ",
            trade_date=trade_date
        )
        if sz_today_df is None or sz_today_df.empty:
            sz_today_df = pro.index_daily(ts_code="399001.SZ", trade_date=trade_date)
            if not sz_today_df.empty:
                index_daily_cache_manager.save_index_daily_data(sz_today_df)
        
        # è·å–æ·±è¯æˆæŒ‡æ˜¨æ—¥æ•°æ®
        sz_yesterday_df = index_daily_cache_manager.get_index_daily_data(
            ts_code="399001.SZ",
            trade_date=yesterday_date
        )
        if sz_yesterday_df is None or sz_yesterday_df.empty:
            sz_yesterday_df = pro.index_daily(ts_code="399001.SZ", trade_date=yesterday_date)
            if not sz_yesterday_df.empty:
                index_daily_cache_manager.save_index_daily_data(sz_yesterday_df)
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å®Œæ•´
        if (sh_today_df is None or sh_today_df.empty or 
            sh_yesterday_df is None or sh_yesterday_df.empty or
            sz_today_df is None or sz_today_df.empty or
            sz_yesterday_df is None or sz_yesterday_df.empty):
            result["error"] = "æ— æ³•è·å–å®Œæ•´çš„æŒ‡æ•°æ•°æ®"
            return result
        
        # è®¡ç®—ä»Šæ—¥å’Œæ˜¨æ—¥æˆäº¤é¢ (amount å•ä½ä¸ºåƒå…ƒ)
        sh_today = float(sh_today_df.iloc[0]['amount']) if pd.notna(sh_today_df.iloc[0]['amount']) else 0
        sh_yesterday = float(sh_yesterday_df.iloc[0]['amount']) if pd.notna(sh_yesterday_df.iloc[0]['amount']) else 0
        sz_today = float(sz_today_df.iloc[0]['amount']) if pd.notna(sz_today_df.iloc[0]['amount']) else 0
        sz_yesterday = float(sz_yesterday_df.iloc[0]['amount']) if pd.notna(sz_yesterday_df.iloc[0]['amount']) else 0
        
        today_total = sh_today + sz_today
        yesterday_total = sh_yesterday + sz_yesterday
        
        # è®¡ç®—å˜åŒ–ç‡
        if yesterday_total > 0:
            change_pct = (today_total / yesterday_total - 1) * 100
        else:
            change_pct = 0
        
        # è·å–æ—¥æœŸä¿¡æ¯
        sh_today_date = str(sh_today_df.iloc[0]['trade_date']) if pd.notna(sh_today_df.iloc[0]['trade_date']) else trade_date
        sh_yesterday_date = str(sh_yesterday_df.iloc[0]['trade_date']) if pd.notna(sh_yesterday_df.iloc[0]['trade_date']) else yesterday_date
        
        # è½¬æ¢ä¸ºäº¿å…ƒ
        sh_amount_yuan = sh_today / 10000  # è½¬æ¢ä¸ºäº¿å…ƒ
        sz_amount_yuan = sz_today / 10000
        today_amount_yuan = today_total / 10000
        yesterday_amount_yuan = yesterday_total / 10000
        
        # è®¾ç½®æ•°æ®å­—æ®µï¼ˆæ— è®ºéªŒè¯æ˜¯å¦é€šè¿‡éƒ½å…ˆè®¾ç½®ï¼Œç¡®ä¿èƒ½æ˜¾ç¤ºæ•°æ®ï¼‰
        result["sh_amount"] = sh_amount_yuan
        result["sz_amount"] = sz_amount_yuan
        result["today_amount"] = today_amount_yuan
        result["yesterday_amount"] = yesterday_amount_yuan
        result["change_pct"] = change_pct
        result["today_date"] = sh_today_date
        result["yesterday_date"] = sh_yesterday_date
        
        # æ•°æ®éªŒè¯ï¼šä»…ä½œä¸ºè­¦å‘Šï¼Œä¸å½±å“æ•°æ®å±•ç¤º
        # ç§»é™¤ä¸¥æ ¼çš„èŒƒå›´é™åˆ¶ï¼Œå› ä¸ºå®é™…å¸‚åœºæˆäº¤é¢å¯èƒ½è¶…å‡ºé¢„æœŸèŒƒå›´
        result["success"] = True
        
        # è¯Šæ–­
        if change_pct > 10:
            result["diagnosis"] = "ğŸ“ˆ æ˜¾è‘—æ”¾é‡"
        elif change_pct > 0:
            result["diagnosis"] = "ğŸ“ˆ æ¸©å’Œæ”¾é‡"
        elif change_pct > -10:
            result["diagnosis"] = "ğŸ“‰ æ¸©å’Œç¼©é‡"
        else:
            result["diagnosis"] = "ğŸ“‰ æ˜¾è‘—ç¼©é‡"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _analyze_style_and_profit_effect(trade_date: str) -> Dict[str, Any]:
    """
    æ¨¡å—2: é£æ ¼ä¸èµšé’±æ•ˆåº” (å¤§å°ç›˜å‰ªåˆ€å·®)
    
    å·¥å…·: æ²ªæ·±300(000300.SH), å›½è¯2000(399303.SZ), ç§‘åˆ›50(000688.SH)
    é€»è¾‘:
        300â†‘ + 2000â†‘ = å…¨é¢åšå¤š
        300â†‘ + 2000â†“ = åªèµšæŒ‡æ•°ï¼ˆè°¨æ…ï¼‰
        300â†“ + 2000â†‘ = é¢˜ææ´»è·ƒï¼ˆè½»æŒ‡æ•°é‡ä¸ªè‚¡ï¼‰
        300â†“ + 2000â†“ = å…¨é¢é€€æ½®
    """
    result = {
        "success": False,
        "hs300": {"pct_chg": 0, "close": 0},
        "gz2000": {"pct_chg": 0, "close": 0},
        "kc50": {"pct_chg": 0, "close": 0},
        "diagnosis": "",
        "diagnosis_detail": "",
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        index_codes = ["000300.SH", "399303.SZ", "000688.SH"]
        index_data = {}
        
        for code in index_codes:
            df = index_daily_cache_manager.get_index_daily_data(
                ts_code=code,
                trade_date=trade_date
            )
            
            if df is None or df.empty:
                df = pro.index_daily(ts_code=code, trade_date=trade_date)
                if not df.empty:
                    index_daily_cache_manager.save_index_daily_data(df)
            
            if df is not None and not df.empty:
                index_data[code] = {
                    "pct_chg": float(df.iloc[0]['pct_chg']) if pd.notna(df.iloc[0]['pct_chg']) else 0,
                    "close": float(df.iloc[0]['close']) if pd.notna(df.iloc[0]['close']) else 0
                }
            else:
                index_data[code] = {"pct_chg": 0, "close": 0}
        
        result["success"] = True
        result["hs300"] = index_data.get("000300.SH", {"pct_chg": 0, "close": 0})
        result["gz2000"] = index_data.get("399303.SZ", {"pct_chg": 0, "close": 0})
        result["kc50"] = index_data.get("000688.SH", {"pct_chg": 0, "close": 0})
        
        hs300_up = result["hs300"]["pct_chg"] > 0
        gz2000_up = result["gz2000"]["pct_chg"] > 0
        
        # è¯Šæ–­é€»è¾‘
        if hs300_up and gz2000_up:
            result["diagnosis"] = "ğŸŸ¢ å…¨é¢åšå¤š"
            result["diagnosis_detail"] = "å¤§å°ç›˜å…±æŒ¯ä¸Šæ¶¨"
        elif hs300_up and not gz2000_up:
            result["diagnosis"] = "ğŸŸ¡ åªèµšæŒ‡æ•°"
            result["diagnosis_detail"] = "æƒé‡æŠ¤ç›˜ï¼Œé¢˜æé€€æ½®ï¼Œè°¨æ…æ“ä½œ"
        elif not hs300_up and gz2000_up:
            result["diagnosis"] = "ğŸ”µ é¢˜ææ´»è·ƒ"
            result["diagnosis_detail"] = "è½»æŒ‡æ•°é‡ä¸ªè‚¡ï¼Œå°ç›˜è‚¡æ´»è·ƒ"
        else:
            result["diagnosis"] = "ğŸ”´ å…¨é¢é€€æ½®"
            result["diagnosis_detail"] = "å¤§å°ç›˜å…±æŒ¯ä¸‹è·Œ"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _analyze_sentiment_extremes(
    trade_date: str,
    seal_rate_warning: float,
    limit_down_warning: int,
    style_result: Dict[str, Any]
) -> Dict[str, Any]:
    """
    æ¨¡å—3: æƒ…ç»ªæå€¼æ¢æµ‹
    
    å·¥å…·: get_limit_list(limit_type='U'/'Z'/'D')
    è®¡ç®—: å°æ¿ç‡ = æ¶¨åœæ•° / (æ¶¨åœæ•° + ç‚¸æ¿æ•°)
    å†°ç‚¹æœŸåˆ¤å®š: è·Œåœå®¶æ•° > 20 ä¸” å›½è¯2000 ä¸‹è·Œ
    """
    result = {
        "success": False,
        "limit_up_count": 0,
        "limit_failed_count": 0,
        "limit_down_count": 0,
        "seal_rate": 0,
        "is_ice_period": False,
        "diagnosis": "",
        "warning": None,
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        
        # è·å–æ¶¨åœæ•°æ®
        up_df = pro.limit_list_d(trade_date=trade_date, limit_type='U')
        limit_up_count = len(up_df) if up_df is not None else 0
        
        # è·å–ç‚¸æ¿æ•°æ®
        failed_df = pro.limit_list_d(trade_date=trade_date, limit_type='Z')
        limit_failed_count = len(failed_df) if failed_df is not None else 0
        
        # è·å–è·Œåœæ•°æ®
        down_df = pro.limit_list_d(trade_date=trade_date, limit_type='D')
        limit_down_count = len(down_df) if down_df is not None else 0
        
        # è®¡ç®—å°æ¿ç‡
        if limit_up_count + limit_failed_count > 0:
            seal_rate = limit_up_count / (limit_up_count + limit_failed_count) * 100
        else:
            seal_rate = 0
        
        result["success"] = True
        result["limit_up_count"] = limit_up_count
        result["limit_failed_count"] = limit_failed_count
        result["limit_down_count"] = limit_down_count
        result["seal_rate"] = seal_rate
        
        # å†°ç‚¹æœŸåˆ¤å®šï¼šè·Œåœå®¶æ•° > é˜ˆå€¼ ä¸” å›½è¯2000 ä¸‹è·Œ
        gz2000_down = style_result.get("gz2000", {}).get("pct_chg", 0) < 0
        if limit_down_count > limit_down_warning and gz2000_down:
            result["is_ice_period"] = True
            result["warning"] = "ğŸ”´ã€å†°ç‚¹æœŸã€‘è·Œåœå®¶æ•°è¿‡å¤šä¸”å°ç›˜è‚¡ä¸‹è·Œ"
        
        # è¯Šæ–­
        if seal_rate < seal_rate_warning:
            result["diagnosis"] = "âš ï¸ å°æ¿ç‡åä½"
            if result["warning"] is None:
                result["warning"] = f"å°æ¿ç‡ä½äº {seal_rate_warning}%"
        elif seal_rate >= 80:
            result["diagnosis"] = "ğŸŸ¢ å¸‚åœºæƒ…ç»ªæ´»è·ƒ"
        else:
            result["diagnosis"] = "ğŸŸ¡ å¸‚åœºæƒ…ç»ªä¸€èˆ¬"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _analyze_external_validation(trade_date: str) -> Dict[str, Any]:
    """
    æ¨¡å—4: å¤–éƒ¨éªŒè¯ (ETFæŠ˜ç®—)
    
    å·¥å…·: çº³æŒ‡ETF(513100.SH), ä¸­æ¦‚äº’è”ETF(513050.SH)
    é€»è¾‘: é€šè¿‡åœºå†…ETFæ¶¨è·Œï¼Œåæ¨å¤–å›´ç¯å¢ƒå¯¹Aè‚¡ä»Šæ—¥æƒ…ç»ªçš„å®é™…æ‰°åŠ¨
    """
    result = {
        "success": False,
        "nasdaq_etf": {"pct_chg": 0, "close": 0},
        "china_internet_etf": {"pct_chg": 0, "close": 0},
        "diagnosis": "",
        "error": None
    }
    
    try:
        pro = ts.pro_api()
        etf_codes = ["513100.SH", "513050.SH"]
        etf_data = {}
        
        for code in etf_codes:
            # ETF ä½¿ç”¨ fund_daily æ¥å£
            df = pro.fund_daily(ts_code=code, trade_date=trade_date)
            
            if df is not None and not df.empty:
                etf_data[code] = {
                    "pct_chg": float(df.iloc[0]['pct_chg']) if pd.notna(df.iloc[0].get('pct_chg')) else 0,
                    "close": float(df.iloc[0]['close']) if pd.notna(df.iloc[0]['close']) else 0
                }
            else:
                etf_data[code] = {"pct_chg": 0, "close": 0}
        
        result["success"] = True
        result["nasdaq_etf"] = etf_data.get("513100.SH", {"pct_chg": 0, "close": 0})
        result["china_internet_etf"] = etf_data.get("513050.SH", {"pct_chg": 0, "close": 0})
        
        # è¯Šæ–­
        avg_pct = (result["nasdaq_etf"]["pct_chg"] + result["china_internet_etf"]["pct_chg"]) / 2
        if avg_pct > 1:
            result["diagnosis"] = "ğŸŸ¢ å¤–ç›˜ç¯å¢ƒç§¯æ"
        elif avg_pct > -1:
            result["diagnosis"] = "ğŸŸ¢ å¤–ç›˜å¹²æ‰°æœ‰é™"
        else:
            result["diagnosis"] = "ğŸ”´ å¤–ç›˜æ‹–ç´¯æ˜æ˜¾"
            
    except Exception as e:
        result["error"] = str(e)
    
    return result


def _format_macro_scan_report(
    trade_date: str,
    volume_result: Dict[str, Any],
    style_result: Dict[str, Any],
    sentiment_result: Dict[str, Any],
    external_result: Dict[str, Any]
) -> str:
    """æ ¼å¼åŒ–å®è§‚å…¨æ™¯æ‰«ææŠ¥å‘Š"""
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    formatted_date = f"{trade_date[:4]}-{trade_date[4:6]}-{trade_date[6:8]}" if len(trade_date) == 8 else trade_date
    
    lines = []
    lines.append("ğŸ“Š å®è§‚å…¨æ™¯æ‰«ææŠ¥å‘Š")
    lines.append("=" * 50)
    lines.append(f"ğŸ“… åˆ†ææ—¥æœŸ: {formatted_date}")
    lines.append("")
    
    # æ¨¡å—1: å¸‚åœºé‡èƒ½åˆ¤å®š
    lines.append("ã€ä¸€ã€å¸‚åœºé‡èƒ½åˆ¤å®šã€‘")
    if volume_result["success"]:
        today_date = volume_result.get('today_date', '')
        yesterday_date = volume_result.get('yesterday_date', '')
        
        # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
        if today_date and len(today_date) == 8:
            today_date_fmt = f"{today_date[:4]}-{today_date[4:6]}-{today_date[6:8]}"
        else:
            today_date_fmt = today_date
        
        if yesterday_date and len(yesterday_date) == 8:
            yesterday_date_fmt = f"{yesterday_date[:4]}-{yesterday_date[4:6]}-{yesterday_date[6:8]}"
        else:
            yesterday_date_fmt = yesterday_date
        
        lines.append(f"- ä»Šæ—¥({today_date_fmt})æ€»æˆäº¤é¢: {volume_result['today_amount']:.2f} äº¿å…ƒ")
        lines.append(f"  â€¢ ä¸Šè¯: {volume_result['sh_amount']:.2f} äº¿å…ƒ")
        lines.append(f"  â€¢ æ·±è¯: {volume_result['sz_amount']:.2f} äº¿å…ƒ")
        lines.append(f"- æ˜¨æ—¥({yesterday_date_fmt})æ€»æˆäº¤é¢: {volume_result['yesterday_amount']:.2f} äº¿å…ƒ")
        change_sign = "+" if volume_result['change_pct'] >= 0 else ""
        lines.append(f"- å˜åŒ–: {volume_result['diagnosis']} {change_sign}{volume_result['change_pct']:.1f}%")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {volume_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # æ¨¡å—2: é£æ ¼ä¸èµšé’±æ•ˆåº”
    lines.append("ã€äºŒã€é£æ ¼ä¸èµšé’±æ•ˆåº”ã€‘")
    if style_result["success"]:
        lines.append("| æŒ‡æ•°       | æ¶¨è·Œå¹…        | æ”¶ç›˜ç‚¹ä½     |")
        lines.append("|-----------|--------------|-------------|")
        
        hs300 = style_result["hs300"]
        gz2000 = style_result["gz2000"]
        kc50 = style_result["kc50"]
        
        lines.append(f"| æ²ªæ·±300   | {hs300['pct_chg']:+.2f}%      | {hs300['close']:.2f}      |")
        lines.append(f"| å›½è¯2000  | {gz2000['pct_chg']:+.2f}%      | {gz2000['close']:.2f}      |")
        lines.append(f"| ç§‘åˆ›50    | {kc50['pct_chg']:+.2f}%      | {kc50['close']:.2f}      |")
        lines.append(f"- è¯Šæ–­: {style_result['diagnosis']}ï¼ˆ{style_result['diagnosis_detail']}ï¼‰")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {style_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # æ¨¡å—3: æƒ…ç»ªæå€¼æ¢æµ‹
    lines.append("ã€ä¸‰ã€æƒ…ç»ªæå€¼æ¢æµ‹ã€‘")
    if sentiment_result["success"]:
        lines.append(f"- æ¶¨åœå®¶æ•°: {sentiment_result['limit_up_count']}")
        lines.append(f"- ç‚¸æ¿å®¶æ•°: {sentiment_result['limit_failed_count']}")
        lines.append(f"- è·Œåœå®¶æ•°: {sentiment_result['limit_down_count']}")
        lines.append(f"- å°æ¿ç‡: {sentiment_result['seal_rate']:.1f}%")
        lines.append(f"- è¯Šæ–­: {sentiment_result['diagnosis']}")
        if sentiment_result["warning"]:
            lines.append(f"- é¢„è­¦: {sentiment_result['warning']}")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {sentiment_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # æ¨¡å—4: å¤–éƒ¨éªŒè¯
    lines.append("ã€å››ã€å¤–éƒ¨éªŒè¯ã€‘")
    if external_result["success"]:
        lines.append("| ETF           | æ¶¨è·Œå¹…        | æ”¶ç›˜ä»·       |")
        lines.append("|--------------|--------------|-------------|")
        
        nasdaq = external_result["nasdaq_etf"]
        china_internet = external_result["china_internet_etf"]
        
        lines.append(f"| çº³æŒ‡ETF      | {nasdaq['pct_chg']:+.2f}%      | {nasdaq['close']:.3f}      |")
        lines.append(f"| ä¸­æ¦‚äº’è”     | {china_internet['pct_chg']:+.2f}%      | {china_internet['close']:.3f}      |")
        lines.append(f"- è¯Šæ–­: {external_result['diagnosis']}")
    else:
        lines.append(f"- âš ï¸ æ•°æ®è·å–å¤±è´¥: {external_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    lines.append("")
    
    # ç»¼åˆè¯Šæ–­
    lines.append("=" * 50)
    lines.append("ç»¼åˆè¯Šæ–­")
    lines.append("=" * 50)
    
    # ç»¼åˆè¯„ä¼°
    overall_score = 0
    issues = []
    
    if volume_result["success"]:
        if volume_result["change_pct"] > 0:
            overall_score += 1
        else:
            issues.append("é‡èƒ½èç¼©")
    
    if style_result["success"]:
        if style_result["diagnosis"].startswith("ğŸŸ¢"):
            overall_score += 2
        elif style_result["diagnosis"].startswith("ğŸ”µ"):
            overall_score += 1
        elif style_result["diagnosis"].startswith("ğŸ”´"):
            overall_score -= 1
            issues.append("å…¨é¢é€€æ½®")
    
    if sentiment_result["success"]:
        if sentiment_result["is_ice_period"]:
            overall_score -= 2
            issues.append("å†°ç‚¹æœŸ")
        elif sentiment_result["seal_rate"] >= 70:
            overall_score += 1
        elif sentiment_result["seal_rate"] < 60:
            issues.append("å°æ¿ç‡åä½")
    
    if external_result["success"]:
        avg_pct = (external_result["nasdaq_etf"]["pct_chg"] + external_result["china_internet_etf"]["pct_chg"]) / 2
        if avg_pct < -1:
            issues.append("å¤–ç›˜æ‹–ç´¯")
    
    # è¾“å‡ºç»¼åˆè¯„ä¼°
    if overall_score >= 3:
        lines.append("ğŸŸ¢ å¸‚åœºæ•´ä½“ã€å¥åº·ã€‘")
    elif overall_score >= 1:
        lines.append("ğŸŸ¡ å¸‚åœºæ•´ä½“ã€è°¨æ…ä¹è§‚ã€‘")
    elif overall_score >= -1:
        lines.append("ğŸŸ¡ å¸‚åœºæ•´ä½“ã€éœ‡è¡åˆ†åŒ–ã€‘")
    else:
        lines.append("ğŸ”´ å¸‚åœºæ•´ä½“ã€é«˜é£é™©ã€‘")
    
    if issues:
        lines.append(f"- ä¸»è¦å…³æ³¨ç‚¹: {', '.join(issues)}")
    
    return "\n".join(lines)
