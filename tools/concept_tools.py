"""æ¦‚å¿µæ¿å—ç›¸å…³MCPå·¥å…·"""
import tushare as ts
import pandas as pd
import numpy as np
import json
from typing import TYPE_CHECKING, Optional, List, Dict
from datetime import datetime, timedelta

if TYPE_CHECKING:
    from mcp.server.fastmcp import FastMCP

from config.token_manager import get_tushare_token
from cache.concept_cache_manager import concept_cache_manager
from cache.cache_manager import cache_manager
from tools.alpha_strategy_analyzer import (
    analyze_sector_alpha,
    rank_sectors_alpha,
    format_alpha_analysis,
    calculate_alpha_rank_velocity
)
from utils.common import format_date

# è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†numpyç±»å‹
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, (np.integer, np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64, np.float32)):
            return float(obj)
        elif isinstance(obj, (np.bool_, bool)):
            return bool(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(NumpyEncoder, self).default(obj)

def format_concept_data(df: pd.DataFrame, include_header: bool = False) -> str:
    """
    æ ¼å¼åŒ–æ¦‚å¿µæ¿å—æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ¦‚å¿µæ¿å—æ•°æ®DataFrame
        include_header: æ˜¯å¦åŒ…å«æ ‡é¢˜ï¼ˆé»˜è®¤Falseï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¦‚å¿µæ¿å—æ•°æ®"
    
    # æŒ‰æ¶¨è·Œå¹…æ’åºï¼ˆé™åºï¼‰
    if 'pct_change' in df.columns:
        df = df.sort_values('pct_change', ascending=False)
    
    result = []
    if include_header:
        result.append("ğŸ“Š ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—æ•°æ®")
        result.append("=" * 120)
        result.append("")
    
    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    result.append(f"ğŸ“ˆ å…±æ‰¾åˆ° {len(df)} ä¸ªæ¦‚å¿µæ¿å—")
    result.append("")
    
    # è¡¨å¤´
    result.append(f"{'æ¦‚å¿µä»£ç ':<15} {'æ¦‚å¿µåç§°':<20} {'æ¶¨è·Œå¹…':<10} {'é¢†æ¶¨è‚¡ç¥¨':<15} {'é¢†æ¶¨æ¶¨è·Œå¹…':<12} {'æ€»å¸‚å€¼(ä¸‡å…ƒ)':<15} {'æ¢æ‰‹ç‡':<10} {'ä¸Šæ¶¨/ä¸‹è·Œ':<12}")
    result.append("-" * 120)
    
    for _, row in df.iterrows():
        # æ¦‚å¿µä»£ç 
        ts_code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
        
        # æ¦‚å¿µåç§°
        name = str(row['name'])[:18] if 'name' in row and pd.notna(row['name']) else "-"
        
        # æ¶¨è·Œå¹…
        pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
        
        # é¢†æ¶¨è‚¡ç¥¨
        leading = str(row['leading'])[:13] if 'leading' in row and pd.notna(row['leading']) else "-"
        
        # é¢†æ¶¨è‚¡ç¥¨æ¶¨è·Œå¹…
        leading_pct = f"{row['leading_pct']:+.2f}%" if 'leading_pct' in row and pd.notna(row['leading_pct']) else "-"
        
        # æ€»å¸‚å€¼
        total_mv = f"{row['total_mv']:,.0f}" if 'total_mv' in row and pd.notna(row['total_mv']) else "-"
        
        # æ¢æ‰‹ç‡
        turnover_rate = f"{row['turnover_rate']:.2f}%" if 'turnover_rate' in row and pd.notna(row['turnover_rate']) else "-"
        
        # ä¸Šæ¶¨/ä¸‹è·Œå®¶æ•°
        up_num = int(row['up_num']) if 'up_num' in row and pd.notna(row['up_num']) else 0
        down_num = int(row['down_num']) if 'down_num' in row and pd.notna(row['down_num']) else 0
        up_down = f"{up_num}/{down_num}"
        
        result.append(f"{ts_code:<15} {name:<20} {pct_change:<10} {leading:<15} {leading_pct:<12} {total_mv:<15} {turnover_rate:<10} {up_down:<12}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    result.append("")
    result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    
    if 'pct_change' in df.columns:
        # æ¶¨è·Œå¹…ç»Ÿè®¡
        positive_count = len(df[df['pct_change'] > 0])
        negative_count = len(df[df['pct_change'] < 0])
        flat_count = len(df[df['pct_change'] == 0])
        result.append(f"  - ä¸Šæ¶¨æ¿å—: {positive_count} ä¸ª")
        result.append(f"  - ä¸‹è·Œæ¿å—: {negative_count} ä¸ª")
        result.append(f"  - å¹³ç›˜æ¿å—: {flat_count} ä¸ª")
        
        # æ¶¨è·Œå¹…èŒƒå›´
        if not df['pct_change'].isna().all():
            max_pct = df['pct_change'].max()
            min_pct = df['pct_change'].min()
            result.append(f"  - æœ€å¤§æ¶¨è·Œå¹…: {max_pct:+.2f}%")
            result.append(f"  - æœ€å°æ¶¨è·Œå¹…: {min_pct:+.2f}%")
    
    if 'turnover_rate' in df.columns:
        # æ¢æ‰‹ç‡ç»Ÿè®¡
        if not df['turnover_rate'].isna().all():
            avg_turnover = df['turnover_rate'].mean()
            result.append(f"  - å¹³å‡æ¢æ‰‹ç‡: {avg_turnover:.2f}%")
    
    if 'total_mv' in df.columns:
        # æ€»å¸‚å€¼ç»Ÿè®¡
        if not df['total_mv'].isna().all():
            total_market_value = df['total_mv'].sum()
            result.append(f"  - æ€»å¸‚å€¼åˆè®¡: {total_market_value:,.0f} ä¸‡å…ƒ")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—")
    result.append("  - æ€»å¸‚å€¼å•ä½ï¼šä¸‡å…ƒ")
    result.append("  - æ¢æ‰‹ç‡ï¼šåæ˜ æ¿å—æ´»è·ƒåº¦")
    result.append("  - ä¸Šæ¶¨/ä¸‹è·Œï¼šä¸Šæ¶¨å®¶æ•°/ä¸‹è·Œå®¶æ•°")
    
    return "\n".join(result)

def format_concept_member_data(df: pd.DataFrame, show_date: bool = True, show_concept: bool = True) -> str:
    """
    æ ¼å¼åŒ–æ¦‚å¿µæ¿å—æˆåˆ†æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ¦‚å¿µæ¿å—æˆåˆ†æ•°æ®DataFrame
        show_date: æ˜¯å¦æ˜¾ç¤ºäº¤æ˜“æ—¥æœŸåˆ—ï¼ˆé»˜è®¤Trueï¼‰
        show_concept: æ˜¯å¦æ˜¾ç¤ºæ¦‚å¿µä»£ç åˆ—ï¼ˆé»˜è®¤Trueï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¦‚å¿µæ¿å—æˆåˆ†æ•°æ®"
    
    result = []
    result.append(f"ğŸ“ˆ å…±æ‰¾åˆ° {len(df)} åªæˆåˆ†è‚¡")
    result.append("")
    
    # æ ¹æ®å‚æ•°å†³å®šè¡¨å¤´
    if show_date and show_concept:
        # è¡¨å¤´ï¼šæ˜¾ç¤ºæ‰€æœ‰åˆ—
        result.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'æ¦‚å¿µä»£ç ':<15} {'æˆåˆ†ä»£ç ':<15} {'æˆåˆ†è‚¡åç§°':<20}")
        result.append("-" * 80)
        
        for _, row in df.iterrows():
            trade_date = format_date(str(row['trade_date'])) if 'trade_date' in row and pd.notna(row['trade_date']) else "-"
            ts_code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
            con_code = str(row['con_code']) if 'con_code' in row and pd.notna(row['con_code']) else "-"
            name = str(row['name'])[:18] if 'name' in row and pd.notna(row['name']) else "-"
            result.append(f"{trade_date:<12} {ts_code:<15} {con_code:<15} {name:<20}")
    elif show_concept:
        # è¡¨å¤´ï¼šä¸æ˜¾ç¤ºæ—¥æœŸ
        result.append(f"{'æ¦‚å¿µä»£ç ':<15} {'æˆåˆ†ä»£ç ':<15} {'æˆåˆ†è‚¡åç§°':<20}")
        result.append("-" * 60)
        
        for _, row in df.iterrows():
            ts_code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
            con_code = str(row['con_code']) if 'con_code' in row and pd.notna(row['con_code']) else "-"
            name = str(row['name'])[:18] if 'name' in row and pd.notna(row['name']) else "-"
            result.append(f"{ts_code:<15} {con_code:<15} {name:<20}")
    else:
        # è¡¨å¤´ï¼šåªæ˜¾ç¤ºæˆåˆ†ä»£ç å’Œåç§°
        result.append(f"{'æˆåˆ†ä»£ç ':<15} {'æˆåˆ†è‚¡åç§°':<20}")
        result.append("-" * 40)
        
        for _, row in df.iterrows():
            con_code = str(row['con_code']) if 'con_code' in row and pd.notna(row['con_code']) else "-"
            name = str(row['name'])[:18] if 'name' in row and pd.notna(row['name']) else "-"
            result.append(f"{con_code:<15} {name:<20}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    result.append("")
    result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    
    # æŒ‰æ¦‚å¿µä»£ç åˆ†ç»„ç»Ÿè®¡
    if 'ts_code' in df.columns:
        concept_count = df['ts_code'].nunique()
        if concept_count > 1:
            result.append(f"  - æ¶‰åŠæ¦‚å¿µæ¿å—: {concept_count} ä¸ª")
    
    # æŒ‰äº¤æ˜“æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
    if 'trade_date' in df.columns:
        date_count = df['trade_date'].nunique()
        if date_count > 1:
            result.append(f"  - æ¶‰åŠäº¤æ˜“æ—¥æœŸ: {date_count} ä¸ª")
    
    # æˆåˆ†è‚¡ç»Ÿè®¡
    if 'con_code' in df.columns:
        stock_count = df['con_code'].nunique()
        result.append(f"  - æˆåˆ†è‚¡æ•°é‡: {stock_count} åª")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œæ¿å—æˆåˆ†")
    result.append("  - å¯ä»¥æ ¹æ®æ¦‚å¿µæ¿å—ä»£ç å’Œäº¤æ˜“æ—¥æœŸï¼Œè·å–å†å²æˆåˆ†")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§è·å–5000æ¡æ•°æ®ï¼Œå¯ä»¥é€šè¿‡æ—¥æœŸå’Œä»£ç å¾ªç¯è·å–")
    
    return "\n".join(result)

def get_concept_codes(trade_date: str = None) -> List[str]:
    """
    è·å–æ‰€æœ‰ä¸œè´¢æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨
    
    å‚æ•°:
        trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
    
    è¿”å›:
        æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨
    """
    token = get_tushare_token()
    if not token:
        return []
    
    if trade_date is None:
        trade_date = datetime.now().strftime('%Y%m%d')
    
    try:
        # ä¼˜å…ˆä»ç¼“å­˜è·å–æ•°æ®
        df = concept_cache_manager.get_concept_index_data(trade_date=trade_date)
        
        # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œä»APIè·å–
        if df is None or df.empty:
            pro = ts.pro_api()
            df = pro.dc_index(trade_date=trade_date)
            # ä¿å­˜åˆ°ç¼“å­˜
            if not df.empty:
                concept_cache_manager.save_concept_index_data(df)
        
        if df.empty:
            return []
        
        # æå–å”¯ä¸€çš„æ¿å—ä»£ç 
        if 'ts_code' in df.columns:
            codes = df['ts_code'].unique().tolist()
            return sorted(codes)
        
        return []
    except Exception as e:
        print(f"è·å–æ¦‚å¿µæ¿å—ä»£ç å¤±è´¥: {str(e)}", file=__import__('sys').stderr)
        return []

def format_concept_alpha_analysis(df: pd.DataFrame) -> str:
    """
    æ ¼å¼åŒ–æ¦‚å¿µæ¿å—Alphaåˆ†æç»“æœï¼ˆåŒ…å«æ¿å—åç§°ï¼‰
    
    å‚æ•°:
        df: Alphaåˆ†æç»“æœDataFrameï¼Œåº”åŒ…å«nameã€pct_changeç­‰å­—æ®µ
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ†æç»“æœ"
    
    result = []
    result.append("ğŸ“Š ç›¸å¯¹å¼ºåº¦Alphaæ¨¡å‹åˆ†æç»“æœ")
    result.append("=" * 150)
    result.append("")
    result.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<12} {'æ¿å—åç§°':<20} {'2æ—¥Alpha':<12} {'5æ—¥Alpha':<12} {'ç»¼åˆå¾—åˆ†':<12} {'2æ—¥æ”¶ç›Š':<12} {'5æ—¥æ”¶ç›Š':<12} {'ä»Šæ—¥æ¶¨è·Œ':<10} {'æ¢æ‰‹ç‡':<10}")
    result.append("-" * 150)
    
    for _, row in df.iterrows():
        rank = f"{int(row['rank'])}"
        sector_code = row['sector_code']
        name = str(row.get('name', sector_code))[:18] if 'name' in row else sector_code
        alpha_2 = f"{row['alpha_2']*100:.2f}%" if pd.notna(row['alpha_2']) else "-"
        alpha_5 = f"{row['alpha_5']*100:.2f}%" if pd.notna(row['alpha_5']) else "-"
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        if pd.notna(row.get('score')):
            score = f"{row['score']*100:.2f}%"
        elif pd.notna(row['alpha_2']):
            score = f"{row['alpha_2']*100:.2f}%"
        else:
            score = "-"
        
        r_2 = f"{row['r_sector_2']*100:.2f}%" if pd.notna(row['r_sector_2']) else "-"
        r_5 = f"{row['r_sector_5']*100:.2f}%" if pd.notna(row['r_sector_5']) else "-"
        
        # ä»Šæ—¥æ¶¨è·Œå¹…
        pct_change = f"{row.get('pct_change', 0):.2f}%" if 'pct_change' in row and pd.notna(row.get('pct_change')) else "-"
        
        # æ¢æ‰‹ç‡
        turnover = f"{row.get('turnover', 0):.2f}%" if 'turnover' in row and pd.notna(row.get('turnover')) else "-"
        
        result.append(f"{rank:<6} {sector_code:<12} {name:<20} {alpha_2:<12} {alpha_5:<12} {score:<12} {r_2:<12} {r_5:<12} {pct_change:<10} {turnover:<10}")
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - Alpha = æ¿å—æ”¶ç›Šç‡ - åŸºå‡†æ”¶ç›Šç‡ï¼ˆæ²ªæ·±300ï¼‰")
    result.append("  - ç»¼åˆå¾—åˆ† = Alpha_2 Ã— 60% + Alpha_5 Ã— 40%ï¼ˆå¦‚æœ5æ—¥æ•°æ®ä¸è¶³ï¼Œåˆ™ä»…ä½¿ç”¨2æ—¥Alphaï¼‰")
    result.append("  - å¾—åˆ†è¶Šé«˜ï¼Œè¡¨ç¤ºæ¿å—ç›¸å¯¹å¤§ç›˜è¶Šå¼ºåŠ¿")
    result.append("  - å»ºè®®å…³æ³¨å¾—åˆ†å‰5-10åçš„æ¿å—")
    result.append("")
    result.append(f"ğŸ“Š ç»Ÿè®¡ï¼šå…±åˆ†æ {len(df)} ä¸ªæ¦‚å¿µæ¿å—ï¼Œå…¶ä¸­ {len(df[df['alpha_5'].notna()])} ä¸ªæ¿å—æœ‰5æ—¥æ•°æ®")
    
    return "\n".join(result)

def get_hot_concept_codes(trade_date: str = None, limit: int = 30) -> List[str]:
    """
    è·å–çƒ­é—¨ä¸œè´¢æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨ï¼ˆåŸºäºç»¼åˆæ½œåŠ›å¾—åˆ†CP_Scoreç­›é€‰ï¼‰
    
    ä½¿ç”¨ç»¼åˆæ½œåŠ›å¾—åˆ†(CP_Score)ç®—æ³•ï¼š
    - è¶‹åŠ¿å¾—åˆ†(40%): æ¶¨è·Œå¹…æ’å
    - çƒ­åº¦å¾—åˆ†(30%): æ¢æ‰‹ç‡æ’å
    - é¢†æ¶¨å¾—åˆ†(20%): é¢†æ¶¨è‚¡ç¥¨æ¶¨è·Œå¹…æ’å
    - å¹¿åº¦å¾—åˆ†(10%): æ™®æ¶¨ç‡æ’å
    
    å‚æ•°:
        trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
        limit: è¿”å›çš„çƒ­é—¨æ¿å—æ•°é‡ï¼ˆé»˜è®¤30ï¼‰
    
    è¿”å›:
        çƒ­é—¨æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨
    """
    token = get_tushare_token()
    if not token:
        return []
    
    if trade_date is None:
        trade_date = datetime.now().strftime('%Y%m%d')
    
    try:
        # ä¼˜å…ˆä»ç¼“å­˜è·å–æ•°æ®
        df = concept_cache_manager.get_concept_index_data(trade_date=trade_date)
        
        # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œä»APIè·å–
        if df is None or df.empty:
            pro = ts.pro_api()
            df = pro.dc_index(trade_date=trade_date)
            # ä¿å­˜åˆ°ç¼“å­˜
            if not df.empty:
                concept_cache_manager.save_concept_index_data(df)
        
        if df.empty:
            return []
        
        if 'ts_code' not in df.columns:
            return []
        
        # ==========================
        # 1. æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†
        # ==========================
        data = df.copy()
        
        # é¢„è®¡ç®—æ™®æ¶¨ç‡ (Breadth)
        # é˜²æ­¢é™¤ä»¥0ï¼Œåˆ†æ¯åŠ ä¸€ä¸ªå°æå€¼
        if 'up_num' in data.columns and 'down_num' in data.columns:
            # å¡«å……ç¼ºå¤±å€¼ä¸º0
            up_num = data['up_num'].fillna(0)
            down_num = data['down_num'].fillna(0)
            data['up_ratio'] = up_num / (up_num + down_num + 0.0001)
        else:
            # å¦‚æœæ²¡æœ‰ä¸Šæ¶¨/ä¸‹è·Œå®¶æ•°æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼0.5
            data['up_ratio'] = 0.5
        
        # ==========================
        # 2. é¢„ç­›é€‰ (ç¡¬é—¨æ§›)
        # ==========================
        # å‰”é™¤æå°å¸‚å€¼æ¿å—ï¼ˆå®¹æ˜“è¢«æ“çºµï¼Œæ•°æ®å¤±çœŸï¼‰å’Œæå¤§å¸‚å€¼æ¿å—ï¼ˆå¤§è±¡éš¾èµ·èˆï¼‰
        # total_mv å•ä½æ˜¯ä¸‡å…ƒï¼Œä¿ç•™ 50äº¿ ~ 5000äº¿ ä¹‹é—´çš„æ¿å—
        # 50äº¿ = 500000ä¸‡å…ƒï¼Œ5000äº¿ = 50000000ä¸‡å…ƒ
        if 'total_mv' in data.columns:
            data = data[(data['total_mv'] > 500000) & (data['total_mv'] < 50000000)]
        
        # å‰”é™¤å½“å¤©å¤§è·Œçš„æ¿å—ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€æ±‚å†³å®šæ˜¯å¦å¯ç”¨ï¼‰
        # if 'pct_change' in data.columns:
        #     data = data[data['pct_change'] > -2.0]
        
        if data.empty:
            return []
        
        # ==========================
        # 3. è®¡ç®—åˆ†é¡¹æ’åå¾—åˆ† (0 ~ 1)
        # ==========================
        # pct=True è¡¨ç¤ºç”Ÿæˆç™¾åˆ†ä½æ’åï¼Œæœ€å¤§å€¼ä¸º1ï¼Œæœ€å°å€¼ä¸º0
        
        # è¶‹åŠ¿å¾—åˆ†ï¼šæ¶¨è·Œå¹…æ’å
        if 'pct_change' in data.columns:
            data['score_trend'] = data['pct_change'].rank(pct=True, na_option='keep')
        else:
            data['score_trend'] = 0.5  # é»˜è®¤ä¸­ç­‰å¾—åˆ†
        
        # çƒ­åº¦å¾—åˆ†ï¼šæ¢æ‰‹ç‡æ’å
        if 'turnover_rate' in data.columns:
            data['score_heat'] = data['turnover_rate'].rank(pct=True, na_option='keep')
        else:
            data['score_heat'] = 0.5  # é»˜è®¤ä¸­ç­‰å¾—åˆ†
        
        # é¢†æ¶¨å¾—åˆ†ï¼šé¢†æ¶¨è‚¡ç¥¨æ¶¨è·Œå¹…æ’å
        if 'leading_pct' in data.columns:
            data['score_leader'] = data['leading_pct'].rank(pct=True, na_option='keep')
        else:
            data['score_leader'] = 0.5  # é»˜è®¤ä¸­ç­‰å¾—åˆ†
        
        # å¹¿åº¦å¾—åˆ†ï¼šæ™®æ¶¨ç‡æ’å
        data['score_breadth'] = data['up_ratio'].rank(pct=True, na_option='keep')
        
        # å¡«å……ç¼ºå¤±å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
        data['score_trend'] = data['score_trend'].fillna(0.5)
        data['score_heat'] = data['score_heat'].fillna(0.5)
        data['score_leader'] = data['score_leader'].fillna(0.5)
        data['score_breadth'] = data['score_breadth'].fillna(0.5)
        
        # ==========================
        # 4. è®¡ç®—ç»¼åˆ CP_Score
        # ==========================
        data['cp_score'] = (
            0.4 * data['score_trend'] +
            0.3 * data['score_heat'] +
            0.2 * data['score_leader'] +
            0.1 * data['score_breadth']
        )
        
        # ==========================
        # 5. è¾“å‡ºç»“æœ
        # ==========================
        # æŒ‰å¾—åˆ†é™åºæ’åˆ—ï¼Œå–å‰limitä¸ª
        result = data.sort_values(by='cp_score', ascending=False).head(limit)
        
        # æå–æ¿å—ä»£ç 
        codes = result['ts_code'].unique().tolist()
        return sorted(codes)
        
    except Exception as e:
        import sys
        print(f"è·å–çƒ­é—¨æ¦‚å¿µæ¿å—ä»£ç å¤±è´¥: {str(e)}", file=sys.stderr)
        # å¦‚æœç­›é€‰å¤±è´¥ï¼Œè¿”å›æ‰€æœ‰æ¿å—ä»£ç ï¼ˆé™çº§å¤„ç†ï¼‰
        return get_concept_codes(trade_date)

def analyze_concept_volume_anomaly(
    concept_code: str,
    end_date: str = None,
    vol_ratio_threshold: float = 1.3,
    price_change_5d_min: float = 0.02,
    price_change_5d_max: float = 0.08,
    return_all: bool = False
) -> Optional[Dict]:
    """
    åˆ†æå•ä¸ªä¸œè´¢æ¦‚å¿µæ¿å—çš„æˆäº¤é‡å¼‚åŠ¨
    
    å‚æ•°:
        concept_code: æ¦‚å¿µæ¿å—ä»£ç ï¼ˆå¦‚ï¼šBK1184.DCï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
        vol_ratio_threshold: æˆäº¤é‡æ¯”ç‡é˜ˆå€¼ï¼ˆé»˜è®¤1.8ï¼Œå³MA3/MA10 > 1.8ï¼‰
        price_change_5d_min: 5æ—¥æ¶¨å¹…æœ€å°å€¼ï¼ˆé»˜è®¤0.02ï¼Œå³2%ï¼‰
        price_change_5d_max: 5æ—¥æ¶¨å¹…æœ€å¤§å€¼ï¼ˆé»˜è®¤0.08ï¼Œå³8%ï¼‰
        return_all: æ˜¯å¦è¿”å›æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬ä¸ç¬¦åˆæ¡ä»¶çš„ï¼‰ï¼Œç”¨äºæ‰¾å‡ºæœ€æ¥è¿‘çš„æ•°æ®
    
    è¿”å›:
        å¦‚æœreturn_all=Falseä¸”åŒ¹é…æ¡ä»¶ï¼Œè¿”å›åŒ…å«åˆ†æç»“æœçš„å­—å…¸ï¼›å¦åˆ™è¿”å›None
        å¦‚æœreturn_all=Trueï¼Œæ€»æ˜¯è¿”å›åŒ…å«åˆ†æç»“æœçš„å­—å…¸ï¼Œå¹¶åŒ…å«is_matchå­—æ®µ
    """
    token = get_tushare_token()
    if not token:
        return None
    
    if end_date is None or end_date == "":
        end_date = datetime.now().strftime('%Y%m%d')
    
    try:
        # è·å–è‡³å°‘60å¤©çš„æ•°æ®ï¼ˆç”¨äºè®¡ç®—å‡çº¿ï¼‰
        start_date = (datetime.strptime(end_date, '%Y%m%d') - timedelta(days=60)).strftime('%Y%m%d')
        
        # è·å–ä¸œè´¢æ¦‚å¿µæ¿å—æ—¥çº¿æ•°æ®
        pro = ts.pro_api()
        
        # ä¼˜å…ˆä»ç¼“å­˜è·å–
        df = concept_cache_manager.get_concept_daily_data(
            ts_code=concept_code,
            start_date=start_date,
            end_date=end_date
        )
        
        if df is None or df.empty:
            # ä»APIè·å–ï¼ˆä¸ä¼ é€’idx_typeï¼Œå› ä¸ºå·²ç»æŒ‡å®šäº†ts_codeï¼‰
            df = pro.dc_daily(ts_code=concept_code, start_date=start_date, end_date=end_date)
            if not df.empty:
                concept_cache_manager.save_concept_daily_data(df)
        
        if df.empty:
            return None
        
        # ç­›é€‰æŒ‡å®šæ¦‚å¿µæ¿å—çš„æ•°æ®
        if 'ts_code' in df.columns:
            df = df[df['ts_code'] == concept_code].copy()
        
        if df.empty:
            return None
        
        # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        df = df.sort_values('trade_date', ascending=False).reset_index(drop=True)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®ï¼ˆè‡³å°‘éœ€è¦10ä¸ªäº¤æ˜“æ—¥ç”¨äºè®¡ç®—MA10ï¼‰
        if len(df) < 10:
            return None
        
        # è·å–æœ€æ–°æ•°æ®
        latest = df.iloc[0]
        current_price = latest.get('close', 0)
        
        if pd.isna(current_price) or current_price == 0:
            return None
        
        # è®¡ç®—æˆäº¤é‡MAï¼ˆå›ºå®šä½¿ç”¨MA3å’ŒMA10ï¼‰
        if 'vol' not in df.columns:
            return None
        
        vol_series = df['vol'].copy()
        vol_ma_short = 3  # å›ºå®šä½¿ç”¨MA3
        vol_ma_long = 10  # å›ºå®šä½¿ç”¨MA10
        max_ma = max(vol_ma_short, vol_ma_long)
        
        if vol_series.isna().all() or len(vol_series) < max_ma:
            return None
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡ï¼ˆä½¿ç”¨æœ€æ–°çš„Nå¤©æ•°æ®ï¼‰
        # head() è·å–å‰Nè¡Œï¼ˆæœ€æ–°çš„Nå¤©ï¼Œå› ä¸ºå·²æŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼‰
        ma3_vol = vol_series.head(vol_ma_short).mean()
        ma10_vol = vol_series.head(vol_ma_long).mean()
        
        if pd.isna(ma3_vol) or pd.isna(ma10_vol) or ma10_vol == 0:
            return None
        
        # Volume_Ratio = MA3_Vol / MA10_Vol
        vol_ratio = ma3_vol / ma10_vol
        
        # è®¡ç®—5æ—¥æ¶¨å¹…
        # éœ€è¦è‡³å°‘6ä¸ªäº¤æ˜“æ—¥ï¼ˆä»Šå¤© + 5å¤©å‰ï¼‰
        if len(df) < 6:
            return None
        
        # iloc[5] æ˜¯ç¬¬6ä¸ªæ•°æ®ï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰ï¼Œå³5å¤©å‰
        # å› ä¸ºæ•°æ®å·²æŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼Œiloc[0]æ˜¯ä»Šå¤©ï¼Œiloc[5]æ˜¯5å¤©å‰
        price_5d_ago = df.iloc[5].get('close', 0)
        if pd.isna(price_5d_ago) or price_5d_ago == 0:
            return None
        
        price_change_5d = (current_price - price_5d_ago) / price_5d_ago
        
        # è·å–æ¢æ‰‹ç‡ï¼ˆTurnover_Rateï¼‰
        turnover_rate = latest.get('turnover_rate', 0)
        if pd.isna(turnover_rate):
            turnover_rate = 0
        
        # åˆ¤æ–­æ˜¯å¦ç¬¦åˆç­›é€‰æ¡ä»¶
        is_match = (vol_ratio > vol_ratio_threshold and 
                   price_change_5d_min < price_change_5d < price_change_5d_max)
        
        # å¦‚æœreturn_all=Falseä¸”ä¸ç¬¦åˆæ¡ä»¶ï¼Œè¿”å›None
        if not return_all and not is_match:
            return None
        
        # è®¡ç®—è·ç¦»é˜ˆå€¼çš„å·®è·ï¼ˆç”¨äºæ’åºæ‰¾å‡ºæœ€æ¥è¿‘çš„æ•°æ®ï¼‰
        vol_ratio_diff = vol_ratio - vol_ratio_threshold  # æ­£æ•°è¡¨ç¤ºè¶…è¿‡é˜ˆå€¼
        if price_change_5d < price_change_5d_min:
            price_diff = price_change_5d_min - price_change_5d  # ä½äºæœ€å°å€¼
        elif price_change_5d > price_change_5d_max:
            price_diff = price_change_5d - price_change_5d_max  # è¶…è¿‡æœ€å¤§å€¼
        else:
            price_diff = 0  # åœ¨èŒƒå›´å†…
        
        # ç»¼åˆè·ç¦»åˆ†æ•°ï¼ˆè¶Šå°è¶Šæ¥è¿‘æ¡ä»¶ï¼‰
        # ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»çš„ç®€åŒ–ç‰ˆæœ¬
        distance_score = abs(vol_ratio_diff) + abs(price_diff) * 10  # ä»·æ ¼å·®å¼‚æƒé‡æ›´é«˜
        
        return {
            'code': concept_code,
            'vol_ratio': round(vol_ratio, 2),
            'vol_ma_short': vol_ma_short,  # MA3
            'vol_ma_long': vol_ma_long,  # MA10
            'price_change_5d': round(price_change_5d, 4),
            'turnover_rate': round(turnover_rate, 2),
            'current_price': round(current_price, 2),
            'is_match': is_match,
            'distance_score': round(distance_score, 4),
            'vol_ratio_diff': round(vol_ratio_diff, 2),
            'price_diff': round(price_diff, 4)
        }
    
    except Exception as e:
        import sys
        print(f"åˆ†æ {concept_code} å¤±è´¥: {str(e)}", file=sys.stderr)
        return None

def scan_concept_volume_anomaly(
    end_date: str = None,
    vol_ratio_threshold: float = 1.8,
    price_change_5d_min: float = 0.02,
    price_change_5d_max: float = 0.08,
    hot_limit: int = 160
) -> Dict:
    """
    æ‰«æçƒ­é—¨ä¸œè´¢æ¦‚å¿µæ¿å—çš„æˆäº¤é‡å¼‚åŠ¨
    
    å‚æ•°:
        end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
        vol_ratio_threshold: æˆäº¤é‡æ¯”ç‡é˜ˆå€¼ï¼ˆé»˜è®¤1.8ï¼Œå³MA3/MA10 > 1.8ï¼‰
        price_change_5d_min: 5æ—¥æ¶¨å¹…æœ€å°å€¼ï¼ˆé»˜è®¤0.02ï¼Œå³2%ï¼‰
        price_change_5d_max: 5æ—¥æ¶¨å¹…æœ€å¤§å€¼ï¼ˆé»˜è®¤0.08ï¼Œå³8%ï¼‰
        hot_limit: æ‰«æçš„çƒ­é—¨æ¦‚å¿µæ¿å—æ•°é‡ï¼ˆé»˜è®¤160ï¼Œæ ¹æ®æˆäº¤é¢å’Œæ¢æ‰‹ç‡ç­›é€‰ï¼‰
    
    è¿”å›:
        åŒ…å«æ‰«æç»“æœçš„å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…çš„æ•°æ®ï¼Œä¼šè¿”å›æœ€æ¥è¿‘çš„å‰10ä¸ªæ•°æ®
    """
    if end_date is None or end_date == "":
        end_date = datetime.now().strftime('%Y%m%d')
    
    # è·å–çƒ­é—¨æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨
    concept_codes = get_hot_concept_codes(end_date, limit=hot_limit)
    
    matches = []
    all_results = []  # å­˜å‚¨æ‰€æœ‰ç»“æœï¼ˆåŒ…æ‹¬ä¸ç¬¦åˆæ¡ä»¶çš„ï¼‰
    
    # è·å–æ¦‚å¿µæ¿å—åç§°æ˜ å°„
    name_map = {}
    try:
        pro = ts.pro_api()
        concept_codes_str = ','.join(concept_codes)
        concept_df = pro.dc_index(trade_date=end_date, ts_code=concept_codes_str)
        if not concept_df.empty and 'ts_code' in concept_df.columns and 'name' in concept_df.columns:
            for _, row in concept_df.iterrows():
                name_map[row['ts_code']] = row.get('name', row['ts_code'])
    except Exception as e:
        import sys
        print(f"è·å–æ¦‚å¿µæ¿å—åç§°å¤±è´¥: {str(e)}", file=sys.stderr)
    
    # æ”¶é›†æ‰€æœ‰æ¦‚å¿µçš„æ•°æ®ï¼ˆåŒ…æ‹¬ä¸ç¬¦åˆæ¡ä»¶çš„ï¼‰
    for concept_code in concept_codes:
        result = analyze_concept_volume_anomaly(
            concept_code,
            end_date,
            vol_ratio_threshold,
            price_change_5d_min,
            price_change_5d_max,
            return_all=True  # è¿”å›æ‰€æœ‰æ•°æ®
        )
        
        if result:
            # è·å–æ¦‚å¿µæ¿å—åç§°
            concept_name = name_map.get(concept_code, concept_code)
            
            # æ„å»ºç»“æœæ•°æ®
            match_data = {
                "code": result['code'],
                "name": concept_name,
                "metrics": {
                    "vol_ratio": result['vol_ratio'],
                    "vol_ma_short": result.get('vol_ma_short', 3),  # MA3
                    "vol_ma_long": result.get('vol_ma_long', 10),  # MA10
                    "price_change_5d": result['price_change_5d'],
                    "turnover_rate": result.get('turnover_rate', 0),
                    "current_price": result['current_price']
                },
                "distance_score": result.get('distance_score', 999),
                "vol_ratio_diff": result.get('vol_ratio_diff', 0),
                "price_diff": result.get('price_diff', 0),
                "is_match": result.get('is_match', False),
                "reasoning": _build_reasoning(result, vol_ratio_threshold, price_change_5d_min, price_change_5d_max)
            }
            
            all_results.append(match_data)
            
            # å¦‚æœç¬¦åˆæ¡ä»¶ï¼Œä¹ŸåŠ å…¥matches
            if result.get('is_match', False):
                matches.append(match_data)
    
    # å¯¹æ‰€æœ‰ç»“æœæŒ‰distance_scoreæ’åº
    all_results.sort(key=lambda x: x['distance_score'])
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„æ•°æ®ï¼Œè¿”å›æœ€æ¥è¿‘çš„å‰80ä¸ª
    if len(matches) == 0 and len(all_results) > 0:
        closest_results = all_results[:80]
        
        return {
            "scanned_count": len(concept_codes),
            "matched_count": 0,
            "matches": [],
            "closest_results": closest_results,
            "all_results": all_results[:80],  # æ·»åŠ æ‰€æœ‰ç»“æœï¼ˆå‰80åï¼‰
            "message": f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®ï¼Œä»¥ä¸‹æ˜¯æœ€æ¥è¿‘çš„å‰80ä¸ªæ¦‚å¿µæ¿å—ï¼š"
        }
    
    # å¦‚æœæœ‰åŒ¹é…çš„æ•°æ®ï¼Œä¹Ÿè¿”å›æ‰€æœ‰ç»“æœï¼ˆå‰80åï¼‰ä»¥ä¾¿å®Œæ•´åˆ†æ
    return {
        "scanned_count": len(concept_codes),
        "matched_count": len(matches),
        "matches": matches,
        "all_results": all_results[:80]  # æ·»åŠ æ‰€æœ‰ç»“æœï¼ˆå‰80åï¼‰
    }

def _build_reasoning(result: Dict, vol_ratio_threshold: float, price_change_5d_min: float, price_change_5d_max: float) -> str:
    """
    æ„å»ºæ¨ç†è¯´æ˜æ–‡æœ¬
    
    å‚æ•°:
        result: åˆ†æç»“æœå­—å…¸
        vol_ratio_threshold: æˆäº¤é‡æ¯”ç‡é˜ˆå€¼
        price_change_5d_min: 5æ—¥æ¶¨å¹…æœ€å°å€¼
        price_change_5d_max: 5æ—¥æ¶¨å¹…æœ€å¤§å€¼
    
    è¿”å›:
        æ¨ç†è¯´æ˜æ–‡æœ¬
    """
    vol_ratio = result['vol_ratio']
    price_change_5d = result['price_change_5d']
    vol_ratio_diff = result.get('vol_ratio_diff', 0)
    price_diff = result.get('price_diff', 0)
    
    parts = []
    
    # æˆäº¤é‡æ¯”ç‡è¯´æ˜
    if vol_ratio > vol_ratio_threshold:
        parts.append(f"æˆäº¤é‡æ¯”ç‡ {vol_ratio:.2f} è¶…è¿‡é˜ˆå€¼ {vol_ratio_threshold:.2f} (è¶…å‡º {vol_ratio_diff:.2f})")
    else:
        parts.append(f"æˆäº¤é‡æ¯”ç‡ {vol_ratio:.2f} ä½äºé˜ˆå€¼ {vol_ratio_threshold:.2f} (å·®è· {abs(vol_ratio_diff):.2f})")
    
    # 5æ—¥æ¶¨å¹…è¯´æ˜
    if price_change_5d_min <= price_change_5d <= price_change_5d_max:
        parts.append(f"5æ—¥æ¶¨å¹… {price_change_5d*100:.2f}% åœ¨èŒƒå›´å†… ({price_change_5d_min*100:.0f}% - {price_change_5d_max*100:.0f}%)")
    elif price_change_5d < price_change_5d_min:
        parts.append(f"5æ—¥æ¶¨å¹… {price_change_5d*100:.2f}% ä½äºæœ€å°å€¼ {price_change_5d_min*100:.0f}% (å·®è· {abs(price_diff)*100:.2f}%)")
    else:
        parts.append(f"5æ—¥æ¶¨å¹… {price_change_5d*100:.2f}% è¶…è¿‡æœ€å¤§å€¼ {price_change_5d_max*100:.0f}% (è¶…å‡º {abs(price_diff)*100:.2f}%)")
    
    return "; ".join(parts)

def register_concept_tools(mcp: "FastMCP"):
    """æ³¨å†Œæ¦‚å¿µæ¿å—ç›¸å…³å·¥å…·"""
    
    @mcp.tool()
    def get_eastmoney_concept_board(
        ts_code: str = "",
        name: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = ""
    ) -> str:
        """
        è·å–ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—è¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: æŒ‡æ•°ä»£ç ï¼ˆæ”¯æŒå¤šä¸ªä»£ç åŒæ—¶è¾“å…¥ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼šBK1186.DC,BK1185.DCï¼‰
            name: æ¿å—åç§°ï¼ˆä¾‹å¦‚ï¼šäººå½¢æœºå™¨äººï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250103ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250131ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
        
        æ³¨æ„:
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - æ•°æ®è¯´æ˜ï¼šè·å–ä¸œæ–¹è´¢å¯Œæ¯ä¸ªäº¤æ˜“æ—¥çš„æ¦‚å¿µæ¿å—æ•°æ®ï¼Œæ”¯æŒæŒ‰æ—¥æœŸæŸ¥è¯¢
            - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è·å–5000æ¡æ•°æ®ï¼Œå†å²æ•°æ®å¯æ ¹æ®æ—¥æœŸå¾ªç¯è·å–
            - æƒé™ï¼šç”¨æˆ·ç§¯ç´¯6000ç§¯åˆ†å¯è°ƒå–
        
        è¿”å›:
            åŒ…å«æ¦‚å¿µæ¿å—æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬ï¼š
            - æ¦‚å¿µä»£ç ã€æ¦‚å¿µåç§°
            - æ¶¨è·Œå¹…ã€é¢†æ¶¨è‚¡ç¥¨åŠæ¶¨è·Œå¹…
            - æ€»å¸‚å€¼ã€æ¢æ‰‹ç‡
            - ä¸Šæ¶¨å®¶æ•°ã€ä¸‹è·Œå®¶æ•°
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not name and not trade_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šæ¦‚å¿µä»£ç (ts_code)ã€æ¿å—åç§°(name)ã€äº¤æ˜“æ—¥æœŸ(trade_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if name:
                params['name'] = name
            if trade_date:
                params['trade_date'] = trade_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # ä¼˜å…ˆä»ç¼“å­˜è·å–æ•°æ®
            df = None
            if trade_date:
                # å•æ—¥æœŸæŸ¥è¯¢ï¼Œä¼˜å…ˆä»ç¼“å­˜è·å–
                df = concept_cache_manager.get_concept_index_data(
                    ts_code=ts_code if ts_code else None,
                    name=name if name else None,
                    trade_date=trade_date
                )
            elif start_date and end_date:
                # æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œæ£€æŸ¥ç¼“å­˜æ˜¯å¦å®Œæ•´
                df = concept_cache_manager.get_concept_index_data(
                    ts_code=ts_code if ts_code else None,
                    name=name if name else None,
                    start_date=start_date,
                    end_date=end_date
                )
            
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œä»APIè·å–
            if df is None or df.empty:
                df = pro.dc_index(**params)
                # ä¿å­˜åˆ°ç¼“å­˜
                if not df.empty:
                    concept_cache_manager.save_concept_index_data(df)
            
            if df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"æ¦‚å¿µä»£ç : {ts_code}")
                if name:
                    param_info.append(f"æ¿å—åç§°: {name}")
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¦‚å¿µæ¿å—æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰äº¤æ˜“æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            if 'trade_date' in df.columns:
                df = df.sort_values('trade_date', ascending=False)
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = []
            result.append("ğŸ“Š ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—æ•°æ®")
            result.append("=" * 120)
            result.append("")
            
            # æ˜¾ç¤ºæŸ¥è¯¢æ¡ä»¶
            query_info = []
            if ts_code:
                query_info.append(f"æ¦‚å¿µä»£ç : {ts_code}")
            if name:
                query_info.append(f"æ¿å—åç§°: {name}")
            if trade_date:
                query_info.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(trade_date)}")
            if start_date or end_date:
                date_range = f"{format_date(start_date) if start_date else 'å¼€å§‹'} è‡³ {format_date(end_date) if end_date else 'ç»“æŸ'}"
                query_info.append(f"æ—¥æœŸèŒƒå›´: {date_range}")
            
            if query_info:
                result.append("æŸ¥è¯¢æ¡ä»¶:")
                for info in query_info:
                    result.append(f"  - {info}")
                result.append("")
            
            # å¦‚æœæœ‰å¤šä¸ªäº¤æ˜“æ—¥æœŸï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„æ˜¾ç¤º
            if 'trade_date' in df.columns and len(df['trade_date'].unique()) > 1:
                dates = sorted(df['trade_date'].unique(), reverse=True)
                for date in dates[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                    date_df = df[df['trade_date'] == date]
                    if not date_df.empty:
                        result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                        result.append("=" * 120)
                        result.append(format_concept_data(date_df, include_header=False))
                        result.append("")
                
                if len(dates) > 10:
                    result.append(f"ï¼ˆå…± {len(dates)} ä¸ªäº¤æ˜“æ—¥ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ 10 ä¸ªï¼‰")
            else:
                # å•ä¸ªæ—¥æœŸæˆ–æ²¡æœ‰æ—¥æœŸå­—æ®µï¼Œç›´æ¥æ˜¾ç¤º
                result.append(format_concept_data(df, include_header=False))
            
            return "\n".join(result)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_eastmoney_concept_member(
        ts_code: str = "",
        con_code: str = "",
        trade_date: str = ""
    ) -> str:
        """
        è·å–ä¸œæ–¹è´¢å¯Œæ¿å—æ¯æ—¥æˆåˆ†æ•°æ®
        
        å‚æ•°:
            ts_code: æ¿å—æŒ‡æ•°ä»£ç ï¼ˆå¦‚ï¼šBK1184.DCäººå½¢æœºå™¨äººï¼Œå¯é€‰ï¼‰
            con_code: æˆåˆ†è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼š002117.SZï¼Œå¯é€‰ï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250102ï¼Œå¯é€‰ï¼‰
        
        æ³¨æ„:
            - å¯ä»¥æ ¹æ®æ¦‚å¿µæ¿å—ä»£ç å’Œäº¤æ˜“æ—¥æœŸï¼Œè·å–å†å²æˆåˆ†
            - é™é‡ï¼šå•æ¬¡æœ€å¤§è·å–5000æ¡æ•°æ®ï¼Œå¯ä»¥é€šè¿‡æ—¥æœŸå’Œä»£ç å¾ªç¯è·å–
            - æƒé™ï¼šç”¨æˆ·ç§¯ç´¯6000ç§¯åˆ†å¯è°ƒå–
            - æœ¬æ¥å£åªé™ä¸ªäººå­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œå¦‚éœ€å•†ä¸šç”¨é€”ï¼Œè¯·è‡ªè¡Œè”ç³»ä¸œæ–¹è´¢å¯Œè§£å†³æ•°æ®é‡‡è´­é—®é¢˜
        
        è¿”å›:
            åŒ…å«æ¦‚å¿µæ¿å—æˆåˆ†æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬ï¼š
            - äº¤æ˜“æ—¥æœŸ
            - æ¦‚å¿µä»£ç 
            - æˆåˆ†ä»£ç ï¼ˆè‚¡ç¥¨ä»£ç ï¼‰
            - æˆåˆ†è‚¡åç§°
        
        ç¤ºä¾‹:
            - è·å–2025å¹´1æœˆ2æ—¥çš„äººå½¢æœºå™¨äººæ¦‚å¿µæ¿å—æˆåˆ†åˆ—è¡¨ï¼š
              ts_code='BK1184.DC', trade_date='20250102'
            - æŸ¥è¯¢æŸåªè‚¡ç¥¨å±äºå“ªäº›æ¦‚å¿µæ¿å—ï¼š
              con_code='002117.SZ'
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not con_code and not trade_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šæ¿å—æŒ‡æ•°ä»£ç (ts_code)ã€æˆåˆ†è‚¡ç¥¨ä»£ç (con_code)æˆ–äº¤æ˜“æ—¥æœŸ(trade_date)"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if con_code:
                params['con_code'] = con_code
            if trade_date:
                params['trade_date'] = trade_date
            
            # ä¼˜å…ˆä»ç¼“å­˜è·å–æ•°æ®
            df = concept_cache_manager.get_concept_member_data(
                ts_code=ts_code if ts_code else None,
                con_code=con_code if con_code else None,
                trade_date=trade_date if trade_date else None
            )
            
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œä»APIè·å–
            if df is None or df.empty:
                df = pro.dc_member(**params)
                # ä¿å­˜åˆ°ç¼“å­˜
                if not df.empty:
                    concept_cache_manager.save_concept_member_data(df)
            
            if df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"æ¿å—æŒ‡æ•°ä»£ç : {ts_code}")
                if con_code:
                    param_info.append(f"æˆåˆ†è‚¡ç¥¨ä»£ç : {con_code}")
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¦‚å¿µæ¿å—æˆåˆ†æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰äº¤æ˜“æ—¥æœŸå’Œæ¦‚å¿µä»£ç æ’åº
            sort_columns = []
            if 'trade_date' in df.columns:
                sort_columns.append('trade_date')
            if 'ts_code' in df.columns:
                sort_columns.append('ts_code')
            if sort_columns:
                df = df.sort_values(sort_columns, ascending=[False] * len(sort_columns))
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = []
            result.append("ğŸ“Š ä¸œæ–¹è´¢å¯Œæ¿å—æˆåˆ†æ•°æ®")
            result.append("=" * 80)
            result.append("")
            
            # æ˜¾ç¤ºæŸ¥è¯¢æ¡ä»¶
            query_info = []
            if ts_code:
                query_info.append(f"æ¿å—æŒ‡æ•°ä»£ç : {ts_code}")
            if con_code:
                query_info.append(f"æˆåˆ†è‚¡ç¥¨ä»£ç : {con_code}")
            if trade_date:
                query_info.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(trade_date)}")
            
            if query_info:
                result.append("æŸ¥è¯¢æ¡ä»¶:")
                for info in query_info:
                    result.append(f"  - {info}")
                result.append("")
            
            # å¦‚æœæœ‰å¤šä¸ªäº¤æ˜“æ—¥æœŸæˆ–å¤šä¸ªæ¦‚å¿µæ¿å—ï¼ŒæŒ‰æ—¥æœŸå’Œæ¦‚å¿µåˆ†ç»„æ˜¾ç¤º
            if 'trade_date' in df.columns and len(df['trade_date'].unique()) > 1:
                dates = sorted(df['trade_date'].unique(), reverse=True)
                for date in dates[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                    date_df = df[df['trade_date'] == date]
                    if not date_df.empty:
                        result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                        result.append("=" * 80)
                        
                        # å¦‚æœè¯¥æ—¥æœŸæœ‰å¤šä¸ªæ¦‚å¿µæ¿å—ï¼ŒæŒ‰æ¦‚å¿µæ¿å—åˆ†ç»„
                        if 'ts_code' in date_df.columns and len(date_df['ts_code'].unique()) > 1:
                            concepts = date_df['ts_code'].unique()
                            for concept in concepts:
                                concept_df = date_df[date_df['ts_code'] == concept]
                                if not concept_df.empty:
                                    result.append(f"ğŸ“Œ æ¦‚å¿µæ¿å—: {concept} ({len(concept_df)} åªæˆåˆ†è‚¡)")
                                    result.append("-" * 80)
                                    # ä¸æ˜¾ç¤ºæ—¥æœŸå’Œæ¦‚å¿µä»£ç ï¼ˆå·²åœ¨æ ‡é¢˜ä¸­æ˜¾ç¤ºï¼‰
                                    result.append(format_concept_member_data(concept_df, show_date=False, show_concept=False))
                                    result.append("")
                        else:
                            # å•ä¸ªæ¦‚å¿µæ¿å—ï¼Œä¸æ˜¾ç¤ºæ—¥æœŸå’Œæ¦‚å¿µä»£ç 
                            result.append(format_concept_member_data(date_df, show_date=False, show_concept=False))
                            result.append("")
                
                if len(dates) > 10:
                    result.append(f"ï¼ˆå…± {len(dates)} ä¸ªäº¤æ˜“æ—¥ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ 10 ä¸ªï¼‰")
            elif 'ts_code' in df.columns and len(df['ts_code'].unique()) > 1:
                # å¤šä¸ªæ¦‚å¿µæ¿å—ï¼ŒæŒ‰æ¦‚å¿µæ¿å—åˆ†ç»„
                concepts = df['ts_code'].unique()
                for concept in concepts:
                    concept_df = df[df['ts_code'] == concept]
                    if not concept_df.empty:
                        result.append(f"ğŸ“Œ æ¦‚å¿µæ¿å—: {concept} ({len(concept_df)} åªæˆåˆ†è‚¡)")
                        result.append("-" * 80)
                        # ä¸æ˜¾ç¤ºæ¦‚å¿µä»£ç ï¼ˆå·²åœ¨æ ‡é¢˜ä¸­æ˜¾ç¤ºï¼‰
                        result.append(format_concept_member_data(concept_df, show_date=True, show_concept=False))
                        result.append("")
            else:
                # å•ä¸ªæ—¥æœŸæˆ–å•ä¸ªæ¦‚å¿µæ¿å—ï¼Œæ ¹æ®æŸ¥è¯¢æ¡ä»¶å†³å®šæ˜¾ç¤ºå“ªäº›åˆ—
                show_date_col = not trade_date or len(df['trade_date'].unique()) > 1 if 'trade_date' in df.columns else False
                show_concept_col = not ts_code or len(df['ts_code'].unique()) > 1 if 'ts_code' in df.columns else False
                result.append(format_concept_member_data(df, show_date=show_date_col, show_concept=show_concept_col))
            
            return "\n".join(result)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_eastmoney_concept_daily(
        ts_code: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = "",
        idx_type: str = ""
    ) -> str:
        """
        è·å–ä¸œè´¢æ¦‚å¿µæ¿å—ã€è¡Œä¸šæŒ‡æ•°æ¿å—ã€åœ°åŸŸæ¿å—è¡Œæƒ…æ•°æ®
        
        å‚æ•°:
            ts_code: æ¿å—ä»£ç ï¼ˆæ ¼å¼ï¼šxxxxx.DCï¼Œå¦‚ï¼šBK1184.DCï¼Œå¯é€‰ï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250513ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼Œå¯é€‰ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250101ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼Œå¯é€‰ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20250531ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼Œå¯é€‰ï¼‰
            idx_type: æ¿å—ç±»å‹ï¼ˆå¯é€‰å€¼ï¼šæ¦‚å¿µæ¿å—ã€è¡Œä¸šæ¿å—ã€åœ°åŸŸæ¿å—ï¼Œå¯é€‰ï¼‰
        
        æ³¨æ„:
            - å¦‚æœæä¾›äº†trade_dateï¼Œå°†æŸ¥è¯¢è¯¥ç‰¹å®šæ—¥æœŸçš„æ•°æ®
            - å¦‚æœæä¾›äº†start_dateå’Œend_dateï¼Œå°†æŸ¥è¯¢è¯¥æ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            - trade_dateä¼˜å…ˆçº§é«˜äºstart_date/end_date
            - æ•°æ®è¯´æ˜ï¼šè·å–ä¸œè´¢æ¦‚å¿µæ¿å—ã€è¡Œä¸šæŒ‡æ•°æ¿å—ã€åœ°åŸŸæ¿å—è¡Œæƒ…æ•°æ®ï¼Œå†å²æ•°æ®å¼€å§‹äº2020å¹´
            - é™é‡ï¼šå•æ¬¡æœ€å¤§2000æ¡æ•°æ®ï¼Œå¯æ ¹æ®æ—¥æœŸå‚æ•°å¾ªç¯è·å–
            - æƒé™ï¼šç”¨æˆ·ç§¯ç´¯6000ç§¯åˆ†å¯è°ƒå–
            - æœ¬æ¥å£åªé™ä¸ªäººå­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ï¼Œå¦‚éœ€å•†ä¸šç”¨é€”ï¼Œè¯·è‡ªè¡Œè”ç³»ä¸œæ–¹è´¢å¯Œè§£å†³æ•°æ®é‡‡è´­é—®é¢˜
        
        è¿”å›:
            åŒ…å«æ¿å—è¡Œæƒ…æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬ï¼š
            - æ¿å—ä»£ç ã€äº¤æ˜“æ—¥æœŸ
            - å¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ç‚¹ä½
            - æ¶¨è·Œç‚¹ä½ã€æ¶¨è·Œå¹…
            - æˆäº¤é‡ã€æˆäº¤é¢
            - æŒ¯å¹…ã€æ¢æ‰‹ç‡
        
        ç¤ºä¾‹:
            - è·å–2025å¹´5æœˆ13æ—¥æ‰€æœ‰æ¦‚å¿µæ¿å—è¡Œæƒ…ï¼š
              trade_date='20250513'
            - è·å–æŸä¸ªæ¿å—çš„å†å²è¡Œæƒ…ï¼š
              ts_code='BK1184.DC', start_date='20250101', end_date='20250531'
            - è·å–è¡Œä¸šæ¿å—è¡Œæƒ…ï¼š
              idx_type='è¡Œä¸šæ¿å—', trade_date='20250513'
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not trade_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šæ¿å—ä»£ç (ts_code)ã€äº¤æ˜“æ—¥æœŸ(trade_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if trade_date:
                params['trade_date'] = trade_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            if idx_type:
                params['idx_type'] = idx_type
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # ä¼˜å…ˆä»ç¼“å­˜è·å–æ•°æ®
            df = None
            if trade_date:
                # å•æ—¥æœŸæŸ¥è¯¢ï¼Œä¼˜å…ˆä»ç¼“å­˜è·å–
                df = concept_cache_manager.get_concept_daily_data(
                    ts_code=ts_code if ts_code else None,
                    trade_date=trade_date,
                    idx_type=idx_type if idx_type else None
                )
            elif start_date and end_date:
                # æ—¥æœŸèŒƒå›´æŸ¥è¯¢ï¼Œæ£€æŸ¥ç¼“å­˜æ˜¯å¦å®Œæ•´
                df = concept_cache_manager.get_concept_daily_data(
                    ts_code=ts_code if ts_code else None,
                    start_date=start_date,
                    end_date=end_date,
                    idx_type=idx_type if idx_type else None
                )
            
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®ï¼Œä»APIè·å–
            if df is None or df.empty:
                df = pro.dc_daily(**params)
                # ä¿å­˜åˆ°ç¼“å­˜
                if not df.empty:
                    concept_cache_manager.save_concept_daily_data(df)
            
            if df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"æ¿å—ä»£ç : {ts_code}")
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                if idx_type:
                    param_info.append(f"æ¿å—ç±»å‹: {idx_type}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¿å—è¡Œæƒ…æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰äº¤æ˜“æ—¥æœŸå’Œæ¶¨è·Œå¹…æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼Œæ¶¨è·Œå¹…é™åºï¼‰
            sort_columns = []
            if 'trade_date' in df.columns:
                sort_columns.append('trade_date')
            if 'pct_change' in df.columns:
                sort_columns.append('pct_change')
            if sort_columns:
                df = df.sort_values(sort_columns, ascending=[False, False])
            
            # æ ¼å¼åŒ–è¾“å‡º
            result = []
            result.append("ğŸ“Š ä¸œè´¢æ¦‚å¿µ/è¡Œä¸š/åœ°åŸŸæ¿å—è¡Œæƒ…æ•°æ®")
            result.append("=" * 120)
            result.append("")
            
            # æ˜¾ç¤ºæŸ¥è¯¢æ¡ä»¶
            query_info = []
            if ts_code:
                query_info.append(f"æ¿å—ä»£ç : {ts_code}")
            if trade_date:
                query_info.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(trade_date)}")
            if start_date or end_date:
                date_range = f"{format_date(start_date) if start_date else 'å¼€å§‹'} è‡³ {format_date(end_date) if end_date else 'ç»“æŸ'}"
                query_info.append(f"æ—¥æœŸèŒƒå›´: {date_range}")
            if idx_type:
                query_info.append(f"æ¿å—ç±»å‹: {idx_type}")
            
            if query_info:
                result.append("æŸ¥è¯¢æ¡ä»¶:")
                for info in query_info:
                    result.append(f"  - {info}")
                result.append("")
            
            # è°ƒç”¨æ ¼å¼åŒ–å‡½æ•°
            result.append(format_concept_daily_data(df, ts_code or ""))
            
            return "\n".join(result)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def analyze_concept_alpha_strategy(
        concept_code: str = "",
        benchmark_code: str = "000300.SH",
        end_date: str = ""
    ) -> str:
        """
        åˆ†æå•ä¸ªä¸œè´¢æ¦‚å¿µæ¿å—çš„ç›¸å¯¹å¼ºåº¦Alpha
        
        å‚æ•°:
            concept_code: æ¦‚å¿µæ¿å—ä»£ç ï¼ˆå¦‚ï¼šBK1184.DCäººå½¢æœºå™¨äººã€BK1186.DCé¦–å‘ç»æµç­‰ï¼‰
            benchmark_code: åŸºå‡†æŒ‡æ•°ä»£ç ï¼ˆé»˜è®¤ï¼š000300.SHæ²ªæ·±300ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20241124ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
        
        è¿”å›:
            åŒ…å«Alphaåˆ†æç»“æœçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - è®¡ç®—2å¤©å’Œ5å¤©çš„åŒºé—´æ”¶ç›Šç‡
            - è®¡ç®—è¶…é¢æ”¶ç›ŠAlpha = æ¿å—æ”¶ç›Š - åŸºå‡†æ”¶ç›Š
            - ç»¼åˆå¾—åˆ† = Alpha_2 Ã— 60% + Alpha_5 Ã— 40%
        """
        if not concept_code:
            return "è¯·æä¾›æ¦‚å¿µæ¿å—ä»£ç (å¦‚ï¼šBK1184.DCã€BK1186.DCç­‰)"
        
        # å¦‚æœend_dateä¸ºç©ºï¼Œä½¿ç”¨Noneè®©analyze_sector_alphaä½¿ç”¨é»˜è®¤å€¼
        if end_date == "":
            end_date = None
        
        result = analyze_sector_alpha(concept_code, benchmark_code, end_date)
        
        if "error" in result:
            return result["error"]
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = []
        output.append(f"ğŸ“Š {concept_code} ç›¸å¯¹å¼ºåº¦Alphaåˆ†æ")
        output.append("=" * 80)
        output.append("")
        output.append(f"åŸºå‡†æŒ‡æ•°: {result['benchmark_code']}")
        output.append(f"åˆ†ææ—¥æœŸ: {result['end_date']}")
        output.append("")
        output.append("ğŸ“ˆ æ”¶ç›Šç‡åˆ†æï¼š")
        output.append("-" * 80)
        
        if pd.notna(result['r_sector_2']):
            output.append(f"æ¿å—2æ—¥æ”¶ç›Šç‡: {result['r_sector_2']*100:.2f}%")
        else:
            output.append("æ¿å—2æ—¥æ”¶ç›Šç‡: æ•°æ®ä¸è¶³")
        
        if pd.notna(result['r_sector_5']):
            output.append(f"æ¿å—5æ—¥æ”¶ç›Šç‡: {result['r_sector_5']*100:.2f}%")
        else:
            output.append("æ¿å—5æ—¥æ”¶ç›Šç‡: æ•°æ®ä¸è¶³")
        
        if pd.notna(result['r_benchmark_2']):
            output.append(f"åŸºå‡†2æ—¥æ”¶ç›Šç‡: {result['r_benchmark_2']*100:.2f}%")
        else:
            output.append("åŸºå‡†2æ—¥æ”¶ç›Šç‡: æ•°æ®ä¸è¶³")
        
        if pd.notna(result['r_benchmark_5']):
            output.append(f"åŸºå‡†5æ—¥æ”¶ç›Šç‡: {result['r_benchmark_5']*100:.2f}%")
        else:
            output.append("åŸºå‡†5æ—¥æ”¶ç›Šç‡: æ•°æ®ä¸è¶³")
        
        output.append("")
        output.append("ğŸ¯ Alphaåˆ†æï¼š")
        output.append("-" * 80)
        
        if pd.notna(result['alpha_2']):
            alpha_2_pct = result['alpha_2'] * 100
            status_2 = "âœ… è·‘èµ¢å¤§ç›˜" if alpha_2_pct > 0 else "âŒ è·‘è¾“å¤§ç›˜"
            output.append(f"2æ—¥Alpha: {alpha_2_pct:+.2f}% {status_2}")
        else:
            output.append("2æ—¥Alpha: æ•°æ®ä¸è¶³")
        
        if pd.notna(result['alpha_5']):
            alpha_5_pct = result['alpha_5'] * 100
            status_5 = "âœ… è·‘èµ¢å¤§ç›˜" if alpha_5_pct > 0 else "âŒ è·‘è¾“å¤§ç›˜"
            output.append(f"5æ—¥Alpha: {alpha_5_pct:+.2f}% {status_5}")
        else:
            output.append("5æ—¥Alpha: æ•°æ®ä¸è¶³")
        
        output.append("")
        output.append("ğŸ† ç»¼åˆè¯„åˆ†ï¼š")
        output.append("-" * 80)
        
        if pd.notna(result['score']):
            score_pct = result['score'] * 100
            if score_pct > 5:
                rating = "â­â­â­ éå¸¸å¼ºåŠ¿"
            elif score_pct > 2:
                rating = "â­â­ å¼ºåŠ¿"
            elif score_pct > 0:
                rating = "â­ ç•¥å¼º"
            elif score_pct > -2:
                rating = "â– ä¸­æ€§"
            elif score_pct > -5:
                rating = "âš ï¸ å¼±åŠ¿"
            else:
                rating = "âŒ éå¸¸å¼±åŠ¿"
            
            output.append(f"ç»¼åˆå¾—åˆ†: {score_pct:+.2f}% {rating}")
            output.append("")
            output.append("è®¡ç®—å…¬å¼: å¾—åˆ† = Alpha_2 Ã— 60% + Alpha_5 Ã— 40%")
        else:
            output.append("ç»¼åˆå¾—åˆ†: æ•°æ®ä¸è¶³")
        
        return "\n".join(output)
    
    @mcp.tool()
    def rank_concepts_by_alpha(
        benchmark_code: str = "000300.SH",
        end_date: str = "",
        top_n: int = 20,
        hot_limit: int = 80
    ) -> str:
        """
        å¯¹çƒ­é—¨ä¸œè´¢æ¦‚å¿µæ¿å—è¿›è¡ŒAlphaæ’åï¼ˆä»…æŸ¥è¯¢çƒ­é—¨æ¦‚å¿µæ¿å—ä»¥å‡å°‘è®¡ç®—é‡ï¼‰
        
        å‚æ•°:
            benchmark_code: åŸºå‡†æŒ‡æ•°ä»£ç ï¼ˆé»˜è®¤ï¼š000300.SHæ²ªæ·±300ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
            top_n: æ˜¾ç¤ºå‰Nåï¼ˆé»˜è®¤20ï¼‰
            hot_limit: ç­›é€‰çš„çƒ­é—¨æ¦‚å¿µæ¿å—æ•°é‡ï¼ˆé»˜è®¤200ï¼Œæ ¹æ®æˆäº¤é¢å’Œæ¢æ‰‹ç‡ç­›é€‰ï¼‰
        
        è¿”å›:
            åŒ…å«æ’åç»“æœçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - è‡ªåŠ¨è·å–æŒ‡å®šæ—¥æœŸçš„çƒ­é—¨æ¦‚å¿µæ¿å—ï¼ˆæ ¹æ®æˆäº¤é¢å’Œæ¢æ‰‹ç‡ç­›é€‰ï¼‰
            - æŒ‰ç»¼åˆå¾—åˆ†é™åºæ’åˆ—
            - æ˜¾ç¤ºå‰Nåå¼ºåŠ¿æ¿å—
            - ä»…åˆ†æçƒ­é—¨æ¿å—ä»¥å‡å°‘è®¡ç®—é‡ï¼Œæé«˜å“åº”é€Ÿåº¦
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å¦‚æœend_dateä¸ºç©ºï¼Œä½¿ç”¨Noneè®©analyze_sector_alphaä½¿ç”¨é»˜è®¤å€¼
        if end_date == "":
            end_date = None
        
        try:
            # è·å–çƒ­é—¨æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨ï¼ˆæ ¹æ®æˆäº¤é¢å’Œæ¢æ‰‹ç‡ç­›é€‰ï¼‰
            trade_date_str = end_date if end_date else datetime.now().strftime('%Y%m%d')
            concept_codes = get_hot_concept_codes(trade_date_str, limit=hot_limit)
            
            if not concept_codes:
                return "æ— æ³•è·å–çƒ­é—¨æ¦‚å¿µæ¿å—åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œtokené…ç½®ã€‚\næç¤ºï¼šå¯èƒ½æ˜¯æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥Tushare tokenæ˜¯å¦æœ‰æ•ˆã€‚"
            
            # è¿›è¡ŒAlphaæ’å
            df = rank_sectors_alpha(concept_codes, benchmark_code, end_date)
            
            if df.empty:
                return "æ— æ³•è·å–æ¿å—æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œtokené…ç½®ã€‚\næç¤ºï¼šå¦‚æœæ‰€æœ‰æ¿å—éƒ½è¿”å›é”™è¯¯ï¼Œå¯èƒ½æ˜¯æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥Tushare tokenæ˜¯å¦æœ‰æ•ˆã€‚"
            
            # æ˜¾ç¤ºæ‰€æœ‰æ’åï¼ˆå¦‚æœtop_nå¤§äºç­‰äºæ€»æ•°ï¼Œæ˜¾ç¤ºå…¨éƒ¨ï¼‰
            if top_n >= len(df):
                df_display = df
            else:
                df_display = df.head(top_n)
            
            # è·å–æ¿å—åç§°å’Œä»Šæ—¥è¡Œæƒ…æ•°æ®
            try:
                pro = ts.pro_api()
                concept_codes_str = ','.join(df_display['sector_code'].tolist())
                
                # ç›´æ¥ä½¿ç”¨APIæŸ¥è¯¢ï¼Œä¸é€šè¿‡ç¼“å­˜ç®¡ç†å™¨ï¼ˆå› ä¸ºå¯èƒ½ä¸æ”¯æŒå¤šä»£ç æŸ¥è¯¢ï¼‰
                concept_df = pro.dc_index(ts_code=concept_codes_str, trade_date=trade_date_str)
                
                # åˆ›å»ºæ¿å—ä»£ç åˆ°åç§°çš„æ˜ å°„
                name_map = {}
                pct_map = {}
                amount_map = {}
                turnover_map = {}
                
                if not concept_df.empty and 'ts_code' in concept_df.columns:
                    for _, row in concept_df.iterrows():
                        code = row['ts_code']
                        name_map[code] = row.get('name', code) if pd.notna(row.get('name')) else code
                        pct_map[code] = row.get('pct_change', 0) if pd.notna(row.get('pct_change')) else 0
                        amount_map[code] = row.get('amount', 0) if pd.notna(row.get('amount')) else 0
                        turnover_map[code] = row.get('turnover', 0) if pd.notna(row.get('turnover')) else 0
                
                # æ·»åŠ æ¿å—åç§°ç­‰ä¿¡æ¯åˆ°DataFrame
                df_display['name'] = df_display['sector_code'].map(name_map).fillna(df_display['sector_code'])
                df_display['pct_change'] = df_display['sector_code'].map(pct_map).fillna(0)
                df_display['amount'] = df_display['sector_code'].map(amount_map).fillna(0)
                df_display['turnover'] = df_display['sector_code'].map(turnover_map).fillna(0)
                
            except Exception as e:
                # å¦‚æœè·å–åç§°å¤±è´¥ï¼Œä½¿ç”¨ä»£ç ä½œä¸ºåç§°
                import sys
                print(f"è·å–æ¿å—åç§°å¤±è´¥: {str(e)}", file=sys.stderr)
                df_display['name'] = df_display['sector_code']
                df_display['pct_change'] = 0
                df_display['amount'] = 0
                df_display['turnover'] = 0
            
            # ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼åŒ–å‡½æ•°æ˜¾ç¤ºå®Œæ•´ä¿¡æ¯
            result = format_concept_alpha_analysis(df_display)
            
            # å¦‚æœåªæ˜¾ç¤ºäº†éƒ¨åˆ†ï¼Œæ·»åŠ æç¤º
            if top_n < len(df):
                result += f"\n\nï¼ˆå…±åˆ†æ {len(df)} ä¸ªçƒ­é—¨æ¦‚å¿µæ¿å—ï¼Œä»…æ˜¾ç¤ºå‰ {top_n} åï¼‰"
            else:
                result += f"\n\nï¼ˆå…±åˆ†æ {len(df)} ä¸ªçƒ­é—¨æ¦‚å¿µæ¿å—ï¼‰"
            
            result += f"\nï¼ˆä»çƒ­é—¨æ¿å—ä¸­ç­›é€‰ï¼Œç­›é€‰æ ‡å‡†ï¼šæˆäº¤é¢å’Œæ¢æ‰‹ç‡ï¼Œç­›é€‰æ•°é‡ï¼š{hot_limit}ï¼‰"
            
            return result
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def rank_concepts_alpha_velocity(
        benchmark_code: str = "000300.SH",
        end_date: str = ""
    ) -> str:
        """
        åˆ†æä¸œè´¢æ¦‚å¿µæ¿å—Alphaæ’åä¸Šå‡é€Ÿåº¦
        
        å‚æ•°:
            benchmark_code: åŸºå‡†æŒ‡æ•°ä»£ç ï¼ˆé»˜è®¤ï¼š000300.SHæ²ªæ·±300ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
        
        è¿”å›:
            åŒ…å«æ’åä¸Šå‡é€Ÿåº¦çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬ï¼š
            - æ¿å—å½“å¤©alphaå€¼
            - ç›¸è¾ƒæ˜¨æ—¥ä¸Šå‡ä½æ•°
            - ç›¸è¾ƒå‰å¤©ä¸Šå‡ä½æ•°
            - ä¸€å¤©å†…ä¸Šå‡ä½æ•°æ’è¡Œ
            - ä¸¤å¤©å†…ä¸Šå‡ä½æ•°æ’è¡Œ
        
        è¯´æ˜:
            - è‡ªåŠ¨è·å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰æ¦‚å¿µæ¿å—
            - è®¡ç®—æ’åä¸Šå‡é€Ÿåº¦ï¼ˆå½“å¤©å¯¹æ¯”å‰ä¸€å¤©å’Œå‰ä¸¤å¤©çš„æ’åå˜åŒ–ï¼‰
            - æ­£æ•°è¡¨ç¤ºæ’åä¸Šå‡ï¼Œè´Ÿæ•°è¡¨ç¤ºæ’åä¸‹é™
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        try:
            # å¦‚æœend_dateä¸ºç©ºï¼Œä½¿ç”¨Noneè®©calculate_alpha_rank_velocityä½¿ç”¨é»˜è®¤å€¼
            if end_date == "":
                end_date = None
            
            # è·å–æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨
            concept_codes = get_concept_codes(end_date or datetime.now().strftime('%Y%m%d'))
            
            if not concept_codes:
                return "æ— æ³•è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œtokené…ç½®ã€‚\næç¤ºï¼šå¯èƒ½æ˜¯æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥Tushare tokenæ˜¯å¦æœ‰æ•ˆã€‚"
            
            # è®¡ç®—æ’åä¸Šå‡é€Ÿåº¦
            df = calculate_alpha_rank_velocity(concept_codes, benchmark_code, end_date)
            
            if df.empty:
                # å¦‚æœæ— æ³•è·å–æ’åä¸Šå‡é€Ÿåº¦æ•°æ®ï¼Œå°è¯•è·å–å½“å‰æ’åä½œä¸ºé™çº§æ–¹æ¡ˆ
                today = datetime.now().strftime('%Y%m%d')
                df_current = rank_sectors_alpha(concept_codes, benchmark_code, today)
                if not df_current.empty:
                    # è¿”å›å½“å‰æ’åï¼Œä½†æç¤ºæ— æ³•è·å–å†å²æ’å
                    return f"âš ï¸ æ— æ³•è·å–å†å²æ’åæ•°æ®ï¼Œä»…æ˜¾ç¤ºå½“å‰æ’åï¼š\n\n" + format_alpha_analysis(df_current) + "\n\næç¤ºï¼šå¯èƒ½æ˜¯APIé™æµæˆ–å†å²æ•°æ®ç¼ºå¤±ï¼Œè¯·ç¨åé‡è¯•è·å–æ’åä¸Šå‡é€Ÿåº¦åˆ†æã€‚"
                else:
                    return "æ— æ³•è·å–æ¿å—æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œtokené…ç½®ã€‚\næç¤ºï¼šå¦‚æœæ‰€æœ‰æ¿å—éƒ½è¿”å›é”™è¯¯ï¼Œå¯èƒ½æ˜¯æ•°æ®è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥Tushare tokenæ˜¯å¦æœ‰æ•ˆã€‚"
            
            # è·å–å®é™…ä½¿ç”¨çš„æ—¥æœŸä¿¡æ¯
            current_date = df.attrs.get('current_date', 'æœªçŸ¥')
            yesterday_date = df.attrs.get('yesterday_date', None)
            day_before_yesterday_date = df.attrs.get('day_before_yesterday_date', None)
            
            # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
            def format_date_display(date_str):
                """æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤ºï¼ˆYYYYMMDD -> YYYY-MM-DDï¼‰"""
                if date_str and len(str(date_str)) == 8:
                    date_str = str(date_str)
                    return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
                return str(date_str) if date_str else "æ— æ•°æ®"
            
            current_date_display = format_date_display(current_date)
            yesterday_date_display = format_date_display(yesterday_date)
            day_before_yesterday_date_display = format_date_display(day_before_yesterday_date)
            
            # æ ¼å¼åŒ–è¾“å‡º
            output = []
            output.append("ğŸ“Š ä¸œè´¢æ¦‚å¿µæ¿å—Alphaæ’åä¸Šå‡é€Ÿåº¦åˆ†æ")
            output.append("=" * 120)
            output.append("")
            output.append(f"ğŸ“… åˆ†ææ—¥æœŸï¼š")
            output.append(f"  - å½“å‰æ—¥æœŸï¼š{current_date_display} ({current_date})")
            output.append(f"  - å¯¹æ¯”æ—¥æœŸ1ï¼ˆè¾ƒæ˜¨æ—¥ï¼‰ï¼š{yesterday_date_display} ({yesterday_date if yesterday_date else 'æ— æ•°æ®'})")
            output.append(f"  - å¯¹æ¯”æ—¥æœŸ2ï¼ˆè¾ƒå‰å¤©ï¼‰ï¼š{day_before_yesterday_date_display} ({day_before_yesterday_date if day_before_yesterday_date else 'æ— æ•°æ®'})")
            output.append("")
            
            # æ˜¾ç¤ºæ‰€æœ‰æ¿å—çš„åŸºæœ¬ä¿¡æ¯
            output.append("ğŸ“ˆ æ‰€æœ‰æ¿å—Alphaå€¼åŠæ’åå˜åŒ–ï¼š")
            output.append("-" * 120)
            change_1d_label = f"è¾ƒ{yesterday_date_display}å˜åŒ–" if yesterday_date else "è¾ƒæ˜¨æ—¥ä¸Šå‡"
            change_2d_label = f"è¾ƒ{day_before_yesterday_date_display}å˜åŒ–" if day_before_yesterday_date else "è¾ƒå‰å¤©ä¸Šå‡"
            output.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {'Alphaå€¼':<12} {change_1d_label:<20} {change_2d_label:<20}")
            output.append("-" * 120)
            
            # æŒ‰å½“å‰æ’åæ’åº
            df_sorted = df.sort_values('current_rank', ascending=True)
            
            for _, row in df_sorted.iterrows():
                rank = f"{int(row['current_rank'])}"
                concept_code = row['sector_code']
                alpha = f"{row['current_alpha']*100:.2f}%" if pd.notna(row['current_alpha']) else "-"
                
                # è¾ƒæ˜¨æ—¥ä¸Šå‡ä½æ•°
                if pd.notna(row['rank_change_1d']):
                    change_1d = f"{int(row['rank_change_1d']):+d}"
                    if row['rank_change_1d'] > 0:
                        change_1d += " â¬†ï¸"
                    elif row['rank_change_1d'] < 0:
                        change_1d += " â¬‡ï¸"
                    else:
                        change_1d += " â–"
                else:
                    change_1d = "-"
                
                # è¾ƒå‰å¤©ä¸Šå‡ä½æ•°
                if pd.notna(row['rank_change_2d']):
                    change_2d = f"{int(row['rank_change_2d']):+d}"
                    if row['rank_change_2d'] > 0:
                        change_2d += " â¬†ï¸"
                    elif row['rank_change_2d'] < 0:
                        change_2d += " â¬‡ï¸"
                    else:
                        change_2d += " â–"
                else:
                    change_2d = "-"
                
                output.append(f"{rank:<6} {concept_code:<15} {alpha:<12} {change_1d:<12} {change_2d:<12}")
            
            output.append("")
            
            # ä¸€å¤©å†…ä¸Šå‡ä½æ•°æ’è¡Œï¼ˆåªæ˜¾ç¤ºæœ‰æ•°æ®çš„ï¼‰
            df_1d = df[df['rank_change_1d'].notna()].copy()
            if not df_1d.empty:
                df_1d = df_1d.sort_values('rank_change_1d', ascending=False)
                output.append(f"ğŸš€ è¾ƒ{yesterday_date_display}æ’åå˜åŒ–æ’è¡Œï¼ˆå‰10åï¼‰ï¼š")
                output.append("-" * 120)
                output.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {f'{current_date_display}æ’å':<15} {'æ’åå˜åŒ–':<12} {'Alphaå€¼':<12}")
                output.append("-" * 120)
                
                for idx, (_, row) in enumerate(df_1d.head(10).iterrows(), 1):
                    rank = f"{int(row['current_rank'])}"
                    concept_code = row['sector_code']
                    change_1d = f"{int(row['rank_change_1d']):+d}"
                    alpha = f"{row['current_alpha']*100:.2f}%" if pd.notna(row['current_alpha']) else "-"
                    output.append(f"{idx:<6} {concept_code:<15} {rank:<15} {change_1d:<12} {alpha:<12}")
                
                output.append("")
            
            # ä¸¤å¤©å†…ä¸Šå‡ä½æ•°æ’è¡Œï¼ˆåªæ˜¾ç¤ºæœ‰æ•°æ®çš„ï¼‰
            df_2d = df[df['rank_change_2d'].notna()].copy()
            if not df_2d.empty:
                df_2d = df_2d.sort_values('rank_change_2d', ascending=False)
                output.append(f"ğŸš€ è¾ƒ{day_before_yesterday_date_display}æ’åå˜åŒ–æ’è¡Œï¼ˆå‰10åï¼‰ï¼š")
                output.append("-" * 120)
                output.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {f'{current_date_display}æ’å':<15} {'æ’åå˜åŒ–':<12} {'Alphaå€¼':<12}")
                output.append("-" * 120)
                
                for idx, (_, row) in enumerate(df_2d.head(10).iterrows(), 1):
                    rank = f"{int(row['current_rank'])}"
                    concept_code = row['sector_code']
                    change_2d = f"{int(row['rank_change_2d']):+d}"
                    alpha = f"{row['current_alpha']*100:.2f}%" if pd.notna(row['current_alpha']) else "-"
                    output.append(f"{idx:<6} {concept_code:<15} {rank:<15} {change_2d:<12} {alpha:<12}")
                
                output.append("")
            
            output.append("ğŸ“ è¯´æ˜ï¼š")
            output.append("  - Alpha = æ¿å—æ”¶ç›Šç‡ - åŸºå‡†æ”¶ç›Šç‡ï¼ˆæ²ªæ·±300ï¼‰")
            output.append("  - æ’åå˜åŒ– = å¯¹æ¯”æ—¥æœŸæ’å - å½“å‰æ’åï¼ˆæ­£æ•°è¡¨ç¤ºæ’åä¸Šå‡ï¼‰")
            output.append(f"  - å½“å‰æ—¥æœŸï¼š{current_date_display} ({current_date})")
            if yesterday_date:
                output.append(f"  - å¯¹æ¯”æ—¥æœŸ1ï¼š{yesterday_date_display} ({yesterday_date})")
            if day_before_yesterday_date:
                output.append(f"  - å¯¹æ¯”æ—¥æœŸ2ï¼š{day_before_yesterday_date_display} ({day_before_yesterday_date})")
            output.append("  - å»ºè®®å…³æ³¨æ’åå˜åŒ–è¾ƒå¤§çš„æ¿å—ï¼Œå¯èƒ½å…·æœ‰è¾ƒå¼ºåŠ¨èƒ½")
            output.append("")
            output.append(f"ğŸ“Š ç»Ÿè®¡ï¼šå…±åˆ†æ {len(df)} ä¸ªæ¦‚å¿µæ¿å—")
            
            return "\n".join(output)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def get_concept_moneyflow_dc(
        ts_code: str = "",
        trade_date: str = "",
        start_date: str = "",
        end_date: str = "",
        content_type: str = ""
    ) -> str:
        """
        è·å–ä¸œæ–¹è´¢å¯Œæ¿å—èµ„é‡‘æµå‘æ•°æ®ï¼ˆæ¦‚å¿µã€è¡Œä¸šã€åœ°åŸŸï¼‰
        
        å‚æ•°:
            ts_code: æ¿å—ä»£ç ï¼ˆå¦‚ï¼šBK1184.DCï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰æ¿å—ï¼‰
            trade_date: äº¤æ˜“æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œå¦‚ï¼š20240927ï¼ŒæŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸end_dateé…åˆä½¿ç”¨ï¼‰
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œéœ€ä¸start_dateé…åˆä½¿ç”¨ï¼‰
            content_type: èµ„é‡‘ç±»å‹ï¼ˆè¡Œä¸šã€æ¦‚å¿µã€åœ°åŸŸï¼Œç•™ç©ºåˆ™æŸ¥è¯¢æ‰€æœ‰ç±»å‹ï¼‰
        
        è¿”å›:
            åŒ…å«æ¿å—èµ„é‡‘æµå‘æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
        
        è¯´æ˜:
            - æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œï¼Œæ¯å¤©ç›˜åæ›´æ–°
            - æ”¯æŒæŒ‰æ¿å—ä»£ç ã€äº¤æ˜“æ—¥æœŸã€æ—¥æœŸèŒƒå›´ã€èµ„é‡‘ç±»å‹ç­›é€‰
            - æ˜¾ç¤ºä¸»åŠ›å‡€æµå…¥é¢ã€è¶…å¤§å•/å¤§å•/ä¸­å•/å°å•çš„å‡€æµå…¥é¢å’Œå æ¯”
            - æ˜¾ç¤ºä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡ã€æ’åç­‰ä¿¡æ¯
            - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†
            - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è°ƒå–5000æ¡æ•°æ®ï¼Œå¯ä»¥æ ¹æ®æ—¥æœŸå’Œä»£ç å¾ªç¯æå–å…¨éƒ¨æ•°æ®
        """
        token = get_tushare_token()
        if not token:
            return "è¯·å…ˆé…ç½®Tushare token"
        
        # å‚æ•°éªŒè¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not ts_code and not trade_date and not start_date and not end_date:
            return "è¯·è‡³å°‘æä¾›ä»¥ä¸‹å‚æ•°ä¹‹ä¸€ï¼šæ¿å—ä»£ç (ts_code)ã€äº¤æ˜“æ—¥æœŸ(trade_date)æˆ–æ—¥æœŸèŒƒå›´(start_date/end_date)"
        
        try:
            pro = ts.pro_api()
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            params = {}
            if ts_code:
                params['ts_code'] = ts_code
            if trade_date:
                params['trade_date'] = trade_date
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            if content_type:
                params['content_type'] = content_type
            
            # å¦‚æœåŒæ—¶æä¾›äº†trade_dateå’Œæ—¥æœŸèŒƒå›´ï¼Œä¼˜å…ˆä½¿ç”¨trade_date
            if trade_date and (start_date or end_date):
                params.pop('start_date', None)
                params.pop('end_date', None)
            
            # å°è¯•ä»ç¼“å­˜è·å–ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿè¿”å›ï¼‰
            cache_params = {
                'ts_code': ts_code or '',
                'trade_date': trade_date or '',
                'start_date': start_date or '',
                'end_date': end_date or '',
                'content_type': content_type or ''
            }
            df = cache_manager.get_dataframe('moneyflow_ind_dc', **cache_params)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆè¿‡æœŸåç«‹å³æ›´æ–°ï¼‰
            need_update = False
            if df is None:
                need_update = True
            elif cache_manager.is_expired('moneyflow_ind_dc', **cache_params):
                need_update = True
            
            if need_update:
                # è¿‡æœŸåç«‹å³æ›´æ–°ï¼ˆåŒæ­¥ï¼‰
                df = pro.moneyflow_ind_dc(**params)
                
                # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆåˆ›å»ºæ–°ç‰ˆæœ¬ï¼‰
                if not df.empty:
                    cache_manager.set('moneyflow_ind_dc', df, **cache_params)
            
            if df.empty:
                param_info = []
                if ts_code:
                    param_info.append(f"æ¿å—ä»£ç : {ts_code}")
                if trade_date:
                    param_info.append(f"äº¤æ˜“æ—¥æœŸ: {trade_date}")
                if start_date or end_date:
                    param_info.append(f"æ—¥æœŸèŒƒå›´: {start_date or 'å¼€å§‹'} è‡³ {end_date or 'ç»“æŸ'}")
                if content_type:
                    param_info.append(f"èµ„é‡‘ç±»å‹: {content_type}")
                
                return f"æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¿å—èµ„é‡‘æµå‘æ•°æ®\næŸ¥è¯¢æ¡ä»¶: {', '.join(param_info)}"
            
            # æŒ‰äº¤æ˜“æ—¥æœŸå’Œæ’åæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼Œæ’åå‡åºï¼‰
            sort_columns = []
            if 'trade_date' in df.columns:
                sort_columns.append('trade_date')
            if 'rank' in df.columns:
                sort_columns.append('rank')
            if sort_columns:
                df = df.sort_values(sort_columns, ascending=[False, True])
            
            # æ ¼å¼åŒ–è¾“å‡º
            return format_concept_moneyflow_dc_data(df, ts_code, content_type or "")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}\nè¯¦ç»†ä¿¡æ¯ï¼š{error_detail}"
    
    @mcp.tool()
    def scan_concepts_volume_anomaly(
        end_date: str = "",
        vol_ratio_threshold: float = 1.15,
        price_change_5d_min: float = 0.02,
        price_change_5d_max: float = 0.08,
        hot_limit: int = 160
    ) -> str:
        """
        åˆ†æä¸œè´¢æ¦‚å¿µæ¿å—æˆäº¤é‡å¼‚åŠ¨
        
        å‚æ•°:
            end_date: ç»“æŸæ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©ï¼‰
            vol_ratio_threshold: æˆäº¤é‡æ¯”ç‡é˜ˆå€¼ï¼ˆé»˜è®¤1.8ï¼Œå³MA3/MA10 > 1.8ï¼Œèµ„é‡‘è¿›åœºï¼‰
            price_change_5d_min: 5æ—¥æ¶¨å¹…æœ€å°å€¼ï¼ˆé»˜è®¤0.02ï¼Œå³2%ï¼Œå³ä¾§å¯åŠ¨ï¼‰
            price_change_5d_max: 5æ—¥æ¶¨å¹…æœ€å¤§å€¼ï¼ˆé»˜è®¤0.08ï¼Œå³8%ï¼Œæ‹’ç»å·¦ä¾§æ­»é±¼ï¼‰
            hot_limit: æ‰«æçš„çƒ­é—¨æ¦‚å¿µæ¿å—æ•°é‡ï¼ˆé»˜è®¤80ï¼Œæ ¹æ®æˆäº¤é¢å’Œæ¢æ‰‹ç‡ç­›é€‰ï¼‰
        
        è¿”å›:
            JSONæ ¼å¼å­—ç¬¦ä¸²ï¼ŒåŒ…å«æ‰«æç»“æœ
        
        è¯´æ˜:
            - æ‰«æçƒ­é—¨ä¸œè´¢æ¦‚å¿µæ¿å—ï¼ˆæ ¹æ®æˆäº¤é¢å’Œæ¢æ‰‹ç‡ç­›é€‰ï¼‰
            - è®¡ç®—æŒ‡æ ‡ï¼š
              * Volume_Ratio = MA3_Vol / MA10_Vol
              * Price_Change_5dï¼ˆ5æ—¥æ¶¨å¹…ï¼‰
              * Turnover_Rateï¼ˆæ¢æ‰‹ç‡ï¼‰
            - ç­›é€‰é€»è¾‘ï¼š
              * Volume_Ratio > vol_ratio_thresholdï¼ˆèµ„é‡‘è¿›åœºï¼‰
              * price_change_5d_min < Price_Change_5d < price_change_5d_maxï¼ˆå³ä¾§å¯åŠ¨ï¼‰
            - å¦‚æœæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ•°æ®ï¼Œä¼šè¿”å›æœ€æ¥è¿‘çš„å‰10ä¸ªæ•°æ®ï¼Œå¹¶å±•ç¤ºå…·ä½“çš„å‚æ•°ç»†èŠ‚
        """
        token = get_tushare_token()
        if not token:
            return json.dumps({
                "error": "è¯·å…ˆé…ç½®Tushare token",
                "scanned_count": 0,
                "matched_count": 0,
                "matches": []
            }, ensure_ascii=False, indent=2, cls=NumpyEncoder)
        
        try:
            # å¦‚æœend_dateä¸ºç©ºï¼Œä½¿ç”¨Noneè®©å‡½æ•°ä½¿ç”¨é»˜è®¤å€¼
            if end_date == "":
                end_date = None
            
            # éªŒè¯å‚æ•°
            if vol_ratio_threshold <= 0:
                return json.dumps({
                    "error": "æˆäº¤é‡æ¯”ç‡é˜ˆå€¼å¿…é¡»å¤§äº0",
                    "scanned_count": 0,
                    "matched_count": 0,
                    "matches": []
                }, ensure_ascii=False, indent=2, cls=NumpyEncoder)
            
            if price_change_5d_min >= price_change_5d_max:
                return json.dumps({
                    "error": "5æ—¥æ¶¨å¹…æœ€å°å€¼å¿…é¡»å°äºæœ€å¤§å€¼",
                    "scanned_count": 0,
                    "matched_count": 0,
                    "matches": []
                }, ensure_ascii=False, indent=2, cls=NumpyEncoder)
            
            # æ‰«ææˆäº¤é‡å¼‚åŠ¨ï¼ˆè°ƒç”¨æ¨¡å—çº§åˆ«çš„å‡½æ•°ï¼‰
            result = scan_concept_volume_anomaly(
                end_date=end_date,
                vol_ratio_threshold=vol_ratio_threshold,
                price_change_5d_min=price_change_5d_min,
                price_change_5d_max=price_change_5d_max,
                hot_limit=hot_limit
            )
            
            # å¦‚æœæ²¡æœ‰åŒ¹é…çš„æ•°æ®ï¼Œæ ¼å¼åŒ–æœ€æ¥è¿‘çš„ç»“æœ
            if result.get('matched_count', 0) == 0 and 'closest_results' in result:
                # æ·»åŠ ç­›é€‰æ¡ä»¶ä¿¡æ¯
                result['filter_criteria'] = {
                    "vol_ratio_threshold": vol_ratio_threshold,
                    "price_change_5d_min": price_change_5d_min,
                    "price_change_5d_max": price_change_5d_max
                }
            
            # è¿”å›JSONæ ¼å¼å­—ç¬¦ä¸²ï¼ˆä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨å¤„ç†numpyç±»å‹ï¼‰
            return json.dumps(result, ensure_ascii=False, indent=2, cls=NumpyEncoder)
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            return json.dumps({
                "error": f"æ‰«æå¤±è´¥ï¼š{str(e)}",
                "details": error_detail,
                "scanned_count": 0,
                "matched_count": 0,
                "matches": []
            }, ensure_ascii=False, indent=2, cls=NumpyEncoder)

def format_concept_daily_data(df: pd.DataFrame, ts_code: str = "") -> str:
    """
    æ ¼å¼åŒ–æ¦‚å¿µæ¿å—è¡Œæƒ…æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ¦‚å¿µæ¿å—è¡Œæƒ…æ•°æ®DataFrame
        ts_code: æ¿å—ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¦‚å¿µæ¿å—è¡Œæƒ…æ•°æ®"
    
    result = []
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªæ¿å—æˆ–å¤šä¸ªæ¿å—
    if ts_code:
        # æŒ‰æ¿å—ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            code_df = df[df['ts_code'] == code]
            if not code_df.empty:
                result.append(format_single_concept_daily(code_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # å¦‚æœæœ‰å¤šä¸ªäº¤æ˜“æ—¥æœŸï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„æ˜¾ç¤º
        if 'trade_date' in df.columns and len(df['trade_date'].unique()) > 1:
            dates = sorted(df['trade_date'].unique(), reverse=True)
            for date in dates[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                date_df = df[df['trade_date'] == date]
                if not date_df.empty:
                    result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                    result.append("=" * 120)
                    result.append(f"{'æ¿å—ä»£ç ':<15} {'æ”¶ç›˜ç‚¹ä½':<12} {'æ¶¨è·Œç‚¹ä½':<12} {'æ¶¨è·Œå¹…':<10} {'æŒ¯å¹…':<10} {'æ¢æ‰‹ç‡':<10} {'æˆäº¤é‡':<15} {'æˆäº¤é¢':<15}")
                    result.append("-" * 120)
                    
                    # æŒ‰æ¶¨è·Œå¹…æ’åºï¼ˆé™åºï¼‰
                    if 'pct_change' in date_df.columns:
                        date_df = date_df.sort_values('pct_change', ascending=False)
                    
                    for _, row in date_df.iterrows():
                        code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
                        close = f"{row['close']:.2f}" if 'close' in row and pd.notna(row['close']) else "-"
                        change = f"{row['change']:+.2f}" if 'change' in row and pd.notna(row['change']) else "-"
                        pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
                        swing = f"{row['swing']:.2f}%" if 'swing' in row and pd.notna(row['swing']) else "-"
                        turnover_rate = f"{row['turnover_rate']:.2f}%" if 'turnover_rate' in row and pd.notna(row['turnover_rate']) else "-"
                        vol = f"{row['vol']:.0f}" if 'vol' in row and pd.notna(row['vol']) else "-"
                        amount = f"{row['amount']:.0f}" if 'amount' in row and pd.notna(row['amount']) else "-"
                        
                        result.append(f"{code:<15} {close:<12} {change:<12} {pct_change:<10} {swing:<10} {turnover_rate:<10} {vol:<15} {amount:<15}")
                    
                    result.append("")
            
            if len(dates) > 10:
                result.append(f"ï¼ˆå…± {len(dates)} ä¸ªäº¤æ˜“æ—¥ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ 10 ä¸ªï¼‰")
        else:
            # å•ä¸ªæ—¥æœŸæˆ–æ²¡æœ‰æ—¥æœŸå­—æ®µï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰æ¿å—
            result.append(f"ğŸ“ˆ å…±æ‰¾åˆ° {len(df)} ä¸ªæ¿å—")
            result.append("")
            result.append(f"{'æ¿å—ä»£ç ':<15} {'æ”¶ç›˜ç‚¹ä½':<12} {'æ¶¨è·Œç‚¹ä½':<12} {'æ¶¨è·Œå¹…':<10} {'æŒ¯å¹…':<10} {'æ¢æ‰‹ç‡':<10} {'æˆäº¤é‡':<15} {'æˆäº¤é¢':<15}")
            result.append("-" * 120)
            
            # æŒ‰æ¶¨è·Œå¹…æ’åºï¼ˆé™åºï¼‰
            if 'pct_change' in df.columns:
                df = df.sort_values('pct_change', ascending=False)
            
            for _, row in df.iterrows():
                code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
                close = f"{row['close']:.2f}" if 'close' in row and pd.notna(row['close']) else "-"
                change = f"{row['change']:+.2f}" if 'change' in row and pd.notna(row['change']) else "-"
                pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
                swing = f"{row['swing']:.2f}%" if 'swing' in row and pd.notna(row['swing']) else "-"
                turnover_rate = f"{row['turnover_rate']:.2f}%" if 'turnover_rate' in row and pd.notna(row['turnover_rate']) else "-"
                vol = f"{row['vol']:.0f}" if 'vol' in row and pd.notna(row['vol']) else "-"
                amount = f"{row['amount']:.0f}" if 'amount' in row and pd.notna(row['amount']) else "-"
                
                result.append(f"{code:<15} {close:<12} {change:<12} {pct_change:<10} {swing:<10} {turnover_rate:<10} {vol:<15} {amount:<15}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            result.append("")
            result.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
            
            if 'pct_change' in df.columns:
                positive_count = len(df[df['pct_change'] > 0])
                negative_count = len(df[df['pct_change'] < 0])
                flat_count = len(df[df['pct_change'] == 0])
                result.append(f"  - ä¸Šæ¶¨æ¿å—: {positive_count} ä¸ª")
                result.append(f"  - ä¸‹è·Œæ¿å—: {negative_count} ä¸ª")
                result.append(f"  - å¹³ç›˜æ¿å—: {flat_count} ä¸ª")
                
                if not df['pct_change'].isna().all():
                    max_pct = df['pct_change'].max()
                    min_pct = df['pct_change'].min()
                    result.append(f"  - æœ€å¤§æ¶¨è·Œå¹…: {max_pct:+.2f}%")
                    result.append(f"  - æœ€å°æ¶¨è·Œå¹…: {min_pct:+.2f}%")
            
            if 'turnover_rate' in df.columns:
                if not df['turnover_rate'].isna().all():
                    avg_turnover = df['turnover_rate'].mean()
                    result.append(f"  - å¹³å‡æ¢æ‰‹ç‡: {avg_turnover:.2f}%")
            
            result.append("")
            result.append("ğŸ“ è¯´æ˜ï¼š")
            result.append("  - æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œæ¦‚å¿µ/è¡Œä¸š/åœ°åŸŸæ¿å—")
            result.append("  - å†å²æ•°æ®å¼€å§‹äº2020å¹´")
            result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§2000æ¡æ•°æ®")
    
    return "\n".join(result)

def format_single_concept_daily(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªæ¿å—çš„æ—¥çº¿è¡Œæƒ…æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªæ¿å—çš„æ—¥çº¿è¡Œæƒ…æ•°æ®DataFrame
        ts_code: æ¿å—ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„è¡Œæƒ…æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    result.append(f"ğŸ“ˆ {ts_code} æ—¥çº¿è¡Œæƒ…")
    result.append("=" * 120)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š20æ¡ï¼‰
    display_count = min(20, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'å¼€ç›˜':<12} {'æœ€é«˜':<12} {'æœ€ä½':<12} {'æ”¶ç›˜':<12} {'æ¶¨è·Œç‚¹ä½':<12} {'æ¶¨è·Œå¹…':<10} {'æŒ¯å¹…':<10} {'æ¢æ‰‹ç‡':<10} {'æˆäº¤é‡':<15} {'æˆäº¤é¢':<15}")
    result.append("-" * 140)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(row['trade_date'])
        open_price = f"{row['open']:.2f}" if pd.notna(row['open']) else "-"
        high = f"{row['high']:.2f}" if pd.notna(row['high']) else "-"
        low = f"{row['low']:.2f}" if pd.notna(row['low']) else "-"
        close = f"{row['close']:.2f}" if pd.notna(row['close']) else "-"
        change = f"{row['change']:+.2f}" if pd.notna(row['change']) else "-"
        pct_change = f"{row['pct_change']:+.2f}%" if pd.notna(row['pct_change']) else "-"
        swing = f"{row['swing']:.2f}%" if pd.notna(row['swing']) else "-"
        turnover_rate = f"{row['turnover_rate']:.2f}%" if pd.notna(row['turnover_rate']) else "-"
        vol = f"{row['vol']:.0f}" if pd.notna(row['vol']) else "-"
        amount = f"{row['amount']:.0f}" if pd.notna(row['amount']) else "-"
        
        result.append(f"{trade_date:<12} {open_price:<12} {high:<12} {low:<12} {close:<12} {change:<12} {pct_change:<10} {swing:<10} {turnover_rate:<10} {vol:<15} {amount:<15}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 120)
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(latest['trade_date'])}")
        result.append(f"å¼€ç›˜ç‚¹ä½: {latest['open']:.2f}" if pd.notna(latest['open']) else "å¼€ç›˜ç‚¹ä½: -")
        result.append(f"æœ€é«˜ç‚¹ä½: {latest['high']:.2f}" if pd.notna(latest['high']) else "æœ€é«˜ç‚¹ä½: -")
        result.append(f"æœ€ä½ç‚¹ä½: {latest['low']:.2f}" if pd.notna(latest['low']) else "æœ€ä½ç‚¹ä½: -")
        result.append(f"æ”¶ç›˜ç‚¹ä½: {latest['close']:.2f}" if pd.notna(latest['close']) else "æ”¶ç›˜ç‚¹ä½: -")
        if pd.notna(latest.get('change')):
            result.append(f"æ¶¨è·Œç‚¹ä½: {latest['change']:+.2f}")
        if pd.notna(latest.get('pct_change')):
            result.append(f"æ¶¨è·Œå¹…: {latest['pct_change']:+.2f}%")
        if pd.notna(latest.get('swing')):
            result.append(f"æŒ¯å¹…: {latest['swing']:.2f}%")
        if pd.notna(latest.get('turnover_rate')):
            result.append(f"æ¢æ‰‹ç‡: {latest['turnover_rate']:.2f}%")
        if pd.notna(latest.get('vol')):
            result.append(f"æˆäº¤é‡: {latest['vol']:.0f}")
        if pd.notna(latest.get('amount')):
            result.append(f"æˆäº¤é¢: {latest['amount']:.0f}")
    
    return "\n".join(result)


def format_concept_moneyflow_dc_data(df: pd.DataFrame, ts_code: str = "", content_type: str = "") -> str:
    """
    æ ¼å¼åŒ–æ¿å—èµ„é‡‘æµå‘æ•°æ®è¾“å‡º
    
    å‚æ•°:
        df: æ¿å—èµ„é‡‘æµå‘æ•°æ®DataFrame
        ts_code: æ¿å—ä»£ç ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        content_type: èµ„é‡‘ç±»å‹ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ¿å—èµ„é‡‘æµå‘æ•°æ®"
    
    # æŒ‰äº¤æ˜“æ—¥æœŸå’Œæ’åæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼Œæ’åå‡åºï¼‰
    sort_columns = []
    if 'trade_date' in df.columns:
        sort_columns.append('trade_date')
    if 'rank' in df.columns:
        sort_columns.append('rank')
    if sort_columns:
        df = df.sort_values(sort_columns, ascending=[False, True])
    
    result = []
    
    # å¦‚æœæŸ¥è¯¢çš„æ˜¯å•ä¸ªæ¿å—æˆ–å¤šä¸ªæ¿å—
    if ts_code:
        # æŒ‰æ¿å—ä»£ç åˆ†ç»„æ˜¾ç¤º
        codes = [code.strip() for code in ts_code.split(',')]
        for code in codes:
            code_df = df[df['ts_code'] == code]
            if not code_df.empty:
                result.append(format_single_concept_moneyflow_dc(code_df, code))
                result.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”
    else:
        # å¦‚æœæœ‰å¤šä¸ªäº¤æ˜“æ—¥æœŸï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„æ˜¾ç¤º
        if 'trade_date' in df.columns and len(df['trade_date'].unique()) > 1:
            dates = sorted(df['trade_date'].unique(), reverse=True)
            for date in dates[:10]:  # æœ€å¤šæ˜¾ç¤ºæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
                date_df = df[df['trade_date'] == date]
                if not date_df.empty:
                    result.append(f"ğŸ“… äº¤æ˜“æ—¥æœŸ: {format_date(date)}")
                    result.append("=" * 180)
                    
                    # æŒ‰èµ„é‡‘ç±»å‹åˆ†ç»„
                    if content_type:
                        # æŒ‡å®šäº†ç±»å‹ï¼Œç›´æ¥æ˜¾ç¤º
                        result.append(format_moneyflow_table(date_df, content_type))
                    else:
                        # æœªæŒ‡å®šç±»å‹ï¼ŒæŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
                        if 'content_type' in date_df.columns:
                            types = date_df['content_type'].unique()
                            for ct in types:
                                type_df = date_df[date_df['content_type'] == ct]
                                if not type_df.empty:
                                    result.append(f"ğŸ“Š {ct}èµ„é‡‘æµå‘ï¼ˆæŒ‰ä¸»åŠ›å‡€æµå…¥æ’åºï¼‰ï¼š")
                                    result.append(format_moneyflow_table(type_df, ct))
                                    result.append("")
                        else:
                            result.append(format_moneyflow_table(date_df, ""))
                    result.append("")
        else:
            # å•ä¸ªæ—¥æœŸæˆ–å•ä¸ªæ¿å—ï¼Œä½¿ç”¨è¯¦ç»†æ ¼å¼
            if ts_code and len(df['ts_code'].unique()) == 1:
                result.append(format_single_concept_moneyflow_dc(df, df['ts_code'].iloc[0]))
            else:
                # æ˜¾ç¤ºæ‰€æœ‰æ¿å—
                result.append("ğŸ“Š æ¿å—èµ„é‡‘æµå‘æ•°æ®")
                result.append("=" * 180)
                
                # æŒ‰èµ„é‡‘ç±»å‹åˆ†ç»„
                if content_type:
                    result.append(format_moneyflow_table(df, content_type))
                else:
                    if 'content_type' in df.columns:
                        types = df['content_type'].unique()
                        for ct in types:
                            type_df = df[df['content_type'] == ct]
                            if not type_df.empty:
                                result.append(f"ğŸ“Š {ct}èµ„é‡‘æµå‘ï¼ˆæŒ‰ä¸»åŠ›å‡€æµå…¥æ’åºï¼‰ï¼š")
                                result.append(format_moneyflow_table(type_df, ct))
                                result.append("")
                    else:
                        result.append(format_moneyflow_table(df, ""))
    
    result.append("")
    result.append("ğŸ“ è¯´æ˜ï¼š")
    result.append("  - æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œï¼Œæ¯å¤©ç›˜åæ›´æ–°")
    result.append("  - ä¸»åŠ›å‡€æµå…¥ = è¶…å¤§å•å‡€æµå…¥ + å¤§å•å‡€æµå…¥")
    result.append("  - æ­£æ•°è¡¨ç¤ºå‡€æµå…¥ï¼Œè´Ÿæ•°è¡¨ç¤ºå‡€æµå‡º")
    result.append("  - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†")
    result.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è°ƒå–5000æ¡æ•°æ®")
    
    return "\n".join(result)


def format_moneyflow_table(df: pd.DataFrame, content_type: str = "") -> str:
    """
    æ ¼å¼åŒ–èµ„é‡‘æµå‘è¡¨æ ¼
    
    å‚æ•°:
        df: èµ„é‡‘æµå‘æ•°æ®DataFrame
        content_type: èµ„é‡‘ç±»å‹
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„è¡¨æ ¼å­—ç¬¦ä¸²
    """
    if df.empty:
        return ""
    
    # æŒ‰ä¸»åŠ›å‡€æµå…¥é¢æ’åºï¼ˆé™åºï¼‰
    if 'net_amount' in df.columns:
        df = df.sort_values('net_amount', ascending=False)
    
    # é‡ç½®ç´¢å¼•ï¼Œä»¥ä¾¿ç”Ÿæˆè¿ç»­åºå·
    df = df.reset_index(drop=True)
    
    result = []
    result.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {'æ¿å—åç§°':<20} {'æ¶¨è·Œå¹…':<10} {'æœ€æ–°æŒ‡æ•°':<12} {'ä¸»åŠ›å‡€æµå…¥(å…ƒ)':<18} {'ä¸»åŠ›å‡€æµå…¥å æ¯”':<16} {'è¶…å¤§å•å‡€æµå…¥(å…ƒ)':<18} {'è¶…å¤§å•å æ¯”':<14} {'å¤§å•å‡€æµå…¥(å…ƒ)':<16} {'å¤§å•å æ¯”':<12} {'ä¸­å•å‡€æµå…¥(å…ƒ)':<16} {'ä¸­å•å æ¯”':<12} {'å°å•å‡€æµå…¥(å…ƒ)':<16} {'å°å•å æ¯”':<12} {'ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡':<20}")
    result.append("-" * 180)
    
    for idx, (_, row) in enumerate(df.iterrows(), start=1):
        rank = str(idx)  # ä½¿ç”¨è¿ç»­åºå·ï¼Œè€Œä¸æ˜¯åŸå§‹rankå­—æ®µ
        code = str(row['ts_code']) if 'ts_code' in row and pd.notna(row['ts_code']) else "-"
        name = str(row['name'])[:18] if 'name' in row and pd.notna(row['name']) else "-"
        pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
        close = f"{row['close']:.2f}" if 'close' in row and pd.notna(row['close']) else "-"
        net_amount = f"{row['net_amount']:.2f}" if 'net_amount' in row and pd.notna(row['net_amount']) else "-"
        net_amount_rate = f"{row['net_amount_rate']:+.2f}%" if 'net_amount_rate' in row and pd.notna(row['net_amount_rate']) else "-"
        buy_elg_amount = f"{row['buy_elg_amount']:.2f}" if 'buy_elg_amount' in row and pd.notna(row['buy_elg_amount']) else "-"
        buy_elg_amount_rate = f"{row['buy_elg_amount_rate']:+.2f}%" if 'buy_elg_amount_rate' in row and pd.notna(row['buy_elg_amount_rate']) else "-"
        buy_lg_amount = f"{row['buy_lg_amount']:.2f}" if 'buy_lg_amount' in row and pd.notna(row['buy_lg_amount']) else "-"
        buy_lg_amount_rate = f"{row['buy_lg_amount_rate']:+.2f}%" if 'buy_lg_amount_rate' in row and pd.notna(row['buy_lg_amount_rate']) else "-"
        buy_md_amount = f"{row['buy_md_amount']:.2f}" if 'buy_md_amount' in row and pd.notna(row['buy_md_amount']) else "-"
        buy_md_amount_rate = f"{row['buy_md_amount_rate']:+.2f}%" if 'buy_md_amount_rate' in row and pd.notna(row['buy_md_amount_rate']) else "-"
        buy_sm_amount = f"{row['buy_sm_amount']:.2f}" if 'buy_sm_amount' in row and pd.notna(row['buy_sm_amount']) else "-"
        buy_sm_amount_rate = f"{row['buy_sm_amount_rate']:+.2f}%" if 'buy_sm_amount_rate' in row and pd.notna(row['buy_sm_amount_rate']) else "-"
        max_stock = str(row['buy_sm_amount_stock'])[:18] if 'buy_sm_amount_stock' in row and pd.notna(row['buy_sm_amount_stock']) else "-"
        
        result.append(f"{rank:<6} {code:<15} {name:<20} {pct_change:<10} {close:<12} {net_amount:<18} {net_amount_rate:<16} {buy_elg_amount:<18} {buy_elg_amount_rate:<14} {buy_lg_amount:<16} {buy_lg_amount_rate:<12} {buy_md_amount:<16} {buy_md_amount_rate:<12} {buy_sm_amount:<16} {buy_sm_amount_rate:<12} {max_stock:<20}")
    
    return "\n".join(result)


def format_single_concept_moneyflow_dc(df: pd.DataFrame, ts_code: str) -> str:
    """
    æ ¼å¼åŒ–å•ä¸ªæ¿å—çš„èµ„é‡‘æµå‘æ•°æ®
    
    å‚æ•°:
        df: å•ä¸ªæ¿å—çš„èµ„é‡‘æµå‘æ•°æ®DataFrame
        ts_code: æ¿å—ä»£ç 
    
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
    """
    if df.empty:
        return f"æœªæ‰¾åˆ° {ts_code} çš„èµ„é‡‘æµå‘æ•°æ®"
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    df = df.sort_values('trade_date', ascending=False)
    
    result = []
    sector_name = str(df.iloc[0]['name']) if 'name' in df.columns and pd.notna(df.iloc[0]['name']) else ts_code
    content_type = str(df.iloc[0]['content_type']) if 'content_type' in df.columns and pd.notna(df.iloc[0]['content_type']) else ""
    result.append(f"ğŸ’° {ts_code} {sector_name} èµ„é‡‘æµå‘æ•°æ®")
    if content_type:
        result.append(f"ğŸ“Š ç±»å‹ï¼š{content_type}")
    result.append("=" * 180)
    result.append("")
    
    # æ˜¾ç¤ºæœ€è¿‘çš„æ•°æ®ï¼ˆæœ€å¤š30æ¡ï¼‰
    display_count = min(30, len(df))
    result.append(f"æœ€è¿‘ {display_count} ä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼š")
    result.append("")
    result.append(f"{'æ—¥æœŸ':<12} {'æ¶¨è·Œå¹…':<10} {'æœ€æ–°æŒ‡æ•°':<12} {'ä¸»åŠ›å‡€æµå…¥(å…ƒ)':<18} {'ä¸»åŠ›å‡€æµå…¥å æ¯”':<16} {'è¶…å¤§å•å‡€æµå…¥(å…ƒ)':<18} {'è¶…å¤§å•å æ¯”':<14} {'å¤§å•å‡€æµå…¥(å…ƒ)':<16} {'å¤§å•å æ¯”':<12} {'ä¸­å•å‡€æµå…¥(å…ƒ)':<16} {'ä¸­å•å æ¯”':<12} {'å°å•å‡€æµå…¥(å…ƒ)':<16} {'å°å•å æ¯”':<12} {'ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡':<20} {'æ’å':<6}")
    result.append("-" * 180)
    
    for _, row in df.head(display_count).iterrows():
        trade_date = format_date(str(row['trade_date']))
        pct_change = f"{row['pct_change']:+.2f}%" if 'pct_change' in row and pd.notna(row['pct_change']) else "-"
        close = f"{row['close']:.2f}" if 'close' in row and pd.notna(row['close']) else "-"
        net_amount = f"{row['net_amount']:.2f}" if 'net_amount' in row and pd.notna(row['net_amount']) else "-"
        net_amount_rate = f"{row['net_amount_rate']:+.2f}%" if 'net_amount_rate' in row and pd.notna(row['net_amount_rate']) else "-"
        buy_elg_amount = f"{row['buy_elg_amount']:.2f}" if 'buy_elg_amount' in row and pd.notna(row['buy_elg_amount']) else "-"
        buy_elg_amount_rate = f"{row['buy_elg_amount_rate']:+.2f}%" if 'buy_elg_amount_rate' in row and pd.notna(row['buy_elg_amount_rate']) else "-"
        buy_lg_amount = f"{row['buy_lg_amount']:.2f}" if 'buy_lg_amount' in row and pd.notna(row['buy_lg_amount']) else "-"
        buy_lg_amount_rate = f"{row['buy_lg_amount_rate']:+.2f}%" if 'buy_lg_amount_rate' in row and pd.notna(row['buy_lg_amount_rate']) else "-"
        buy_md_amount = f"{row['buy_md_amount']:.2f}" if 'buy_md_amount' in row and pd.notna(row['buy_md_amount']) else "-"
        buy_md_amount_rate = f"{row['buy_md_amount_rate']:+.2f}%" if 'buy_md_amount_rate' in row and pd.notna(row['buy_md_amount_rate']) else "-"
        buy_sm_amount = f"{row['buy_sm_amount']:.2f}" if 'buy_sm_amount' in row and pd.notna(row['buy_sm_amount']) else "-"
        buy_sm_amount_rate = f"{row['buy_sm_amount_rate']:+.2f}%" if 'buy_sm_amount_rate' in row and pd.notna(row['buy_sm_amount_rate']) else "-"
        max_stock = str(row['buy_sm_amount_stock'])[:18] if 'buy_sm_amount_stock' in row and pd.notna(row['buy_sm_amount_stock']) else "-"
        rank = f"{int(row['rank'])}" if 'rank' in row and pd.notna(row['rank']) else "-"
        
        result.append(f"{trade_date:<12} {pct_change:<10} {close:<12} {net_amount:<18} {net_amount_rate:<16} {buy_elg_amount:<18} {buy_elg_amount_rate:<14} {buy_lg_amount:<16} {buy_lg_amount_rate:<12} {buy_md_amount:<16} {buy_md_amount_rate:<12} {buy_sm_amount:<16} {buy_sm_amount_rate:<12} {max_stock:<20} {rank:<6}")
    
    # å¦‚æœæœ‰æ›´å¤šæ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if len(df) > display_count:
        result.append("")
        result.append(f"ï¼ˆå…± {len(df)} æ¡æ•°æ®ï¼Œä»…æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡ï¼‰")
    
    # æ˜¾ç¤ºæœ€æ–°æ•°æ®æ‘˜è¦
    if not df.empty:
        latest = df.iloc[0]
        result.append("")
        result.append("ğŸ“Š æœ€æ–°æ•°æ®æ‘˜è¦ï¼š")
        result.append("-" * 180)
        trade_date_str = str(latest.get('trade_date', '-'))
        result.append(f"äº¤æ˜“æ—¥æœŸ: {format_date(trade_date_str)}")
        result.append(f"æ¿å—åç§°: {latest.get('name', '-')}")
        if 'content_type' in latest and pd.notna(latest['content_type']):
            result.append(f"èµ„é‡‘ç±»å‹: {latest['content_type']}")
        result.append(f"æ¶¨è·Œå¹…: {latest.get('pct_change', 0):+.2f}%" if pd.notna(latest.get('pct_change')) else "æ¶¨è·Œå¹…: -")
        result.append(f"æœ€æ–°æŒ‡æ•°: {latest.get('close', 0):.2f}" if pd.notna(latest.get('close')) else "æœ€æ–°æŒ‡æ•°: -")
        if 'rank' in latest and pd.notna(latest['rank']):
            result.append(f"æ’å: {int(latest['rank'])}")
        result.append("")
        result.append("èµ„é‡‘æµå‘ï¼š")
        result.append(f"  ä¸»åŠ›å‡€æµå…¥: {latest.get('net_amount', 0):.2f} å…ƒ ({latest.get('net_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('net_amount')) else "  ä¸»åŠ›å‡€æµå…¥: -")
        result.append(f"  è¶…å¤§å•å‡€æµå…¥: {latest.get('buy_elg_amount', 0):.2f} å…ƒ ({latest.get('buy_elg_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_elg_amount')) else "  è¶…å¤§å•å‡€æµå…¥: -")
        result.append(f"  å¤§å•å‡€æµå…¥: {latest.get('buy_lg_amount', 0):.2f} å…ƒ ({latest.get('buy_lg_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_lg_amount')) else "  å¤§å•å‡€æµå…¥: -")
        result.append(f"  ä¸­å•å‡€æµå…¥: {latest.get('buy_md_amount', 0):.2f} å…ƒ ({latest.get('buy_md_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_md_amount')) else "  ä¸­å•å‡€æµå…¥: -")
        result.append(f"  å°å•å‡€æµå…¥: {latest.get('buy_sm_amount', 0):.2f} å…ƒ ({latest.get('buy_sm_amount_rate', 0):+.2f}%)" if pd.notna(latest.get('buy_sm_amount')) else "  å°å•å‡€æµå…¥: -")
        if 'buy_sm_amount_stock' in latest and pd.notna(latest['buy_sm_amount_stock']):
            result.append(f"  ä¸»åŠ›å‡€æµå…¥æœ€å¤§è‚¡: {latest['buy_sm_amount_stock']}")
    
    return "\n".join(result)
