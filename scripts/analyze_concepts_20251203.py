"""
åˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—çš„å„é¡¹æ•°æ®å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
æ”¯æŒæŒ‡å®šæ—¥æœŸï¼ŒåŒ…å«5ä¸ªä»»åŠ¡ï¼š
1. é‡ä»·å¼‚åŠ¨åˆ†æ
2. Alphaæ”¶ç›Šæ’è¡Œ
3. èµ„é‡‘æµå…¥æƒ…å†µ
4. Alphaå¢é•¿é€Ÿåº¦æ’è¡Œ
5. æ¶¨è·Œåœè‚¡ç¥¨æ•°æ®
"""
import sys
import argparse
from pathlib import Path
import time
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config.token_manager import get_tushare_token, init_env_file
import tushare as ts
import pandas as pd
from tools.concept_tools import (
    scan_concept_volume_anomaly,
    get_hot_concept_codes,
    get_concept_codes
)
from tools.alpha_strategy_analyzer import (
    rank_sectors_alpha,
    calculate_alpha_rank_velocity,
    format_alpha_analysis
)
from tools.stock_tools import format_limit_list_data, format_large_number
from cache.cache_manager import cache_manager
from utils.common import format_date

# è§£æå‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description='åˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®')
parser.add_argument(
    '--date', 
    type=str, 
    default=None,
    help='åˆ†ææ—¥æœŸï¼Œæ ¼å¼ï¼šYYYYMMDDï¼ˆå¦‚ï¼š20251204ï¼‰ï¼Œé»˜è®¤ä¸ºä»Šå¤©'
)
args = parser.parse_args()

# åˆå§‹åŒ–
init_env_file()
token = get_tushare_token()
if token:
    ts.set_token(token)
    print("âœ“ å·²åŠ è½½ Tushare token\n")
else:
    print("âš ï¸  æœªæ‰¾åˆ° Tushare token")
    sys.exit(1)

# ç¡®å®šåˆ†ææ—¥æœŸ
if args.date:
    end_date = args.date
else:
    # é»˜è®¤ä½¿ç”¨ä»Šå¤©
    end_date = datetime.now().strftime("%Y%m%d")

print(f"åˆ†ææ—¥æœŸ: {end_date}\n")

# åˆ›å»ºdocæ–‡ä»¶å¤¹
doc_dir = Path("doc")
doc_dir.mkdir(exist_ok=True)

# ç”Ÿæˆæ—¶é—´æˆ³
timestamp = int(time.time())

def save_result_to_file(content: str, task_name: str, task_number: int = None):
    """ä¿å­˜ç»“æœåˆ°å•ç‹¬æ–‡ä»¶"""
    # ç”Ÿæˆæ–‡ä»¶åï¼šæ—¥æœŸ-æ—¶é—´æˆ³-ä»»åŠ¡X-ç®€çŸ­æè¿°.txt
    task_descriptions = {
        1: "é‡ä»·å¼‚åŠ¨åˆ†æ",
        2: "Alphaæ”¶ç›Šæ’è¡Œ",
        3: "èµ„é‡‘æµå…¥æƒ…å†µ",
        4: "Alphaå¢é•¿é€Ÿåº¦æ’è¡Œ",
        5: "æ¶¨è·Œåœè‚¡ç¥¨æ•°æ®"
    }
    
    if task_number and task_number in task_descriptions:
        description = task_descriptions[task_number]
        if "é”™è¯¯" in task_name:
            description += "-é”™è¯¯"
        filename = f"{end_date}-{timestamp}-ä»»åŠ¡{task_number}-{description}.txt"
    else:
        # å¦‚æœæ²¡æœ‰ä»»åŠ¡ç¼–å·ï¼Œä½¿ç”¨ä»»åŠ¡åç®€åŒ–ç‰ˆ
        task_suffix = task_name.replace("ä»»åŠ¡", "").replace("ï¼š", "-").replace("ï¼ˆé”™è¯¯ï¼‰", "-é”™è¯¯")
        task_suffix = task_suffix.replace("ä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—", "").replace("ä¸œæ–¹è´¢å¯Œæ¦‚å¿µ", "")
        task_suffix = task_suffix.replace(" ", "").strip("-")
        filename = f"{end_date}-{timestamp}-{task_suffix}.txt"
    
    # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
    filename = filename.replace("/", "-").replace("\\", "-").replace(":", "-").replace("*", "-").replace("?", "-").replace('"', "-").replace("|", "-")
    filepath = doc_dir / filename
    
    # å†™å…¥æ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(f"{task_name}\n")
        f.write(f"{'='*80}\n\n")
        f.write(content)
    
    print(f"âœ“ {task_name} ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    return filepath

# ä»»åŠ¡1ï¼šåˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—20251203é‡ä»·å¼‚åŠ¨æƒ…å†µ
print("=" * 80)
print("ä»»åŠ¡1ï¼šåˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—é‡ä»·å¼‚åŠ¨æƒ…å†µ")
print("=" * 80)
try:
    scan_result = scan_concept_volume_anomaly(
        end_date=end_date,
        vol_ratio_threshold=1.15,
        price_change_5d_min=0.02,
        price_change_5d_max=0.08,
        hot_limit=160
    )
    
    # æ ¼å¼åŒ–ç»“æœ - ä¿å­˜æ‰€æœ‰çƒ­é—¨æ¿å—çš„æ•°æ®
    result_text = []
    result_text.append(f"ğŸ“Š ä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—é‡ä»·å¼‚åŠ¨åˆ†æ")
    result_text.append(f"åˆ†ææ—¥æœŸ: {end_date}")
    result_text.append(f"æ‰«ææ¿å—æ•°é‡: {scan_result.get('scanned_count', 0)}")
    result_text.append(f"åŒ¹é…å¼‚åŠ¨æ•°é‡: {scan_result.get('matched_count', 0)}")
    result_text.append("")
    
    # ä¿å­˜æ‰€æœ‰æ¿å—æ•°æ®ï¼ˆall_resultsåŒ…å«æ‰€æœ‰æ‰«æçš„æ¿å—ï¼‰
    all_results = scan_result.get('all_results', [])
    if all_results:
        result_text.append(f"ğŸ“‹ æ‰€æœ‰çƒ­é—¨æ¿å—é‡ä»·æ•°æ®ï¼ˆå…±{len(all_results)}ä¸ªï¼‰:")
        result_text.append("-" * 120)
        result_text.append(f"{'åºå·':<6} {'æ¿å—ä»£ç ':<15} {'æ¿å—åç§°':<30} {'æˆäº¤é‡æ¯”ç‡':<12} {'5æ—¥æ¶¨å¹…':<12} {'æ¢æ‰‹ç‡':<12} {'å½“å‰ä»·æ ¼':<12} {'æ˜¯å¦åŒ¹é…':<10} {'è¯´æ˜':<30}")
        result_text.append("-" * 120)
        
        for i, match in enumerate(all_results, 1):
            code = match.get('code', '')
            name = match.get('name', code)
            metrics = match.get('metrics', {})
            vol_ratio = metrics.get('vol_ratio', 0)
            price_change_5d = metrics.get('price_change_5d', 0)
            turnover_rate = metrics.get('turnover_rate', 0)
            current_price = metrics.get('current_price', 0)
            is_match = "æ˜¯" if match.get('is_match', False) else "å¦"
            reasoning = match.get('reasoning', 'æ— ')
            
            result_text.append(f"{i:<6} {code:<15} {str(name)[:28]:<30} {vol_ratio:>10.2f} {price_change_5d*100:>10.2f}% {turnover_rate:>10.2f}% {current_price:>10.2f} {is_match:<10} {str(reasoning)[:28]:<30}")
        
        result_text.append("")
        result_text.append("-" * 120)
        result_text.append("")
    
    # å¦‚æœæœ‰åŒ¹é…çš„å¼‚åŠ¨æ¿å—ï¼Œå•ç‹¬åˆ—å‡º
    if scan_result.get('matched_count', 0) > 0:
        result_text.append("âœ… ç¬¦åˆå¼‚åŠ¨æ¡ä»¶çš„æ¿å—:")
        result_text.append("-" * 120)
        for i, match in enumerate(scan_result.get('matches', []), 1):
            result_text.append(f"\n{i}. {match.get('name', match.get('code'))} ({match.get('code')})")
            metrics = match.get('metrics', {})
            result_text.append(f"   æˆäº¤é‡æ¯”ç‡: {metrics.get('vol_ratio', 0):.2f}")
            result_text.append(f"   5æ—¥æ¶¨å¹…: {metrics.get('price_change_5d', 0)*100:.2f}%")
            result_text.append(f"   æ¢æ‰‹ç‡: {metrics.get('turnover_rate', 0):.2f}%")
            result_text.append(f"   å½“å‰ä»·æ ¼: {metrics.get('current_price', 0):.2f}")
            result_text.append(f"   è¯´æ˜: {match.get('reasoning', 'æ— ')}")
    
    result_content = "\n".join(result_text)
    save_result_to_file(result_content, "ä»»åŠ¡1ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—é‡ä»·å¼‚åŠ¨åˆ†æ", task_number=1)
    print("âœ“ ä»»åŠ¡1å®Œæˆ\n")
    
except Exception as e:
    import traceback
    error_msg = f"ä»»åŠ¡1æ‰§è¡Œå¤±è´¥: {str(e)}\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"
    print(error_msg)
    save_result_to_file(error_msg, "ä»»åŠ¡1ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—é‡ä»·å¼‚åŠ¨åˆ†æï¼ˆé”™è¯¯ï¼‰", task_number=1)

# ä»»åŠ¡2ï¼šåˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—20251203 alpha æ”¶ç›Šæ’è¡Œ
print("=" * 80)
print("ä»»åŠ¡2ï¼šåˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaæ”¶ç›Šæ’è¡Œ")
print("=" * 80)
try:
    # è·å–çƒ­é—¨æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨
    concept_codes = get_hot_concept_codes(end_date, limit=80)
    
    if not concept_codes:
        result_content = "æ— æ³•è·å–çƒ­é—¨æ¦‚å¿µæ¿å—åˆ—è¡¨"
        save_result_to_file(result_content, "ä»»åŠ¡2ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaæ”¶ç›Šæ’è¡Œï¼ˆé”™è¯¯ï¼‰", task_number=2)
        print("âš ï¸ æ— æ³•è·å–çƒ­é—¨æ¦‚å¿µæ¿å—åˆ—è¡¨\n")
    else:
        # è¿›è¡ŒAlphaæ’å
        df = rank_sectors_alpha(concept_codes, "000300.SH", end_date)
        
        if df.empty:
            result_content = "æ— æ³•è·å–æ¿å—Alphaæ•°æ®"
            save_result_to_file(result_content, "ä»»åŠ¡2ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaæ”¶ç›Šæ’è¡Œï¼ˆé”™è¯¯ï¼‰", task_number=2)
            print("âš ï¸ æ— æ³•è·å–æ¿å—Alphaæ•°æ®\n")
        else:
            # è·å–æ¿å—åç§° - è·å–æ‰€æœ‰æ¿å—çš„åç§°
            try:
                pro = ts.pro_api()
                # åˆ†æ‰¹è·å–æ¿å—åç§°ï¼ˆAPIå¯èƒ½æœ‰é™åˆ¶ï¼‰
                all_codes = df['sector_code'].tolist()
                name_map = {}
                pct_map = {}
                amount_map = {}
                turnover_map = {}
                
                # æ¯æ¬¡æŸ¥è¯¢æœ€å¤š50ä¸ªä»£ç 
                batch_size = 50
                for i in range(0, len(all_codes), batch_size):
                    batch_codes = all_codes[i:i+batch_size]
                    concept_codes_str = ','.join(batch_codes)
                    concept_df = pro.dc_index(ts_code=concept_codes_str, trade_date=end_date)
                    
                    if not concept_df.empty and 'ts_code' in concept_df.columns:
                        for _, row in concept_df.iterrows():
                            code = row['ts_code']
                            name_map[code] = row.get('name', code) if pd.notna(row.get('name')) else code
                            pct_map[code] = row.get('pct_change', 0) if pd.notna(row.get('pct_change')) else 0
                            amount_map[code] = row.get('amount', 0) if pd.notna(row.get('amount')) else 0
                            turnover_map[code] = row.get('turnover', 0) if pd.notna(row.get('turnover')) else 0
                
                # æ·»åŠ æ¿å—åç§°ç­‰ä¿¡æ¯
                df['name'] = df['sector_code'].map(name_map).fillna(df['sector_code'])
                df['pct_change'] = df['sector_code'].map(pct_map).fillna(0)
                df['amount'] = df['sector_code'].map(amount_map).fillna(0)
                df['turnover'] = df['sector_code'].map(turnover_map).fillna(0)
                
            except Exception as e:
                import sys
                print(f"è·å–æ¿å—åç§°å¤±è´¥: {str(e)}", file=sys.stderr)
                df['name'] = df['sector_code']
                df['pct_change'] = 0
                df['amount'] = 0
                df['turnover'] = 0
            
            # æ ¼å¼åŒ–è¾“å‡º
            result_text = []
            result_text.append(f"ğŸ“Š ä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaæ”¶ç›Šæ’è¡Œ")
            result_text.append(f"åˆ†ææ—¥æœŸ: {end_date}")
            result_text.append(f"åŸºå‡†æŒ‡æ•°: 000300.SH (æ²ªæ·±300)")
            result_text.append(f"åˆ†ææ¿å—æ•°é‡: {len(df)}")
            result_text.append("")
            result_text.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {'æ¿å—åç§°':<20} {'Alphaå¾—åˆ†':<12} {'Alpha_2':<12} {'Alpha_5':<12} {'ä»Šæ—¥æ¶¨è·Œ':<10} {'æˆäº¤é¢(äº¿)':<12}")
            result_text.append("-" * 120)
            
            # ä¿å­˜æ‰€æœ‰æ¿å—æ•°æ®ï¼Œä¸æˆªæ–­
            for i, row in df.iterrows():
                rank = row.get('rank', i+1)
                code = row.get('sector_code', '')
                name = row.get('name', code)
                score = row.get('alpha_score', 0)
                alpha_2 = row.get('alpha_2', 0)
                alpha_5 = row.get('alpha_5', 0)
                pct = row.get('pct_change', 0)
                amount = row.get('amount', 0) / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
                
                result_text.append(f"{rank:<6} {code:<15} {name[:18]:<20} {score*100:>10.2f}% {alpha_2*100:>10.2f}% {alpha_5*100:>10.2f}% {pct:>8.2f}% {amount:>10.2f}")
            
            result_content = "\n".join(result_text)
            save_result_to_file(result_content, "ä»»åŠ¡2ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaæ”¶ç›Šæ’è¡Œ", task_number=2)
            print("âœ“ ä»»åŠ¡2å®Œæˆ\n")
            
except Exception as e:
    import traceback
    error_msg = f"ä»»åŠ¡2æ‰§è¡Œå¤±è´¥: {str(e)}\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"
    print(error_msg)
    save_result_to_file(error_msg, "ä»»åŠ¡2ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaæ”¶ç›Šæ’è¡Œï¼ˆé”™è¯¯ï¼‰", task_number=2)

# ä»»åŠ¡3ï¼šè·å–ä¸œæ–¹è´¢å¯Œæ¦‚å¿µ20251203èµ„é‡‘æµå…¥æƒ…å†µ
print("=" * 80)
print("ä»»åŠ¡3ï¼šè·å–ä¸œæ–¹è´¢å¯Œæ¦‚å¿µèµ„é‡‘æµå…¥æƒ…å†µ")
print("=" * 80)
try:
    pro = ts.pro_api()
    
    # è·å–æ¦‚å¿µæ¿å—èµ„é‡‘æµå‘æ•°æ®
    df = pro.moneyflow_ind_dc(trade_date=end_date, content_type="æ¦‚å¿µ")
    
    if df.empty:
        result_content = f"æœªæ‰¾åˆ°{end_date}çš„æ¦‚å¿µæ¿å—èµ„é‡‘æµå‘æ•°æ®"
        save_result_to_file(result_content, "ä»»åŠ¡3ï¼šä¸œæ–¹è´¢å¯Œæ¦‚å¿µèµ„é‡‘æµå…¥æƒ…å†µï¼ˆé”™è¯¯ï¼‰", task_number=3)
        print("âš ï¸ æœªæ‰¾åˆ°èµ„é‡‘æµå‘æ•°æ®\n")
    else:
        # æŒ‰ä¸»åŠ›å‡€æµå…¥æ’åº
        if 'net_mf_amount' in df.columns:
            df = df.sort_values('net_mf_amount', ascending=False)
        
        # æ ¼å¼åŒ–è¾“å‡º
        result_text = []
        result_text.append(f"ğŸ“Š ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—èµ„é‡‘æµå…¥æƒ…å†µ")
        result_text.append(f"åˆ†ææ—¥æœŸ: {end_date}")
        result_text.append(f"æ¿å—æ•°é‡: {len(df)}")
        result_text.append("")
        result_text.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {'æ¿å—åç§°':<25} {'ä¸»åŠ›å‡€æµå…¥(ä¸‡)':<18} {'è¶…å¤§å•(ä¸‡)':<15} {'å¤§å•(ä¸‡)':<15} {'ä¸­å•(ä¸‡)':<15} {'å°å•(ä¸‡)':<15}")
        result_text.append("-" * 140)
        
        # ä¿å­˜æ‰€æœ‰æ¿å—æ•°æ®ï¼Œä¸æˆªæ–­
        for i, row in df.iterrows():
            rank = i + 1
            code = row.get('ts_code', '')
            name = row.get('name', code) if 'name' in row else code
            net_mf = row.get('net_mf_amount', 0) / 10000  # è½¬æ¢ä¸ºä¸‡å…ƒ
            super_large = row.get('super_large_amount', 0) / 10000
            large = row.get('large_amount', 0) / 10000
            mid = row.get('mid_amount', 0) / 10000
            small = row.get('small_amount', 0) / 10000
            
            result_text.append(f"{rank:<6} {code:<15} {str(name)[:23]:<25} {net_mf:>15.2f} {super_large:>13.2f} {large:>13.2f} {mid:>13.2f} {small:>13.2f}")
        
        result_content = "\n".join(result_text)
        save_result_to_file(result_content, "ä»»åŠ¡3ï¼šä¸œæ–¹è´¢å¯Œæ¦‚å¿µèµ„é‡‘æµå…¥æƒ…å†µ", task_number=3)
        print("âœ“ ä»»åŠ¡3å®Œæˆ\n")
        
except Exception as e:
    import traceback
    error_msg = f"ä»»åŠ¡3æ‰§è¡Œå¤±è´¥: {str(e)}\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"
    print(error_msg)
    save_result_to_file(error_msg, "ä»»åŠ¡3ï¼šä¸œæ–¹è´¢å¯Œæ¦‚å¿µèµ„é‡‘æµå…¥æƒ…å†µï¼ˆé”™è¯¯ï¼‰", task_number=3)

# ä»»åŠ¡4ï¼šåˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—20251203alphaå¢é•¿é€Ÿåº¦æ’è¡Œ
print("=" * 80)
print("ä»»åŠ¡4ï¼šåˆ†æä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaå¢é•¿é€Ÿåº¦æ’è¡Œ")
print("=" * 80)
try:
    # è·å–æ¦‚å¿µæ¿å—ä»£ç åˆ—è¡¨
    concept_codes = get_concept_codes(end_date)
    
    if not concept_codes:
        result_content = "æ— æ³•è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨"
        save_result_to_file(result_content, "ä»»åŠ¡4ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaå¢é•¿é€Ÿåº¦æ’è¡Œï¼ˆé”™è¯¯ï¼‰", task_number=4)
        print("âš ï¸ æ— æ³•è·å–æ¦‚å¿µæ¿å—åˆ—è¡¨\n")
    else:
        # è®¡ç®—æ’åä¸Šå‡é€Ÿåº¦
        df = calculate_alpha_rank_velocity(concept_codes, "000300.SH", end_date)
        
        if df.empty:
            result_content = "æ— æ³•è·å–Alphaæ’åä¸Šå‡é€Ÿåº¦æ•°æ®"
            save_result_to_file(result_content, "ä»»åŠ¡4ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaå¢é•¿é€Ÿåº¦æ’è¡Œï¼ˆé”™è¯¯ï¼‰", task_number=4)
            print("âš ï¸ æ— æ³•è·å–Alphaæ’åä¸Šå‡é€Ÿåº¦æ•°æ®\n")
        else:
            # è·å–å®é™…ä½¿ç”¨çš„æ—¥æœŸä¿¡æ¯
            current_date = df.attrs.get('current_date', end_date)
            yesterday_date = df.attrs.get('yesterday_date', None)
            day_before_yesterday_date = df.attrs.get('day_before_yesterday_date', None)
            
            # æ ¼å¼åŒ–è¾“å‡º
            result_text = []
            result_text.append(f"ğŸ“Š ä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaæ’åä¸Šå‡é€Ÿåº¦åˆ†æ")
            result_text.append(f"åˆ†ææ—¥æœŸ: {current_date}")
            if yesterday_date:
                result_text.append(f"å¯¹æ¯”æ—¥æœŸ1ï¼ˆè¾ƒæ˜¨æ—¥ï¼‰: {yesterday_date}")
            if day_before_yesterday_date:
                result_text.append(f"å¯¹æ¯”æ—¥æœŸ2ï¼ˆè¾ƒå‰å¤©ï¼‰: {day_before_yesterday_date}")
            result_text.append("")
            
            # æŒ‰1æ—¥ä¸Šå‡ä½æ•°æ’åº - ä¿å­˜æ‰€æœ‰æ•°æ®
            if 'rank_change_1d' in df.columns:
                df_sorted_1d = df.sort_values('rank_change_1d', ascending=False)
                result_text.append(f"ğŸ“ˆ ä¸€å¤©å†…æ’åä¸Šå‡é€Ÿåº¦æ’è¡Œï¼ˆå…±{len(df_sorted_1d)}ä¸ªæ¿å—ï¼‰:")
                result_text.append("-" * 120)
                result_text.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {'Alphaå€¼':<12} {'è¾ƒæ˜¨æ—¥ä¸Šå‡':<15} {'è¾ƒå‰å¤©ä¸Šå‡':<15} {'å½“å‰æ’å':<12}")
                result_text.append("-" * 120)
                
                # ä¿å­˜æ‰€æœ‰æ•°æ®ï¼Œä¸æˆªæ–­
                for i, row in df_sorted_1d.iterrows():
                    rank = i + 1
                    code = row.get('sector_code', '')
                    alpha = row.get('alpha_score', 0)
                    change_1d = row.get('rank_change_1d', 0)
                    change_2d = row.get('rank_change_2d', 0)
                    current_rank = row.get('current_rank', 0)
                    
                    result_text.append(f"{rank:<6} {code:<15} {alpha*100:>10.2f}% {change_1d:>13.0f} {change_2d:>13.0f} {current_rank:>10.0f}")
            
            result_text.append("")
            
            # æŒ‰2æ—¥ä¸Šå‡ä½æ•°æ’åº - ä¿å­˜æ‰€æœ‰æ•°æ®
            if 'rank_change_2d' in df.columns:
                df_sorted_2d = df.sort_values('rank_change_2d', ascending=False)
                result_text.append(f"ğŸ“ˆ ä¸¤å¤©å†…æ’åä¸Šå‡é€Ÿåº¦æ’è¡Œï¼ˆå…±{len(df_sorted_2d)}ä¸ªæ¿å—ï¼‰:")
                result_text.append("-" * 120)
                result_text.append(f"{'æ’å':<6} {'æ¿å—ä»£ç ':<15} {'Alphaå€¼':<12} {'è¾ƒæ˜¨æ—¥ä¸Šå‡':<15} {'è¾ƒå‰å¤©ä¸Šå‡':<15} {'å½“å‰æ’å':<12}")
                result_text.append("-" * 120)
                
                # ä¿å­˜æ‰€æœ‰æ•°æ®ï¼Œä¸æˆªæ–­
                for i, row in df_sorted_2d.iterrows():
                    rank = i + 1
                    code = row.get('sector_code', '')
                    alpha = row.get('alpha_score', 0)
                    change_1d = row.get('rank_change_1d', 0)
                    change_2d = row.get('rank_change_2d', 0)
                    current_rank = row.get('current_rank', 0)
                    
                    result_text.append(f"{rank:<6} {code:<15} {alpha*100:>10.2f}% {change_1d:>13.0f} {change_2d:>13.0f} {current_rank:>10.0f}")
            
            result_content = "\n".join(result_text)
            save_result_to_file(result_content, "ä»»åŠ¡4ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaå¢é•¿é€Ÿåº¦æ’è¡Œ", task_number=4)
            print("âœ“ ä»»åŠ¡4å®Œæˆ\n")
            
except Exception as e:
    import traceback
    error_msg = f"ä»»åŠ¡4æ‰§è¡Œå¤±è´¥: {str(e)}\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"
    print(error_msg)
    save_result_to_file(error_msg, "ä»»åŠ¡4ï¼šä¸œè´¢çƒ­é—¨æ¦‚å¿µæ¿å—Alphaå¢é•¿é€Ÿåº¦æ’è¡Œï¼ˆé”™è¯¯ï¼‰", task_number=4)

# ä»»åŠ¡5ï¼šè·å–æ¶¨è·Œåœè‚¡ç¥¨æ•°æ®
print("=" * 80)
print("ä»»åŠ¡5ï¼šè·å–æ¶¨è·Œåœè‚¡ç¥¨æ•°æ®")
print("=" * 80)
try:
    pro = ts.pro_api()
    
    # è·å–æ¶¨è·Œåœæ•°æ®
    df = pro.limit_list_d(trade_date=end_date)
    
    if df.empty:
        result_content = f"æœªæ‰¾åˆ°{end_date}çš„æ¶¨è·Œåœè‚¡ç¥¨æ•°æ®\n\næç¤ºï¼š\n- è¯·ç¡®è®¤è¯¥æ—¥æœŸæ˜¯å¦ä¸ºäº¤æ˜“æ—¥\n- è¯¥æ—¥æœŸæ˜¯å¦æœ‰è‚¡ç¥¨æ¶¨è·Œåœæˆ–ç‚¸æ¿\n- æ³¨æ„ï¼šæœ¬æ¥å£ä¸æä¾›STè‚¡ç¥¨çš„ç»Ÿè®¡"
        save_result_to_file(result_content, "ä»»åŠ¡5ï¼šæ¶¨è·Œåœè‚¡ç¥¨æ•°æ®ï¼ˆé”™è¯¯ï¼‰", task_number=5)
        print("âš ï¸ æœªæ‰¾åˆ°æ¶¨è·Œåœæ•°æ®\n")
    else:
        # æ ¼å¼åŒ–è¾“å‡º
        result_text = []
        result_text.append(f"ğŸ“Š æ¶¨è·Œåœè‚¡ç¥¨æ•°æ®")
        result_text.append(f"åˆ†ææ—¥æœŸ: {end_date}")
        result_text.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        if 'limit' in df.columns:
            limit_stats = df['limit'].value_counts()
            result_text.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
            result_text.append("-" * 120)
            limit_type_map = {'U': 'æ¶¨åœ', 'D': 'è·Œåœ', 'Z': 'ç‚¸æ¿'}
            for limit_val, count in limit_stats.items():
                type_name = limit_type_map.get(str(limit_val), str(limit_val))
                result_text.append(f"  - {type_name}: {count} åª")
            result_text.append("")
        
        # æŒ‰è¿æ¿æ•°æ’åºï¼ˆé™åºï¼‰ï¼Œç„¶åæŒ‰å°å•é‡‘é¢æ’åºï¼ˆé™åºï¼‰
        if 'limit_times' in df.columns:
            df = df.sort_values(['limit_times', 'fd_amount'], ascending=[False, False], na_position='last')
        elif 'fd_amount' in df.columns:
            df = df.sort_values('fd_amount', ascending=False, na_position='last')
        
        result_text.append(f"å…±æ‰¾åˆ° {len(df)} æ¡æ¶¨è·Œåœè®°å½•ï¼Œæ¶‰åŠ {len(df['ts_code'].unique()) if 'ts_code' in df.columns else len(df)} åªè‚¡ç¥¨")
        result_text.append("")
        result_text.append(f"{'äº¤æ˜“æ—¥æœŸ':<12} {'è‚¡ç¥¨ä»£ç ':<15} {'è‚¡ç¥¨åç§°':<20} {'è¡Œä¸š':<15} {'ç±»å‹':<8} {'æ”¶ç›˜ä»·':<10} {'æ¶¨è·Œå¹…':<10} {'æˆäº¤é¢(å…ƒ)':<18} {'å°å•é‡‘é¢(å…ƒ)':<18} {'é¦–æ¬¡å°æ¿':<12} {'æœ€åå°æ¿':<12} {'ç‚¸æ¿æ¬¡æ•°':<10} {'è¿æ¿æ•°':<8} {'æ¶¨åœç»Ÿè®¡':<15}")
        result_text.append("-" * 200)
        
        # ä¿å­˜æ‰€æœ‰æ•°æ®ï¼Œä¸æˆªæ–­
        for _, row in df.iterrows():
            trade_date_str = format_date(str(row.get('trade_date', '-'))) if pd.notna(row.get('trade_date')) else "-"
            code = str(row.get('ts_code', '-'))[:13]
            name = str(row.get('name', '-'))[:18]
            industry = str(row.get('industry', '-'))[:13]
            limit_val = str(row.get('limit', '-'))
            limit_type_map = {'U': 'æ¶¨åœ', 'D': 'è·Œåœ', 'Z': 'ç‚¸æ¿'}
            limit_type_name = limit_type_map.get(limit_val, limit_val)
            close = f"{row.get('close', 0):.2f}" if pd.notna(row.get('close')) else "-"
            pct_chg = f"{row.get('pct_chg', 0):+.2f}%" if pd.notna(row.get('pct_chg')) else "-"
            amount = format_large_number(row.get('amount', 0)) if pd.notna(row.get('amount')) else "-"
            fd_amount = format_large_number(row.get('fd_amount', 0)) if pd.notna(row.get('fd_amount')) else "-"
            first_time = str(row.get('first_time', '-'))[:10] if pd.notna(row.get('first_time')) else "-"
            last_time = str(row.get('last_time', '-'))[:10] if pd.notna(row.get('last_time')) else "-"
            open_times = str(int(row.get('open_times', 0))) if pd.notna(row.get('open_times')) else "-"
            limit_times = str(int(row.get('limit_times', 0))) if pd.notna(row.get('limit_times')) else "-"
            up_stat = str(row.get('up_stat', '-'))[:13] if pd.notna(row.get('up_stat')) else "-"
            
            result_text.append(f"{trade_date_str:<12} {code:<15} {name:<20} {industry:<15} {limit_type_name:<8} {close:<10} {pct_chg:<10} {amount:<18} {fd_amount:<18} {first_time:<12} {last_time:<12} {open_times:<10} {limit_times:<8} {up_stat:<15}")
        
        result_text.append("")
        result_text.append("ğŸ“Š è¯¦ç»†ç»Ÿè®¡ï¼š")
        result_text.append("-" * 120)
        
        if 'ts_code' in df.columns:
            result_text.append(f"æ¶‰åŠè‚¡ç¥¨æ•°é‡: {len(df['ts_code'].unique())} åª")
        
        if 'trade_date' in df.columns:
            result_text.append(f"æ¶‰åŠäº¤æ˜“æ—¥æœŸ: {len(df['trade_date'].unique())} ä¸ª")
        
        # è®¡ç®—æ€»æˆäº¤é¢
        if 'amount' in df.columns:
            total_amount = df['amount'].sum()
            result_text.append(f"æ€»æˆäº¤é¢: {format_large_number(total_amount)} å…ƒ")
        
        # è®¡ç®—æ€»å°å•é‡‘é¢
        if 'fd_amount' in df.columns:
            total_fd_amount = df['fd_amount'].sum()
            result_text.append(f"æ€»å°å•é‡‘é¢: {format_large_number(total_fd_amount)} å…ƒ")
        
        # ç»Ÿè®¡è¿æ¿æƒ…å†µ
        if 'limit_times' in df.columns:
            max_limit_times = df['limit_times'].max()
            if pd.notna(max_limit_times):
                result_text.append(f"æœ€é«˜è¿æ¿æ•°: {int(max_limit_times)} æ¿")
        
        # ç»Ÿè®¡ç‚¸æ¿æƒ…å†µ
        if 'open_times' in df.columns:
            total_open_times = df['open_times'].sum()
            result_text.append(f"æ€»ç‚¸æ¿æ¬¡æ•°: {int(total_open_times)} æ¬¡")
            avg_open_times = df['open_times'].mean()
            if pd.notna(avg_open_times):
                result_text.append(f"å¹³å‡ç‚¸æ¿æ¬¡æ•°: {avg_open_times:.2f} æ¬¡")
        
        result_text.append("")
        result_text.append("ğŸ“ è¯´æ˜ï¼š")
        result_text.append("  - æ•°æ®æ¥æºï¼šTushare limit_list_dæ¥å£")
        result_text.append("  - æ•°æ®å†å²ï¼š2020å¹´è‡³ä»Šï¼ˆä¸æä¾›STè‚¡ç¥¨çš„ç»Ÿè®¡ï¼‰")
        result_text.append("  - ç±»å‹è¯´æ˜ï¼šU=æ¶¨åœï¼ŒD=è·Œåœï¼ŒZ=ç‚¸æ¿")
        result_text.append("  - å°å•é‡‘é¢ï¼šä»¥æ¶¨åœä»·ä¹°å…¥æŒ‚å•çš„èµ„é‡‘æ€»é‡ï¼ˆè·Œåœæ— æ­¤æ•°æ®ï¼‰")
        result_text.append("  - é¦–æ¬¡å°æ¿æ—¶é—´ï¼šè‚¡ç¥¨é¦–æ¬¡è¾¾åˆ°æ¶¨åœä»·çš„æ—¶é—´ï¼ˆè·Œåœæ— æ­¤æ•°æ®ï¼‰")
        result_text.append("  - ç‚¸æ¿æ¬¡æ•°ï¼šæ¶¨åœåå¼€æ¿çš„æ¬¡æ•°ï¼ˆè·Œåœä¸ºå¼€æ¿æ¬¡æ•°ï¼‰")
        result_text.append("  - è¿æ¿æ•°ï¼šä¸ªè‚¡è¿ç»­å°æ¿æ•°é‡")
        result_text.append("  - æ¶¨åœç»Ÿè®¡ï¼šæ ¼å¼ä¸ºN/Tï¼Œè¡¨ç¤ºTå¤©å†…æœ‰Næ¬¡æ¶¨åœ")
        result_text.append("  - æƒé™è¦æ±‚ï¼š5000ç§¯åˆ†ï¼ˆæ¯åˆ†é’Ÿ200æ¬¡ï¼Œæ¯å¤©æ€»é‡1ä¸‡æ¬¡ï¼‰ï¼Œ8000ç§¯åˆ†ä»¥ä¸Šï¼ˆæ¯åˆ†é’Ÿ500æ¬¡ï¼Œæ¯å¤©æ€»é‡ä¸é™åˆ¶ï¼‰")
        result_text.append("  - é™é‡ï¼šå•æ¬¡æœ€å¤§å¯è·å–2500æ¡æ•°æ®ï¼Œå¯é€šè¿‡æ—¥æœŸæˆ–è‚¡ç¥¨å¾ªç¯æå–")
        
        result_content = "\n".join(result_text)
        save_result_to_file(result_content, "ä»»åŠ¡5ï¼šæ¶¨è·Œåœè‚¡ç¥¨æ•°æ®", task_number=5)
        print("âœ“ ä»»åŠ¡5å®Œæˆ\n")
        
except Exception as e:
    import traceback
    error_msg = f"ä»»åŠ¡5æ‰§è¡Œå¤±è´¥: {str(e)}\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"
    print(error_msg)
    save_result_to_file(error_msg, "ä»»åŠ¡5ï¼šæ¶¨è·Œåœè‚¡ç¥¨æ•°æ®ï¼ˆé”™è¯¯ï¼‰", task_number=5)

print("=" * 80)
print("æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
print("=" * 80)
print(f"ç»“æœå·²åˆ†åˆ«ä¿å­˜åˆ° doc/ æ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶åæ ¼å¼ï¼š{end_date}-{timestamp}-ä»»åŠ¡X-*.txt")

